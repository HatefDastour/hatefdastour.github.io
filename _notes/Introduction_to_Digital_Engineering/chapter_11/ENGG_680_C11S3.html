

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>11.3. t-Distributed Stochastic Neighbor Embedding (t-SNE) &#8212; Introduction to Digital Engineering</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_11/ENGG_680_C11S3';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="11.4. Linear and Quadratic Discriminant Analyses" href="ENGG_680_C11S4.html" />
    <link rel="prev" title="11.2. Principal Components Analysis (PCA)" href="ENGG_680_C11S2.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../Introduction.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_01/ReadMe.html">1. Introduction to Python Programming</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S1.html">1.1. Variable names, Expressions and statements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S2.html">1.2. Fundamental Concepts and Operations in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S3.html">1.3. Functions</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_02/ReadMe.html">2. Control Flow: Conditionals, Recursion, and Iteration</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG_680_C02S1.html">2.1. Conditionals and recursion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG_680_C02S2.html">2.2. Iteration</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_03/ReadMe.html">3. Data Structures and File Handling in Python</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S1.html">3.1. Strings in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S2.html">3.2. Python Lists</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S3.html">3.3. Python Dictionaries: Key-Value Pairs in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S4.html">3.4. Python Tuples: Immutable Sequences in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S5.html">3.5. Python Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S6.html">3.6. Files in Python (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_04/ReadMe.html">4. Classes and Objects</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S1.html">4.1. Introduction to Classes and Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S2.html">4.2. Inheritance and Polymorphism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S3.html">4.3. Encapsulation and Abstraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S4.html">4.4. Copying Objects (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S5.html">4.5. Magic Methods (Dunder Methods) in Python (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S6.html">4.6. Examples of Classes (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_05/ReadMe.html">5. Introduction to NumPy</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S1.html">5.1. Basics of Numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S2.html">5.2. NumPy Function Reference and Usage Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S3.html">5.3. Advanced Numpy Concepts (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_06/ReadMe.html">6. Working with Data using Pandas</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S1.html">6.1. An Introduction to Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S2.html">6.2. DataFrame and Series Indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S3.html">6.3. Pandas Data Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S4.html">6.4. Handling Missing Data in Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S5.html">6.5. Combining Datasets using Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S6.html">6.6. Aggregation and Grouping in Pandas</a></li>

</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_07/ReadMe.html">7. Data Visualization using Python</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S1.html">7.1. Getting started with Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S2.html">7.2. Matplotlib Styles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S3.html">7.3. Matplotlib interfaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S4.html">7.4. Adjusting the Plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S5.html">7.5. Seaborn plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S6.html">7.6. Python Plotting Guide</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_08/ReadMe.html">8. An Introduction to Computer Vision</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S1.html">8.1. Getting Started with OpenCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S2.html">8.2. Geometric Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S3.html">8.3. Image Thresholding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S4.html">8.4. Image Filtering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S5.html">8.5. Drawing Functions (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S6.html">8.6. Morphological Transformations (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_09/ReadMe.html">9. An Introduction to Machine Learning</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S1.html">9.1. Statistical Metrics and Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S2.html">9.2. An Introduction to Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S3.html">9.3. Multiple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S4.html">9.4. Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S5.html">9.5. K-Nearest Neighbors (K-NN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S6.html">9.6. Resampling Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S7.html">9.7. Support Vector Machines</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_10/ReadMe.html">10. Tree-Based Methods</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S1.html">10.1. Fundamental Structure of Decision Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S2.html">10.2. Regression Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S3.html">10.3. Classification Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S4.html">10.4. Regression Trees and Linear Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S5.html">10.5. Enhancing Decision Trees with Bagging: An Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S6.html">10.6. Random Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S7.html">10.7. Gradient Boosting</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="ReadMe.html">11. Dimensionality Reduction and Feature Selection</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C11S1.html">11.1. Introduction to Dimensionality Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C11S2.html">11.2. Principal Components Analysis (PCA)</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">11.3. t-Distributed Stochastic Neighbor Embedding (t-SNE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C11S4.html">11.4. Linear and Quadratic Discriminant Analyses</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C11S5.html">11.5. Recursive Feature Elimination (RFE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C11S6.html">11.6. Practical Considerations in Dimensionality Reduction</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_12/ReadMe.html">12. Introduction to Deep Learning</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S1.html">12.1. Understanding Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S2.html">12.2. Fundamentals of Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S3.html">12.3. Tensors and Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S4.html">12.4. Building a linear Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S5.html">12.5. Building a Logistic Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S6.html">12.6. Multilayer Perceptron (MLP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S7.html">12.7. Image classification with TensorFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S8.html">12.8. Image Augmentations with TensorFlow</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../appendixes/ReadMe.html">13. Appendices</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendixes/SampleQuestions_1.html">13.1. Sample Questions 1</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../References.html">14. References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>t-Distributed Stochastic Neighbor Embedding (t-SNE)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-t-sne">11.3.1. Understanding t-SNE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mechanisms-of-t-sne">11.3.2. Mechanisms of t-SNE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advantages-and-points-of-deliberation">11.3.3. Advantages and Points of Deliberation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#utilitarian-avenues">11.3.4. Utilitarian Avenues</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caveats-and-considerations">11.3.5. Caveats and Considerations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-t-sne-with-scikit-learn-sklearn">11.3.6. Using t-SNE with scikit-learn (sklearn)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#swiss-roll-example">11.3.7. Swiss Roll Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exploring-perplexitys-influence-on-t-sne">11.3.8. Exploring Perplexity’s Influence on t-SNE</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="tex2jax_ignore mathjax_ignore section" id="t-distributed-stochastic-neighbor-embedding-t-sne">
<h1><span class="section-number">11.3. </span>t-Distributed Stochastic Neighbor Embedding (t-SNE)<a class="headerlink" href="#t-distributed-stochastic-neighbor-embedding-t-sne" title="Permalink to this headline">#</a></h1>
<p>t-Distributed Stochastic Neighbor Embedding (t-SNE) stands as a formidable technique tailored for the visualization of high-dimensional data in a more accessible lower-dimensional space. This method is widely employed for data exploration and analysis due to its proficiency in preserving the local intricacies within the data, thereby facilitating the discernment of clusters and patterns. Here’s an in-depth exploration of the workings of t-SNE <span id="id1">[<a class="reference internal" href="../References.html#id70" title="T Tony Cai and Rong Ma. Theoretical foundations of t-sne for visualizing high-dimensional clustered data. The Journal of Machine Learning Research, 23(1):13581–13634, 2022.">Cai and Ma, 2022</a>, <a class="reference internal" href="../References.html#id71" title="Van Hoan Do and Stefan Canzar. A generalization of t-sne and umap to single-cell multimodal omics. Genome biology, 22(1):1–9, 2021.">Do and Canzar, 2021</a>]</span>:</p>
<div class="section" id="understanding-t-sne">
<h2><span class="section-number">11.3.1. </span>Understanding t-SNE<a class="headerlink" href="#understanding-t-sne" title="Permalink to this headline">#</a></h2>
<p>t-SNE emerges as a non-linear dimensionality reduction technique that concentrates on conserving pairwise similarities between data points. Its potency lies in its efficacy in capturing intricate, non-linear relationships existing within the data. Notably, t-SNE is not oriented towards feature extraction or transformation like some other techniques; its primary utility lies in visual representation <span id="id2">[<a class="reference internal" href="../References.html#id72" title="Dmitry Kobak and Philipp Berens. The art of using t-sne for single-cell transcriptomics. Nature communications, 10(1):5416, 2019.">Kobak and Berens, 2019</a>, <a class="reference internal" href="../References.html#id79" title="Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 2008.">Van der Maaten and Hinton, 2008</a>]</span>.</p>
<ol class="arabic simple">
<li><p><strong>Establishing Pairwise Similarities</strong>: The journey of t-SNE commences with the computation of pairwise similarities among data points existing in the original high-dimensional space. Typically, these similarities are grounded in Euclidean distances or other relevant distance metrics.</p></li>
<li><p><strong>Mapping Similarities in Reduced Dimensions</strong>: Subsequently, t-SNE endeavors to map these pairwise similarities onto a lower-dimensional canvas, all while diligently preserving the intrinsic relationships. This mapping endeavor strives to draw similar data points closer and push dissimilar points apart, sculpting a coherent representation.</p></li>
<li><p><strong>Embracing Probability Distributions</strong>: t-SNE embraces the realm of probability distributions to model the similarities present in both the high-dimensional and low-dimensional spaces. It crafts a probability distribution that encapsulates the similarities between data points in the original high-dimensional space, and another distribution tailored for the reduced, lower-dimensional space.</p></li>
<li><p><strong>Minimizing Divergence</strong>: The crux of t-SNE lies in minimizing the divergence, a metric of disparity, between these two probability distributions. Through this intricate dance, the algorithm champions the elevation of data points with substantial similarities in the original space to also possess elevated similarities within the reduced dimensions.</p></li>
</ol>
</div>
<div class="section" id="mechanisms-of-t-sne">
<h2><span class="section-number">11.3.2. </span>Mechanisms of t-SNE<a class="headerlink" href="#mechanisms-of-t-sne" title="Permalink to this headline">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Establishing Pairwise Similarities</strong>: In this initial step, the algorithm computes the conditional probabilities representing the likelihood of a data point selecting another point as its neighbor in the high-dimensional space. This calculation relies on Euclidean distances or other distance metrics. Denoted as <span class="math notranslate nohighlight">\(p_{j|i}\)</span>, it signifies the probability of point <span class="math notranslate nohighlight">\(j\)</span> being chosen as a neighbor for point <span class="math notranslate nohighlight">\(i\)</span>. The perplexity parameter governs the number of neighbors each point has, influencing the shape of the Gaussian distribution used to compute these conditional probabilities <span id="id3">[<a class="reference internal" href="../References.html#id70" title="T Tony Cai and Rong Ma. Theoretical foundations of t-sne for visualizing high-dimensional clustered data. The Journal of Machine Learning Research, 23(1):13581–13634, 2022.">Cai and Ma, 2022</a>, <a class="reference internal" href="../References.html#id71" title="Van Hoan Do and Stefan Canzar. A generalization of t-sne and umap to single-cell multimodal omics. Genome biology, 22(1):1–9, 2021.">Do and Canzar, 2021</a>, <a class="reference internal" href="../References.html#id72" title="Dmitry Kobak and Philipp Berens. The art of using t-sne for single-cell transcriptomics. Nature communications, 10(1):5416, 2019.">Kobak and Berens, 2019</a>, <a class="reference internal" href="../References.html#id79" title="Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 2008.">Van der Maaten and Hinton, 2008</a>]</span>.</p></li>
<li><p><strong>Mapping Similarities in Reduced Dimensions</strong>: Here, the focus shifts to finding a lower-dimensional representation of data points that retains their pairwise similarities to the utmost extent. The representation, <span class="math notranslate nohighlight">\(y_i\)</span>, encapsulates two or three dimensions for each data point <span class="math notranslate nohighlight">\(i\)</span>. The process commences with random initialization of <span class="math notranslate nohighlight">\(y_i\)</span> values, iteratively refining them to minimize the divergence between the similarities in high and low dimensions <span id="id4">[<a class="reference internal" href="../References.html#id70" title="T Tony Cai and Rong Ma. Theoretical foundations of t-sne for visualizing high-dimensional clustered data. The Journal of Machine Learning Research, 23(1):13581–13634, 2022.">Cai and Ma, 2022</a>, <a class="reference internal" href="../References.html#id71" title="Van Hoan Do and Stefan Canzar. A generalization of t-sne and umap to single-cell multimodal omics. Genome biology, 22(1):1–9, 2021.">Do and Canzar, 2021</a>, <a class="reference internal" href="../References.html#id72" title="Dmitry Kobak and Philipp Berens. The art of using t-sne for single-cell transcriptomics. Nature communications, 10(1):5416, 2019.">Kobak and Berens, 2019</a>, <a class="reference internal" href="../References.html#id79" title="Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 2008.">Van der Maaten and Hinton, 2008</a>]</span>.</p></li>
<li><p><strong>Embracing Probability Distributions</strong>: This phase involves modeling pairwise similarities in both high-dimensional and low-dimensional realms using probability distributions. High-dimensional similarities are modeled via a joint probability distribution <span class="math notranslate nohighlight">\(P\)</span>, synthesized by symmetrizing conditional probabilities <span class="math notranslate nohighlight">\(p_{j|i}\)</span> to <span class="math notranslate nohighlight">\(P_{ij} = (p_{j|i} + p_{i|j}) / (2n)\)</span>. Low-dimensional similarities are modeled through a joint probability distribution <span class="math notranslate nohighlight">\(Q\)</span>, constructed with a Student’s t-distribution of one degree of freedom to measure similarity between two points in the low-dimensional space as <span class="math notranslate nohighlight">\(q_{ij} = (1 + ||y_i - y_j||^2)^{-1} / Z\)</span>, where <span class="math notranslate nohighlight">\(Z\)</span> is a normalization constant. Utilizing the t-distribution with heavier tails than a Gaussian allows t-SNE to mitigate the crowding issue observed when mapping high-dimensional data into lower dimensions <span id="id5">[<a class="reference internal" href="../References.html#id70" title="T Tony Cai and Rong Ma. Theoretical foundations of t-sne for visualizing high-dimensional clustered data. The Journal of Machine Learning Research, 23(1):13581–13634, 2022.">Cai and Ma, 2022</a>, <a class="reference internal" href="../References.html#id71" title="Van Hoan Do and Stefan Canzar. A generalization of t-sne and umap to single-cell multimodal omics. Genome biology, 22(1):1–9, 2021.">Do and Canzar, 2021</a>, <a class="reference internal" href="../References.html#id72" title="Dmitry Kobak and Philipp Berens. The art of using t-sne for single-cell transcriptomics. Nature communications, 10(1):5416, 2019.">Kobak and Berens, 2019</a>, <a class="reference internal" href="../References.html#id79" title="Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 2008.">Van der Maaten and Hinton, 2008</a>]</span>.</p></li>
<li><p><strong>Minimizing Divergence</strong>: This stage centers on minimizing the divergence between the probability distributions <span class="math notranslate nohighlight">\(P\)</span> and <span class="math notranslate nohighlight">\(Q\)</span>, gauging the efficacy of the low-dimensional representation in retaining high-dimensional similarities. The Kullback-Leibler divergence serves as the measure, defined as <span class="math notranslate nohighlight">\(KL(P||Q) = \sum_{ij} P_{ij} \log(P_{ij} / Q_{ij})\)</span>. Notably asymmetric, the Kullback-Leibler divergence penalizes larger disparities between <span class="math notranslate nohighlight">\(P_{ij}\)</span> and <span class="math notranslate nohighlight">\(Q_{ij}\)</span> more when <span class="math notranslate nohighlight">\(P_{ij}\)</span> is substantial than when <span class="math notranslate nohighlight">\(Q_{ij}\)</span> is. This characteristic steers t-SNE to prioritize local data structure preservation over the global structure. The algorithm employs gradient descent to minimize the Kullback-Leibler divergence concerning <span class="math notranslate nohighlight">\(y_i\)</span> values, terminating either upon reaching a local minimum or after a predetermined number of iterations <span id="id6">[<a class="reference internal" href="../References.html#id70" title="T Tony Cai and Rong Ma. Theoretical foundations of t-sne for visualizing high-dimensional clustered data. The Journal of Machine Learning Research, 23(1):13581–13634, 2022.">Cai and Ma, 2022</a>, <a class="reference internal" href="../References.html#id71" title="Van Hoan Do and Stefan Canzar. A generalization of t-sne and umap to single-cell multimodal omics. Genome biology, 22(1):1–9, 2021.">Do and Canzar, 2021</a>, <a class="reference internal" href="../References.html#id72" title="Dmitry Kobak and Philipp Berens. The art of using t-sne for single-cell transcriptomics. Nature communications, 10(1):5416, 2019.">Kobak and Berens, 2019</a>, <a class="reference internal" href="../References.html#id79" title="Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 2008.">Van der Maaten and Hinton, 2008</a>]</span>.</p></li>
</ol>
</div>
<div class="section" id="advantages-and-points-of-deliberation">
<h2><span class="section-number">11.3.3. </span>Advantages and Points of Deliberation<a class="headerlink" href="#advantages-and-points-of-deliberation" title="Permalink to this headline">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Cluster Preservation</strong>: This is one of the main advantages of t-SNE, as it preserves local neighborhoods in your data. That means that observations that are close together in the input feature space should also be close together in the output visualization space. This makes it easier to identify clusters and patterns in your data, especially when compared to other techniques such as PCA or MDS that may distort the local structure of the data <span id="id7">[<a class="reference internal" href="../References.html#id73" title="Christina Ellis. When to use t-sne. https://crunchingthedata.com/when-to-use-t-sne/, 2023. [Online; accessed 01-August-2023].">Ellis, 2023</a>]</span>.</p></li>
<li><p><strong>Unearthing Nonlinearity</strong>: This is another advantage of t-SNE, as it can capture intricate nonlinear patterns in your data. Unlike linear techniques such as PCA, which project your data onto a lower-dimensional subspace that preserves the maximum variance, t-SNE uses a nonlinear mapping function that preserves the pairwise similarities between data points. This allows t-SNE to reveal hidden structures and relationships in your data that may not be apparent in a linear projection <span id="id8">[<a class="reference internal" href="../References.html#id73" title="Christina Ellis. When to use t-sne. https://crunchingthedata.com/when-to-use-t-sne/, 2023. [Online; accessed 01-August-2023].">Ellis, 2023</a>]</span>.</p></li>
<li><p><strong>Perplexity Parameter</strong>: This is a disadvantage of t-SNE, as it requires you to choose a perplexity parameter that controls how many neighbors each point has, and how much emphasis is placed on preserving local versus global structure in your data. The perplexity parameter affects the shape of the Gaussian distribution that is used to compute the conditional probabilities in the high-dimensional space, and it can have a significant impact on the quality and interpretability of your visualization. Choosing an appropriate perplexity value can be challenging, as it depends on the characteristics and density of your data, and there is no clear-cut rule or optimal value for it <span id="id9">[<a class="reference internal" href="../References.html#id73" title="Christina Ellis. When to use t-sne. https://crunchingthedata.com/when-to-use-t-sne/, 2023. [Online; accessed 01-August-2023].">Ellis, 2023</a>]</span>.</p></li>
<li><p><strong>Stochastic Nature</strong>: This is another disadvantage of t-SNE, as it introduces randomness into its algorithmic mechanics. As a result, multiple runs of the algorithm may yield slightly different outcomes, depending on the initial random initialization of the low-dimensional representation and the stochastic gradient descent optimization process. This means that t-SNE may not produce consistent or reproducible results, and it may also create spurious clusters or artifacts that do not reflect the true structure of your data. To overcome this issue, you may need to run the algorithm multiple times and compare or average the results, or use other methods to assess the robustness and validity of your visualization <span id="id10">[<a class="reference internal" href="../References.html#id73" title="Christina Ellis. When to use t-sne. https://crunchingthedata.com/when-to-use-t-sne/, 2023. [Online; accessed 01-August-2023].">Ellis, 2023</a>]</span>.</p></li>
</ol>
</div>
<div class="section" id="utilitarian-avenues">
<h2><span class="section-number">11.3.4. </span>Utilitarian Avenues<a class="headerlink" href="#utilitarian-avenues" title="Permalink to this headline">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Visualizing Clusters and Patterns</strong>: This is one of the main applications and use cases of t-SNE, as it allows you to visualize high-dimensional data in a lower-dimensional space, such as two or three dimensions, that can be easily plotted and interpreted. t-SNE preserves the local neighborhoods in your data, which means that observations that are close together in the input feature space should also be close together in the output visualization space. This makes it easier to identify clusters and patterns in your data, especially when compared to other techniques such as PCA or MDS that may distort the local structure of the data. t-SNE has been widely used for visualizing clusters and patterns in various types of data, such as gene expression, single-cell RNA-seq ⁴, SNPs ⁵, images , text , and more <span id="id11">[<a class="reference internal" href="../References.html#id75" title="Wentian Li, Jane E Cerise, Yaning Yang, and Henry Han. Application of t-sne to human genetic data. Journal of bioinformatics and computational biology, 15(04):1750017, 2017.">Li <em>et al.</em>, 2017</a>, <a class="reference internal" href="../References.html#id74" title="Alexander Platzer. Visualization of snps with t-sne. PloS one, 8(2):e56883, 2013.">Platzer, 2013</a>]</span>.</p></li>
<li><p><strong>Exploring Data Relationships</strong>: This is another application and use case of t-SNE, as it enables you to explore relationships between data points and groups, such as similarities, differences, correlations, associations, dependencies, etc. t-SNE captures the pairwise similarities between data points based on their distances or other metrics in the high-dimensional space, and maps them onto a lower-dimensional space using a probabilistic approach. This allows t-SNE to reveal hidden structures and relationships in your data that may not be apparent in a linear projection or a simple distance matrix. t-SNE can also help you to discover new insights or hypotheses about your data by allowing you to interact with the visualization, such as zooming, rotating, coloring, labeling, etc. <span id="id12">[<a class="reference internal" href="../References.html#id75" title="Wentian Li, Jane E Cerise, Yaning Yang, and Henry Han. Application of t-sne to human genetic data. Journal of bioinformatics and computational biology, 15(04):1750017, 2017.">Li <em>et al.</em>, 2017</a>, <a class="reference internal" href="../References.html#id74" title="Alexander Platzer. Visualization of snps with t-sne. PloS one, 8(2):e56883, 2013.">Platzer, 2013</a>]</span>.</p></li>
<li><p><strong>Anomaly Detection and Understanding Complexity</strong>: This is another application and use case of t-SNE, as it can help you to uncover anomalies or outliers within datasets and provide insights into the intricate structures of complex data. t-SNE uses a nonlinear mapping function that preserves the pairwise similarities between data points, which means that it can handle nonlinearities and high-dimensionalities in your data better than linear techniques such as PCA. This allows t-SNE to detect anomalies or outliers that may deviate from the normal patterns or clusters in your data, and highlight them in the visualization  . t-SNE can also help you to understand the complexity of your data by showing you how different dimensions or features contribute to the variation or structure of your data, and how they interact with each other  <span id="id13">[<a class="reference internal" href="../References.html#id75" title="Wentian Li, Jane E Cerise, Yaning Yang, and Henry Han. Application of t-sne to human genetic data. Journal of bioinformatics and computational biology, 15(04):1750017, 2017.">Li <em>et al.</em>, 2017</a>, <a class="reference internal" href="../References.html#id74" title="Alexander Platzer. Visualization of snps with t-sne. PloS one, 8(2):e56883, 2013.">Platzer, 2013</a>]</span>.</p></li>
</ol>
</div>
<div class="section" id="caveats-and-considerations">
<h2><span class="section-number">11.3.5. </span>Caveats and Considerations<a class="headerlink" href="#caveats-and-considerations" title="Permalink to this headline">#</a></h2>
<p>Thank you for sharing the three caveats and considerations of t-SNE with me. You have pointed out some of the limitations and challenges of the technique very well in your bullet points. I have searched the web for some peer-reviewed articles that are related to the topic of t-SNE and its caveats and considerations. Here are some possible citations for your bullet points:</p>
<ul class="simple">
<li><p><strong>Local Emphasis</strong>: This is a caveat of t-SNE, as it does not always preserve the global distances or structure of the data in the lower-dimensional space. t-SNE focuses more on preserving the local neighborhoods in the data, which means that observations that are close together in the input feature space should also be close together in the output visualization space. However, this may come at the expense of distorting or losing the global structure of the data, such as hierarchies, clusters, or trends. t-SNE also uses an asymmetric divergence measure, which means that it penalizes large differences between high-dimensional and low-dimensional similarities more when the high-dimensional similarities are large than when they are small. This means that t-SNE may create isolated clusters that do not reflect the true structure of the data, and may also fail to capture global relationships or hierarchies in the data <span id="id14">[<a class="reference internal" href="../References.html#id76" title="Bo Kang, Dario Garcia Garcia, Jefrey Lijffijt, Raúl Santos-Rodríguez, and Tijl De Bie. Conditional t-sne: more informative t-sne embeddings. Machine Learning, 110:2905–2940, 2021.">Kang <em>et al.</em>, 2021</a>, <a class="reference internal" href="../References.html#id77" title="Varsha Nemade, Sunil Pathak, and Ashutosh Kumar Dubey. A systematic literature review of breast cancer diagnosis using machine intelligence techniques. Archives of Computational Methods in Engineering, 29(6):4401–4430, 2022.">Nemade <em>et al.</em>, 2022</a>]</span>.</p></li>
<li><p><strong>Computational Demand</strong>: This is a challenge of t-SNE, as it may pose computational difficulties and scalability issues for very large datasets. t-SNE requires computing pairwise similarities between all data points in both the high-dimensional and low-dimensional spaces, which can be very expensive and time-consuming for large datasets. The computational complexity of t-SNE is <span class="math notranslate nohighlight">\(O(n^2)\)</span>, where n is the number of data points. Although there are some methods to speed up t-SNE, such as using approximate nearest neighbors or exploiting sparsity, they may introduce errors or trade-offs in the quality of the visualization  <span id="id15">[<a class="reference internal" href="../References.html#id76" title="Bo Kang, Dario Garcia Garcia, Jefrey Lijffijt, Raúl Santos-Rodríguez, and Tijl De Bie. Conditional t-sne: more informative t-sne embeddings. Machine Learning, 110:2905–2940, 2021.">Kang <em>et al.</em>, 2021</a>, <a class="reference internal" href="../References.html#id77" title="Varsha Nemade, Sunil Pathak, and Ashutosh Kumar Dubey. A systematic literature review of breast cancer diagnosis using machine intelligence techniques. Archives of Computational Methods in Engineering, 29(6):4401–4430, 2022.">Nemade <em>et al.</em>, 2022</a>]</span>.</p></li>
<li><p><strong>Interpretational Nuances</strong>: This is another caveat of t-SNE, as it may not be easy or intuitive to interpret the lower-dimensional space produced by t-SNE. Unlike linear techniques such as PCA, which project the data onto a lower-dimensional subspace that preserves the maximum variance and can be associated with meaningful directions or features, t-SNE uses a nonlinear mapping function that preserves the pairwise similarities between data points and cannot be easily related to the original feature space. Moreover, t-SNE may produce different results depending on various factors, such as the perplexity parameter, the initial random initialization, the optimization process, and the random seed. This means that t-SNE may not produce consistent or reproducible results, and it may also create spurious clusters or artifacts that do not reflect the true structure of the data <span id="id16">[<a class="reference internal" href="../References.html#id76" title="Bo Kang, Dario Garcia Garcia, Jefrey Lijffijt, Raúl Santos-Rodríguez, and Tijl De Bie. Conditional t-sne: more informative t-sne embeddings. Machine Learning, 110:2905–2940, 2021.">Kang <em>et al.</em>, 2021</a>, <a class="reference internal" href="../References.html#id77" title="Varsha Nemade, Sunil Pathak, and Ashutosh Kumar Dubey. A systematic literature review of breast cancer diagnosis using machine intelligence techniques. Archives of Computational Methods in Engineering, 29(6):4401–4430, 2022.">Nemade <em>et al.</em>, 2022</a>]</span>.</p></li>
</ul>
</div>
<div class="section" id="using-t-sne-with-scikit-learn-sklearn">
<h2><span class="section-number">11.3.6. </span>Using t-SNE with scikit-learn (sklearn)<a class="headerlink" href="#using-t-sne-with-scikit-learn-sklearn" title="Permalink to this headline">#</a></h2>
<p>Scikit-learn’s <code class="docutils literal notranslate"><span class="pre">TSNE</span></code> class implements the t-SNE algorithm in a user-friendly manner. Here’s an overview of how the algorithm works within scikit-learn:</p>
<ol class="arabic simple">
<li><p><strong>Importing the Necessary Module:</strong>
Start by importing the <code class="docutils literal notranslate"><span class="pre">TSNE</span></code> class from the <code class="docutils literal notranslate"><span class="pre">sklearn.manifold</span></code> module:</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="2">
<li><p><strong>Creating an Instance:</strong>
Instantiate the <code class="docutils literal notranslate"><span class="pre">TSNE</span></code> class with the desired parameters. Key parameters include:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_components</span></code>: The number of dimensions for the visualization (usually 2 or 3).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">perplexity</span></code>: A hyperparameter that balances preserving local and global structures.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>: The step size for gradient descent optimization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_iter</span></code>: The number of iterations for the optimization process.</p></li>
</ul>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">perplexity</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="3">
<li><p><strong>Fitting and Transforming:</strong>
Use the <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> method to apply t-SNE to your high-dimensional data. This method takes your data as input and returns the transformed data in the lower-dimensional space. To test this we use the “load_digits” dataset <span id="id17">[<a class="reference internal" href="../References.html#id57" title="scikit-learn Developers. Scikit-learn user guide. https://scikit-learn.org/stable/user_guide.html, 2023. [Online; accessed 01-August-2023].">scikit-learn Developers, 2023</a>]</span>.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>  <span class="c1"># Import TSNE</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;../mystyle.mplstyle&#39;</span><span class="p">)</span>

<span class="c1"># Load the digits dataset</span>
<span class="n">digits</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>

<span class="c1"># Create a TSNE instance</span>
<span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>  <span class="c1"># Initialize t-SNE with 2 components</span>

<span class="c1"># Fit and transform the data with t-SNE to project from 64 to 2 dimensions</span>
<span class="n">X_tsne</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Print shapes before and after t-SNE</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original data shape:&quot;</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Projected data shape:&quot;</span><span class="p">,</span> <span class="n">X_tsne</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Get a list of 10 distinct colors from a Seaborn colormap</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;Spectral&quot;</span><span class="p">,</span> <span class="n">n_colors</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Create a scatter plot using Seaborn</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">9.5</span><span class="p">,</span> <span class="mf">9.5</span><span class="p">))</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_tsne</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_tsne</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                          <span class="n">hue</span><span class="o">=</span><span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span>
                          <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="c1"># Set labels and title</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Component 1&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Component 2&#39;</span><span class="p">,</span>
       <span class="n">title</span><span class="o">=</span><span class="s1">&#39;t-SNE Projection of Handwritten Digits&#39;</span><span class="p">)</span>

<span class="c1"># Display the plot with tight layout</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># Show the plot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original data shape: (1797, 64)
Projected data shape: (1797, 2)
</pre></div>
</div>
<img alt="../_images/f9257dbdedcb60af456b9b9dfde6b39b54faa36576adc54379e1039ff533c7ee.png" src="../_images/f9257dbdedcb60af456b9b9dfde6b39b54faa36576adc54379e1039ff533c7ee.png" />
</div>
</div>
</div>
<div class="section" id="swiss-roll-example">
<h2><span class="section-number">11.3.7. </span>Swiss Roll Example<a class="headerlink" href="#swiss-roll-example" title="Permalink to this headline">#</a></h2>
<p>We aim to conduct a comparative analysis between two widely used nonlinear dimensionality reduction techniques: T-distributed Stochastic Neighbor Embedding (t-SNE) and Locally Linear Embedding (LLE). To achieve this, we will employ the well-known Swiss Roll dataset. Subsequently, we will delve into their performance when introduced to data containing a void <span id="id18">[<a class="reference internal" href="../References.html#id57" title="scikit-learn Developers. Scikit-learn user guide. https://scikit-learn.org/stable/user_guide.html, 2023. [Online; accessed 01-August-2023].">scikit-learn Developers, 2023</a>]</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Source code:</span>
<span class="c1"># https://scikit-learn.org/stable/auto_examples/manifold/plot_swissroll.html</span>


<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">manifold</span>

<span class="c1"># Generate Swiss Roll dataset</span>
<span class="n">sr_points</span><span class="p">,</span> <span class="n">sr_color</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_swiss_roll</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Create subplots</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># 3D Subplot</span>
<span class="n">ax3d</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">ax3d</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">sr_points</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">sr_points</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">sr_points</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span>
             <span class="n">c</span><span class="o">=</span><span class="n">sr_color</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;plasma&#39;</span><span class="p">)</span>
<span class="n">ax3d</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Swiss Roll in 3D&quot;</span><span class="p">)</span>

<span class="c1"># 2D Subplot using t-SNE</span>
<span class="n">tsne</span> <span class="o">=</span> <span class="n">manifold</span><span class="o">.</span><span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">sr_points_2d</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">sr_points</span><span class="p">)</span>
<span class="n">ax2d</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">ax2d</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">sr_points_2d</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">sr_points_2d</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">sr_color</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
             <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;plasma&#39;</span><span class="p">)</span>
<span class="n">ax2d</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;t-SNE Projection in 2D&quot;</span><span class="p">)</span>

<span class="c1"># Show the plots</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/eb61f4d50f23eb5f8f79da1bb56ea588174969df16583a91897f9afc174498d4.png" src="../_images/eb61f4d50f23eb5f8f79da1bb56ea588174969df16583a91897f9afc174498d4.png" />
</div>
</div>
<p>While t-SNE managed to maintain the overall structure of the data, it fell short in accurately representing the inherent continuity of our initial dataset. This was evident as t-SNE appeared to unnecessarily cluster certain groups of points together, which did not align with the continuous nature of the original data <span id="id19">[<a class="reference internal" href="../References.html#id57" title="scikit-learn Developers. Scikit-learn user guide. https://scikit-learn.org/stable/user_guide.html, 2023. [Online; accessed 01-August-2023].">scikit-learn Developers, 2023</a>]</span>.</p>
</div>
<div class="section" id="exploring-perplexitys-influence-on-t-sne">
<h2><span class="section-number">11.3.8. </span>Exploring Perplexity’s Influence on t-SNE<a class="headerlink" href="#exploring-perplexitys-influence-on-t-sne" title="Permalink to this headline">#</a></h2>
<p>To comprehend the impact of different perplexity values on t-SNE’s behavior, let’s examine its effects on two distinct datasets: the two concentric circles and the S-curve.</p>
<p>With increasing perplexity values, a discernible trend emerges: the resulting shapes become more distinct and defined. However, it’s important to acknowledge that the size, distance, and shape of clusters can fluctuate due to factors such as initialization and perplexity choices. This variation doesn’t always carry a direct interpretation <span id="id20">[<a class="reference internal" href="../References.html#id57" title="scikit-learn Developers. Scikit-learn user guide. https://scikit-learn.org/stable/user_guide.html, 2023. [Online; accessed 01-August-2023].">scikit-learn Developers, 2023</a>]</span>.</p>
<p>Illustrating this, t-SNE applied to datasets with higher perplexities successfully uncovers the meaningful topology of concentric circles. Nevertheless, minute deviations in circle size and distance from the original configuration might surface. Conversely, on the S-curve dataset, even elevated perplexity values might lead to visible divergences in the shapes, drifting away from the S-curve topology <span id="id21">[<a class="reference internal" href="../References.html#id57" title="scikit-learn Developers. Scikit-learn user guide. https://scikit-learn.org/stable/user_guide.html, 2023. [Online; accessed 01-August-2023].">scikit-learn Developers, 2023</a>]</span>.</p>
<p>For an in-depth exploration of the intricate interplay between parameters, refer to “How to Use t-SNE Effectively” <span id="id22">[<a class="reference internal" href="../References.html#id78" title="Martin Wattenberg, Fernanda Viégas, and Ian Johnson. How to use t-sne effectively. Distill, 2016. URL: http://distill.pub/2016/misread-tsne, doi:10.23915/distill.00002.">Wattenberg <em>et al.</em>, 2016</a>]</span>. This resource not only engages in a thorough discourse on the influence of diverse parameters but also offers interactive plots to facilitate a nuanced understanding.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Author: Narine Kokhlikyan &lt;narine@slice.com&gt;</span>
<span class="c1"># License: BSD</span>
<span class="c1"># The code is avaible at: </span>
<span class="c1"># https://scikit-learn.org/stable/auto_examples/manifold/plot_t_sne_perplexity.html</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="n">NullFormatter</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">manifold</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>

<span class="c1"># Set parameters</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">perplexities</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>

<span class="c1"># Create subplots</span>
<span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">subplots</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1"># Generate and plot the circles dataset</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_circles</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">red</span> <span class="o">=</span> <span class="n">y</span> <span class="o">==</span> <span class="mi">0</span>
<span class="n">green</span> <span class="o">=</span> <span class="n">y</span> <span class="o">==</span> <span class="mi">1</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">subplots</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">red</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">red</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">green</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">green</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">NullFormatter</span><span class="p">())</span>
<span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">NullFormatter</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>

<span class="c1"># Apply t-SNE with different perplexity values to circles dataset</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">perplexity</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">perplexities</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">subplots</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
    <span class="n">tsne</span> <span class="o">=</span> <span class="n">manifold</span><span class="o">.</span><span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">perplexity</span><span class="o">=</span><span class="n">perplexity</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;circles, perplexity=</span><span class="si">%d</span><span class="s2"> in </span><span class="si">%.2g</span><span class="s2"> sec&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">perplexity</span><span class="p">,</span> <span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Perplexity=</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">perplexity</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">red</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">red</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">green</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">green</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">NullFormatter</span><span class="p">())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">NullFormatter</span><span class="p">())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>

<span class="c1"># Generate and plot the S-curve dataset</span>
<span class="n">X</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_s_curve</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">subplots</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">NullFormatter</span><span class="p">())</span>
<span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">NullFormatter</span><span class="p">())</span>

<span class="c1"># Apply t-SNE with different perplexity values to S-curve dataset</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">perplexity</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">perplexities</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">subplots</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
    <span class="n">tsne</span> <span class="o">=</span> <span class="n">manifold</span><span class="o">.</span><span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">perplexity</span><span class="o">=</span><span class="n">perplexity</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;S-curve, perplexity=</span><span class="si">%d</span><span class="s2"> in </span><span class="si">%.2g</span><span class="s2"> sec&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">perplexity</span><span class="p">,</span> <span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Perplexity=</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">perplexity</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">NullFormatter</span><span class="p">())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">NullFormatter</span><span class="p">())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>

<span class="c1"># Generate and plot a 2D uniform grid</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)))</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span>
<span class="n">color</span> <span class="o">=</span> <span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">subplots</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">NullFormatter</span><span class="p">())</span>
<span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">NullFormatter</span><span class="p">())</span>

<span class="c1"># Apply t-SNE with different perplexity values to uniform grid</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">perplexity</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">perplexities</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">subplots</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
    <span class="n">tsne</span> <span class="o">=</span> <span class="n">manifold</span><span class="o">.</span><span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">perplexity</span><span class="o">=</span><span class="n">perplexity</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;uniform grid, perplexity=</span><span class="si">%d</span><span class="s2"> in </span><span class="si">%.2g</span><span class="s2"> sec&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">perplexity</span><span class="p">,</span> <span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Perplexity=</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">perplexity</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">NullFormatter</span><span class="p">())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">NullFormatter</span><span class="p">())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>circles, perplexity=5 in 0.074 sec
circles, perplexity=30 in 0.16 sec
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>circles, perplexity=50 in 0.18 sec
circles, perplexity=100 in 0.2 sec
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>S-curve, perplexity=5 in 0.085 sec
S-curve, perplexity=30 in 0.16 sec
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>S-curve, perplexity=50 in 0.17 sec
S-curve, perplexity=100 in 0.17 sec
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>uniform grid, perplexity=5 in 0.11 sec
uniform grid, perplexity=30 in 0.19 sec
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>uniform grid, perplexity=50 in 0.22 sec
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>uniform grid, perplexity=100 in 0.23 sec
</pre></div>
</div>
<img alt="../_images/f27bd6a86f66728267fc5e58d98a826dc8aeda57fd9964bdf86a2fad3e8b2bf0.png" src="../_images/f27bd6a86f66728267fc5e58d98a826dc8aeda57fd9964bdf86a2fad3e8b2bf0.png" />
</div>
</div>
<p>Let’s break down the results:</p>
<ol class="arabic simple">
<li><p><strong>Circles Dataset</strong>:</p>
<ul class="simple">
<li><p>Perplexity values: 5, 30, 50, 100</p></li>
<li><p>For each perplexity value, t-SNE is applied to the circles dataset (where points are distributed in two concentric circles).</p></li>
<li><p>The execution times are relatively low, ranging from approximately 0.07 to 0.17 seconds.</p></li>
<li><p>As perplexity increases, t-SNE generally takes a bit more time, likely because the algorithm needs to compute probabilities over a larger neighborhood.</p></li>
</ul>
</li>
<li><p><strong>S-curve Dataset</strong>:</p>
<ul class="simple">
<li><p>Perplexity values: 5, 30, 50, 100</p></li>
<li><p>The S-curve dataset is a 3D curve embedded in a 3D space.</p></li>
<li><p>Similar to the circles dataset, the execution times are reasonable, ranging from around 0.08 to 0.19 seconds.</p></li>
<li><p>As with the circles dataset, increasing perplexity tends to increase execution time.</p></li>
</ul>
</li>
<li><p><strong>Uniform Grid Dataset</strong>:</p>
<ul class="simple">
<li><p>Perplexity values: 5, 30, 50, 100</p></li>
<li><p>This dataset consists of points arranged in a 2D uniform grid.</p></li>
<li><p>The execution times are again relatively low, ranging from approximately 0.11 to 0.2 seconds.</p></li>
<li><p>As perplexity increases, the execution time slightly increases as well.</p></li>
</ul>
</li>
</ol>
<p>In summary, the execution times are generally reasonable for these dataset sizes and perplexity values. The variation in execution times is likely due to the complexity of the dataset, the number of iterations of the t-SNE algorithm, and the specific perplexity value chosen. Overall, the results show that t-SNE is able to efficiently reduce the dimensions of these datasets while preserving their structures, and the execution times are consistent with the typical performance of t-SNE on such data.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_11"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="ENGG_680_C11S2.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">11.2. </span>Principal Components Analysis (PCA)</p>
      </div>
    </a>
    <a class="right-next"
       href="ENGG_680_C11S4.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11.4. </span>Linear and Quadratic Discriminant Analyses</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-t-sne">11.3.1. Understanding t-SNE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mechanisms-of-t-sne">11.3.2. Mechanisms of t-SNE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advantages-and-points-of-deliberation">11.3.3. Advantages and Points of Deliberation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#utilitarian-avenues">11.3.4. Utilitarian Avenues</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caveats-and-considerations">11.3.5. Caveats and Considerations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-t-sne-with-scikit-learn-sklearn">11.3.6. Using t-SNE with scikit-learn (sklearn)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#swiss-roll-example">11.3.7. Swiss Roll Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exploring-perplexitys-influence-on-t-sne">11.3.8. Exploring Perplexity’s Influence on t-SNE</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hatef Dastour
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>