

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>11.5. Recursive Feature Elimination (RFE) &#8212; Introduction to Digital Engineering</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_11/ENGG_680_C11S5';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="11.6. Practical Considerations in Dimensionality Reduction" href="ENGG_680_C11S6.html" />
    <link rel="prev" title="11.4. Linear and Quadratic Discriminant Analyses" href="ENGG_680_C11S4.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../Introduction.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_01/ReadMe.html">1. Introduction to Python Programming</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S1.html">1.1. Variable names, Expressions and statements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S2.html">1.2. Fundamental Concepts and Operations in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S3.html">1.3. Functions</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_02/ReadMe.html">2. Control Flow: Conditionals, Recursion, and Iteration</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG_680_C02S1.html">2.1. Conditionals and recursion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG_680_C02S2.html">2.2. Iteration</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_03/ReadMe.html">3. Data Structures and File Handling in Python</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S1.html">3.1. Strings in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S2.html">3.2. Python Lists</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S3.html">3.3. Python Dictionaries: Key-Value Pairs in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S4.html">3.4. Python Tuples: Immutable Sequences in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S5.html">3.5. Python Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S6.html">3.6. Files in Python (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_04/ReadMe.html">4. Classes and Objects</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S1.html">4.1. Introduction to Classes and Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S2.html">4.2. Inheritance and Polymorphism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S3.html">4.3. Encapsulation and Abstraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S4.html">4.4. Copying Objects (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S5.html">4.5. Magic Methods (Dunder Methods) in Python (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S6.html">4.6. Examples of Classes (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_05/ReadMe.html">5. Introduction to NumPy</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S1.html">5.1. Basics of Numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S2.html">5.2. NumPy Function Reference and Usage Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S3.html">5.3. Advanced Numpy Concepts (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_06/ReadMe.html">6. Working with Data using Pandas</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S1.html">6.1. An Introduction to Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S2.html">6.2. DataFrame and Series Indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S3.html">6.3. Pandas Data Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S4.html">6.4. Handling Missing Data in Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S5.html">6.5. Combining Datasets using Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S6.html">6.6. Aggregation and Grouping in Pandas</a></li>

</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_07/ReadMe.html">7. Data Visualization using Python</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S1.html">7.1. Getting started with Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S2.html">7.2. Matplotlib Styles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S3.html">7.3. Matplotlib interfaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S4.html">7.4. Adjusting the Plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S5.html">7.5. Seaborn plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S6.html">7.6. Python Plotting Guide</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_08/ReadMe.html">8. An Introduction to Computer Vision</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S1.html">8.1. Getting Started with OpenCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S2.html">8.2. Geometric Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S3.html">8.3. Image Thresholding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S4.html">8.4. Image Filtering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S5.html">8.5. Drawing Functions (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S6.html">8.6. Morphological Transformations (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_09/ReadMe.html">9. An Introduction to Machine Learning</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S1.html">9.1. Statistical Metrics and Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S2.html">9.2. An Introduction to Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S3.html">9.3. Multiple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S4.html">9.4. Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S5.html">9.5. K-Nearest Neighbors (K-NN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S6.html">9.6. Resampling Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S7.html">9.7. Support Vector Machines</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_10/ReadMe.html">10. Tree-Based Methods</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S1.html">10.1. Fundamental Structure of Decision Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S2.html">10.2. Regression Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S3.html">10.3. Classification Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S4.html">10.4. Regression Trees and Linear Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S5.html">10.5. Enhancing Decision Trees with Bagging: An Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S6.html">10.6. Random Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S7.html">10.7. Gradient Boosting</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="ReadMe.html">11. Dimensionality Reduction and Feature Selection</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C11S1.html">11.1. Introduction to Dimensionality Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C11S2.html">11.2. Principal Components Analysis (PCA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C11S3.html">11.3. t-Distributed Stochastic Neighbor Embedding (t-SNE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C11S4.html">11.4. Linear and Quadratic Discriminant Analyses</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">11.5. Recursive Feature Elimination (RFE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C11S6.html">11.6. Practical Considerations in Dimensionality Reduction</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_12/ReadMe.html">12. Introduction to Deep Learning</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S1.html">12.1. Understanding Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S2.html">12.2. Fundamentals of Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S3.html">12.3. Tensors and Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S4.html">12.4. Building a linear Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S5.html">12.5. Building a Logistic Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S6.html">12.6. Multilayer Perceptron (MLP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S7.html">12.7. Image classification with TensorFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S8.html">12.8. Image Augmentations with TensorFlow</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../appendixes/ReadMe.html">13. Appendices</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendixes/SampleQuestions_1.html">13.1. Sample Questions 1</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../References.html">14. References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Recursive Feature Elimination (RFE)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-feature-importance-and-rfe-rankings">11.5.1. Visualizing Feature Importance and RFE Rankings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-many-features-to-select">11.5.2. How many Features to select?</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="tex2jax_ignore mathjax_ignore section" id="recursive-feature-elimination-rfe">
<h1><span class="section-number">11.5. </span>Recursive Feature Elimination (RFE)<a class="headerlink" href="#recursive-feature-elimination-rfe" title="Permalink to this headline">#</a></h1>
<p>Recursive Feature Elimination (RFE) is a feature selection technique commonly used in machine learning to select the most relevant features from a given dataset. It aims to improve model performance by iteratively removing the least important features and evaluating the model’s performance after each removal. The process continues until a predefined number of features is reached <span id="id1">[<a class="reference internal" href="../References.html#id91" title="J. Brownlee. Data Preparation for Machine Learning: Data Cleaning, Feature Selection, and Data Transforms in Python. Machine Learning Mastery, 2020. URL: https://books.google.ca/books?id=uAPuDwAAQBAJ.">Brownlee, 2020</a>, <a class="reference internal" href="../References.html#id89" title="Isabelle Guyon and André Elisseeff. An introduction to variable and feature selection. Journal of machine learning research, 3(Mar):1157–1182, 2003.">Guyon and Elisseeff, 2003</a>, <a class="reference internal" href="../References.html#id90" title="M. Kuhn and K. Johnson. Feature Engineering and Selection: A Practical Approach for Predictive Models. Chapman &amp; Hall/CRC Data Science Series. CRC Press, 2019. ISBN 9781351609463. URL: https://books.google.ca/books?id=q5alDwAAQBAJ.">Kuhn and Johnson, 2019</a>]</span>.</p>
<p>Let’s assume we have:</p>
<ul class="simple">
<li><p>Dataset: <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{N \times M}\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the number of samples and <span class="math notranslate nohighlight">\(M\)</span> is the number of features.</p></li>
<li><p>Target: <span class="math notranslate nohighlight">\(y \in \mathbb{R}^{N}\)</span>.</p></li>
<li><p>Model: <span class="math notranslate nohighlight">\(f(\mathbf{w}, \mathbf{x})\)</span> represents the chosen machine learning model with parameters <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>.</p></li>
<li><p>Importance scores: <span class="math notranslate nohighlight">\(\mathbf{s} \in \mathbb{R}^{M}\)</span> represents the importance scores for each feature.</p></li>
</ul>
<ol class="arabic simple">
<li><p><strong>Model Training and Importance Scores Calculation</strong>:</p>
<ul class="simple">
<li><p>Train the model <span class="math notranslate nohighlight">\(f\)</span> on the entire dataset <span class="math notranslate nohighlight">\(X\)</span> to learn the parameters <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>.</p></li>
<li><p>Calculate the importance scores for each feature using some method specific to the model. For example, in linear regression, importance scores might be the absolute values of the feature coefficients, while in tree-based models, it could be computed using feature importance scores.</p></li>
</ul>
</li>
<li><p><strong>Identify and Remove Feature</strong>:</p>
<ul class="simple">
<li><p>Identify the index <span class="math notranslate nohighlight">\(i\)</span> of the feature with the lowest importance score: <span class="math notranslate nohighlight">\(i = \arg \min_{j}(\mathbf{s}[j])\)</span>.</p></li>
<li><p>Remove the feature at index <span class="math notranslate nohighlight">\(i\)</span> from the dataset <span class="math notranslate nohighlight">\(X\)</span> to obtain <span class="math notranslate nohighlight">\(X'\)</span>, where <span class="math notranslate nohighlight">\(X' \in \mathbb{R}^{N \times (M-1)}\)</span>.</p></li>
<li><p>Adjust the importance scores array <span class="math notranslate nohighlight">\(\mathbf{s}\)</span> by removing the element at index <span class="math notranslate nohighlight">\(i\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Retrain Model</strong>:</p>
<ul class="simple">
<li><p>Retrain the model <span class="math notranslate nohighlight">\(f\)</span> using the modified dataset <span class="math notranslate nohighlight">\(X'\)</span> to adapt to the reduced feature set.</p></li>
<li><p>The updated model <span class="math notranslate nohighlight">\(f\)</span> will have updated parameters <span class="math notranslate nohighlight">\(\mathbf{w}'\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Repeat Process</strong>:</p>
<ul class="simple">
<li><p>Repeat steps 1-3 iteratively until you reach the desired number of features to keep or another stopping criterion.</p></li>
</ul>
</li>
<li><p><strong>Final Model</strong>:</p>
<ul class="simple">
<li><p>The final model is the one obtained after the iterative process is completed. It’s trained on the selected subset of features.</p></li>
</ul>
</li>
</ol>
<p>The mathematics in this process primarily involves the operations associated with training the model, calculating importance scores, identifying the minimum importance score, removing features, and updating the model parameters. The specific mathematical equations and expressions will depend on the chosen machine learning model, the method used to calculate importance scores, and the dataset’s structure.</p>
<p>Keep in mind that the mathematical expressions can vary based on the model and approach used, so the details provided here are a general guide to understanding the process.</p>
<div class="admonition-recursive-feature-elimination-rfe-algorithm admonition">
<p class="admonition-title">Recursive Feature Elimination (RFE) Algorithm</p>
<p>Refined Explanation of Recursive Feature Elimination (RFE) in Feature Selection:</p>
<ol class="arabic simple">
<li><p><strong>Input</strong>:</p>
<ul class="simple">
<li><p><strong>Training Data</strong>: The initial dataset containing feature matrix <span class="math notranslate nohighlight">\(X\)</span> (comprising the input features) and target vector <span class="math notranslate nohighlight">\(y\)</span> (consisting of corresponding target values).</p></li>
<li><p><strong>Machine Learning Estimator</strong>: This refers to the chosen predictive model, such as linear regression or support vector machine, that will be employed for feature selection.</p></li>
</ul>
</li>
<li><p><strong>Initialization</strong>:</p>
<ul class="simple">
<li><p>Determine the number of features to retain, denoted as <span class="math notranslate nohighlight">\(k\)</span>, or decide the level of improvement in model performance you seek to achieve.</p></li>
<li><p>Initialize the Recursive Feature Elimination (RFE) process with all the available features.</p></li>
</ul>
</li>
<li><p><strong>Model Training and Importance Score Calculation</strong>:</p>
<ul class="simple">
<li><p>Train the selected machine learning estimator using the training data <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(y\)</span>.</p></li>
<li><p>Compute feature importance scores, which quantify the significance of each feature in contributing to the model’s predictive performance. The approach to obtaining these scores varies based on the type of estimator utilized. For linear models, importance could be inferred from absolute feature coefficients, whereas tree-based models might yield feature importance scores.</p></li>
</ul>
</li>
<li><p><strong>Feature Ranking and Elimination</strong>:</p>
<ul class="simple">
<li><p>Identify the feature with the lowest importance score and eliminate it from the current feature set.</p></li>
<li><p>Update the training data to comprise only the remaining features.</p></li>
<li><p>Re-train the machine learning estimator using the reduced feature set.</p></li>
</ul>
</li>
<li><p><strong>Performance Evaluation</strong>:</p>
<ul class="simple">
<li><p>Assess the performance of the estimator by employing either a validation set or cross-validation methodology with the newly formed, reduced feature set.</p></li>
<li><p>Monitor the chosen performance metric (e.g., accuracy, mean squared error) attained using the current subset of features.</p></li>
</ul>
</li>
<li><p><strong>Stopping Criterion</strong>:</p>
<ul class="simple">
<li><p>Check if the predetermined number of features (<span class="math notranslate nohighlight">\(k\)</span>) has been reached or if the desired level of performance enhancement has been attained. If either condition is met, terminate the process. If not, proceed to step 3.</p></li>
</ul>
</li>
<li><p><strong>Final Model</strong>:</p>
<ul class="simple">
<li><p>The ultimate selection of features consists of those that remain after the completion of the RFE process.</p></li>
<li><p>Train the machine learning estimator using the complete training dataset, but only with the features that were selected through RFE. This final model incorporates the most relevant features while potentially disregarding less significant ones.</p></li>
</ul>
</li>
</ol>
<p>Recursive Feature Elimination is an iterative procedure that systematically identifies and excludes the least important features. By iteratively repeating the steps and continually updating the feature set, RFE aims to enhance the model’s performance and potentially improve its generalization capability.</p>
</div>
<p><font color='Blue'><b>Example:</b></font> In this Example, we utilize the UCI ML Breast Cancer Wisconsin (Diagnostic) dataset to explain the application of Recursive Feature Elimination (RFE).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="c1"># Load the breast cancer dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_breast_cancer</span><span class="p">()</span>

<span class="c1"># Create a Pandas DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>

<span class="c1"># Display the DataFrame</span>
<span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Print dataset description</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;DESCR&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean radius</th>
      <th>mean texture</th>
      <th>mean perimeter</th>
      <th>mean area</th>
      <th>mean smoothness</th>
      <th>mean compactness</th>
      <th>mean concavity</th>
      <th>mean concave points</th>
      <th>mean symmetry</th>
      <th>mean fractal dimension</th>
      <th>...</th>
      <th>worst radius</th>
      <th>worst texture</th>
      <th>worst perimeter</th>
      <th>worst area</th>
      <th>worst smoothness</th>
      <th>worst compactness</th>
      <th>worst concavity</th>
      <th>worst concave points</th>
      <th>worst symmetry</th>
      <th>worst fractal dimension</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17.99</td>
      <td>10.38</td>
      <td>122.80</td>
      <td>1001.0</td>
      <td>0.11840</td>
      <td>0.27760</td>
      <td>0.30010</td>
      <td>0.14710</td>
      <td>0.2419</td>
      <td>0.07871</td>
      <td>...</td>
      <td>25.380</td>
      <td>17.33</td>
      <td>184.60</td>
      <td>2019.0</td>
      <td>0.16220</td>
      <td>0.66560</td>
      <td>0.7119</td>
      <td>0.2654</td>
      <td>0.4601</td>
      <td>0.11890</td>
    </tr>
    <tr>
      <th>1</th>
      <td>20.57</td>
      <td>17.77</td>
      <td>132.90</td>
      <td>1326.0</td>
      <td>0.08474</td>
      <td>0.07864</td>
      <td>0.08690</td>
      <td>0.07017</td>
      <td>0.1812</td>
      <td>0.05667</td>
      <td>...</td>
      <td>24.990</td>
      <td>23.41</td>
      <td>158.80</td>
      <td>1956.0</td>
      <td>0.12380</td>
      <td>0.18660</td>
      <td>0.2416</td>
      <td>0.1860</td>
      <td>0.2750</td>
      <td>0.08902</td>
    </tr>
    <tr>
      <th>2</th>
      <td>19.69</td>
      <td>21.25</td>
      <td>130.00</td>
      <td>1203.0</td>
      <td>0.10960</td>
      <td>0.15990</td>
      <td>0.19740</td>
      <td>0.12790</td>
      <td>0.2069</td>
      <td>0.05999</td>
      <td>...</td>
      <td>23.570</td>
      <td>25.53</td>
      <td>152.50</td>
      <td>1709.0</td>
      <td>0.14440</td>
      <td>0.42450</td>
      <td>0.4504</td>
      <td>0.2430</td>
      <td>0.3613</td>
      <td>0.08758</td>
    </tr>
    <tr>
      <th>3</th>
      <td>11.42</td>
      <td>20.38</td>
      <td>77.58</td>
      <td>386.1</td>
      <td>0.14250</td>
      <td>0.28390</td>
      <td>0.24140</td>
      <td>0.10520</td>
      <td>0.2597</td>
      <td>0.09744</td>
      <td>...</td>
      <td>14.910</td>
      <td>26.50</td>
      <td>98.87</td>
      <td>567.7</td>
      <td>0.20980</td>
      <td>0.86630</td>
      <td>0.6869</td>
      <td>0.2575</td>
      <td>0.6638</td>
      <td>0.17300</td>
    </tr>
    <tr>
      <th>4</th>
      <td>20.29</td>
      <td>14.34</td>
      <td>135.10</td>
      <td>1297.0</td>
      <td>0.10030</td>
      <td>0.13280</td>
      <td>0.19800</td>
      <td>0.10430</td>
      <td>0.1809</td>
      <td>0.05883</td>
      <td>...</td>
      <td>22.540</td>
      <td>16.67</td>
      <td>152.20</td>
      <td>1575.0</td>
      <td>0.13740</td>
      <td>0.20500</td>
      <td>0.4000</td>
      <td>0.1625</td>
      <td>0.2364</td>
      <td>0.07678</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>564</th>
      <td>21.56</td>
      <td>22.39</td>
      <td>142.00</td>
      <td>1479.0</td>
      <td>0.11100</td>
      <td>0.11590</td>
      <td>0.24390</td>
      <td>0.13890</td>
      <td>0.1726</td>
      <td>0.05623</td>
      <td>...</td>
      <td>25.450</td>
      <td>26.40</td>
      <td>166.10</td>
      <td>2027.0</td>
      <td>0.14100</td>
      <td>0.21130</td>
      <td>0.4107</td>
      <td>0.2216</td>
      <td>0.2060</td>
      <td>0.07115</td>
    </tr>
    <tr>
      <th>565</th>
      <td>20.13</td>
      <td>28.25</td>
      <td>131.20</td>
      <td>1261.0</td>
      <td>0.09780</td>
      <td>0.10340</td>
      <td>0.14400</td>
      <td>0.09791</td>
      <td>0.1752</td>
      <td>0.05533</td>
      <td>...</td>
      <td>23.690</td>
      <td>38.25</td>
      <td>155.00</td>
      <td>1731.0</td>
      <td>0.11660</td>
      <td>0.19220</td>
      <td>0.3215</td>
      <td>0.1628</td>
      <td>0.2572</td>
      <td>0.06637</td>
    </tr>
    <tr>
      <th>566</th>
      <td>16.60</td>
      <td>28.08</td>
      <td>108.30</td>
      <td>858.1</td>
      <td>0.08455</td>
      <td>0.10230</td>
      <td>0.09251</td>
      <td>0.05302</td>
      <td>0.1590</td>
      <td>0.05648</td>
      <td>...</td>
      <td>18.980</td>
      <td>34.12</td>
      <td>126.70</td>
      <td>1124.0</td>
      <td>0.11390</td>
      <td>0.30940</td>
      <td>0.3403</td>
      <td>0.1418</td>
      <td>0.2218</td>
      <td>0.07820</td>
    </tr>
    <tr>
      <th>567</th>
      <td>20.60</td>
      <td>29.33</td>
      <td>140.10</td>
      <td>1265.0</td>
      <td>0.11780</td>
      <td>0.27700</td>
      <td>0.35140</td>
      <td>0.15200</td>
      <td>0.2397</td>
      <td>0.07016</td>
      <td>...</td>
      <td>25.740</td>
      <td>39.42</td>
      <td>184.60</td>
      <td>1821.0</td>
      <td>0.16500</td>
      <td>0.86810</td>
      <td>0.9387</td>
      <td>0.2650</td>
      <td>0.4087</td>
      <td>0.12400</td>
    </tr>
    <tr>
      <th>568</th>
      <td>7.76</td>
      <td>24.54</td>
      <td>47.92</td>
      <td>181.0</td>
      <td>0.05263</td>
      <td>0.04362</td>
      <td>0.00000</td>
      <td>0.00000</td>
      <td>0.1587</td>
      <td>0.05884</td>
      <td>...</td>
      <td>9.456</td>
      <td>30.37</td>
      <td>59.16</td>
      <td>268.6</td>
      <td>0.08996</td>
      <td>0.06444</td>
      <td>0.0000</td>
      <td>0.0000</td>
      <td>0.2871</td>
      <td>0.07039</td>
    </tr>
  </tbody>
</table>
<p>569 rows × 30 columns</p>
</div></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>.. _breast_cancer_dataset:

Breast cancer wisconsin (diagnostic) dataset
--------------------------------------------

**Data Set Characteristics:**

    :Number of Instances: 569

    :Number of Attributes: 30 numeric, predictive attributes and the class

    :Attribute Information:
        - radius (mean of distances from center to points on the perimeter)
        - texture (standard deviation of gray-scale values)
        - perimeter
        - area
        - smoothness (local variation in radius lengths)
        - compactness (perimeter^2 / area - 1.0)
        - concavity (severity of concave portions of the contour)
        - concave points (number of concave portions of the contour)
        - symmetry
        - fractal dimension (&quot;coastline approximation&quot; - 1)

        The mean, standard error, and &quot;worst&quot; or largest (mean of the three
        worst/largest values) of these features were computed for each image,
        resulting in 30 features.  For instance, field 0 is Mean Radius, field
        10 is Radius SE, field 20 is Worst Radius.

        - class:
                - WDBC-Malignant
                - WDBC-Benign

    :Summary Statistics:

    ===================================== ====== ======
                                           Min    Max
    ===================================== ====== ======
    radius (mean):                        6.981  28.11
    texture (mean):                       9.71   39.28
    perimeter (mean):                     43.79  188.5
    area (mean):                          143.5  2501.0
    smoothness (mean):                    0.053  0.163
    compactness (mean):                   0.019  0.345
    concavity (mean):                     0.0    0.427
    concave points (mean):                0.0    0.201
    symmetry (mean):                      0.106  0.304
    fractal dimension (mean):             0.05   0.097
    radius (standard error):              0.112  2.873
    texture (standard error):             0.36   4.885
    perimeter (standard error):           0.757  21.98
    area (standard error):                6.802  542.2
    smoothness (standard error):          0.002  0.031
    compactness (standard error):         0.002  0.135
    concavity (standard error):           0.0    0.396
    concave points (standard error):      0.0    0.053
    symmetry (standard error):            0.008  0.079
    fractal dimension (standard error):   0.001  0.03
    radius (worst):                       7.93   36.04
    texture (worst):                      12.02  49.54
    perimeter (worst):                    50.41  251.2
    area (worst):                         185.2  4254.0
    smoothness (worst):                   0.071  0.223
    compactness (worst):                  0.027  1.058
    concavity (worst):                    0.0    1.252
    concave points (worst):               0.0    0.291
    symmetry (worst):                     0.156  0.664
    fractal dimension (worst):            0.055  0.208
    ===================================== ====== ======

    :Missing Attribute Values: None

    :Class Distribution: 212 - Malignant, 357 - Benign

    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian

    :Donor: Nick Street

    :Date: November, 1995

This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.
https://goo.gl/U2Uwz2

Features are computed from a digitized image of a fine needle
aspirate (FNA) of a breast mass.  They describe
characteristics of the cell nuclei present in the image.

Separating plane described above was obtained using
Multisurface Method-Tree (MSM-T) [K. P. Bennett, &quot;Decision Tree
Construction Via Linear Programming.&quot; Proceedings of the 4th
Midwest Artificial Intelligence and Cognitive Science Society,
pp. 97-101, 1992], a classification method which uses linear
programming to construct a decision tree.  Relevant features
were selected using an exhaustive search in the space of 1-4
features and 1-3 separating planes.

The actual linear program used to obtain the separating plane
in the 3-dimensional space is that described in:
[K. P. Bennett and O. L. Mangasarian: &quot;Robust Linear
Programming Discrimination of Two Linearly Inseparable Sets&quot;,
Optimization Methods and Software 1, 1992, 23-34].

This database is also available through the UW CS ftp server:

ftp ftp.cs.wisc.edu
cd math-prog/cpo-dataset/machine-learn/WDBC/

.. topic:: References

   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction 
     for breast tumor diagnosis. IS&amp;T/SPIE 1993 International Symposium on 
     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,
     San Jose, CA, 1993.
   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and 
     prognosis via linear programming. Operations Research, 43(4), pages 570-577, 
     July-August 1995.
   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques
     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 
     163-171.
</pre></div>
</div>
</div>
</div>
<p>Upon inspection, the dataset comprises 569 instances and 32 attributes. The primary objective is to construct a classification model capable of accurately classifying the <strong>Diagnosis</strong> based on the remaining attributes. Before delving into the model creation, let’s commence by generating a count plot that visualizes the distribution of the <strong>Diagnosis</strong> attribute.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;../mystyle.mplstyle&#39;</span><span class="p">)</span>

<span class="n">diagnosis_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">data</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">])</span>
<span class="n">unique_labels</span><span class="p">,</span> <span class="n">label_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">diagnosis_labels</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Create a figure and axis</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">4.5</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">))</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;LightGreen&#39;</span><span class="p">,</span> <span class="s1">&#39;OrangeRed&#39;</span><span class="p">]</span>
<span class="n">explode</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># Explode the first slice</span>

<span class="c1"># Create the pie chart</span>
<span class="n">ax</span><span class="o">.</span><span class="n">pie</span><span class="p">(</span><span class="n">label_counts</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">unique_labels</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">autopct</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%1.1f%%</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">startangle</span><span class="o">=</span><span class="mi">140</span><span class="p">,</span> <span class="n">explode</span><span class="o">=</span><span class="n">explode</span><span class="p">,</span>
       <span class="n">shadow</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">wedgeprops</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;edgecolor&#39;</span><span class="p">:</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="s1">&#39;linewidth&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
       <span class="n">textprops</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fontsize&#39;</span><span class="p">:</span> <span class="mi">14</span><span class="p">})</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>  <span class="c1"># Equal aspect ratio ensures that pie is drawn as a circle.</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Distribution of Diagnosis in Breast Cancer Dataset&#39;</span><span class="p">,</span> <span class="n">weight</span> <span class="o">=</span> <span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/cc6b6d3b3fa90030b6b16bc00e61b2eaea9c7a1b99330125ebb507e12d194c0e.png" src="../_images/cc6b6d3b3fa90030b6b16bc00e61b2eaea9c7a1b99330125ebb507e12d194c0e.png" />
</div>
</div>
<div class="warning admonition">
<p class="admonition-title">Note</p>
<p>In the context of breast cancer:</p>
<ul class="simple">
<li><p><strong>Benign Breast Conditions:</strong> These are non-cancerous changes in breast tissue. While they might cause discomfort or be palpable as lumps, they do not carry the risk of spreading to other parts of the body. Examples include fibroadenomas and cysts.</p></li>
<li><p><strong>Malignant Breast Conditions (Breast Cancer):</strong> Breast cancer occurs when cells in the breast tissue start to grow uncontrollably, forming a malignant tumor. If left untreated, these cancer cells can invade surrounding tissues and potentially metastasize to other organs, leading to life-threatening consequences.</p></li>
</ul>
<p>In summary, “benign” refers to non-cancerous conditions with limited potential to spread, while “malignant” refers to cancerous conditions with the potential to invade surrounding tissues and spread to other parts of the body.</p>
</div>
<p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit"><strong>StratifiedKFold</strong></a> is a modified version of the k-fold cross-validation technique. It generates stratified folds, meaning that each fold retains a similar proportion of samples from each target class as present in the entire dataset. This ensures that the distribution of target classes remains consistent across the folds, enhancing the reliability of model evaluation, especially when dealing with imbalanced datasets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedShuffleSplit</span>

<span class="c1"># Load the breast cancer dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>

<span class="c1"># Create StratifiedShuffleSplit</span>
<span class="n">sss</span> <span class="o">=</span> <span class="n">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">sss</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Split the data into train and test sets</span>
<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">sss</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>

<span class="c1"># Create a DataFrame to store train and test data labels</span>
<span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">diagnosis_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">data</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">y</span><span class="p">])</span>
<span class="n">temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Diagnosis&#39;</span><span class="p">:</span> <span class="n">diagnosis_labels</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="s1">&#39;Set&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_index</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="s1">&#39;Train&#39;</span><span class="p">]})</span>
<span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_temp</span><span class="p">,</span> <span class="n">temp</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Diagnosis&#39;</span><span class="p">:</span> <span class="n">diagnosis_labels</span><span class="p">[</span><span class="n">test_index</span><span class="p">],</span> <span class="s1">&#39;Set&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_index</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="s1">&#39;Test&#39;</span><span class="p">]})</span>
<span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_temp</span><span class="p">,</span> <span class="n">temp</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Set custom color palette</span>
<span class="n">custom_palette</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Benign&#39;</span><span class="p">:</span> <span class="s1">&#39;LightGreen&#39;</span><span class="p">,</span> <span class="s1">&#39;Malignant&#39;</span><span class="p">:</span> <span class="s1">&#39;OrangeRed&#39;</span><span class="p">}</span>
<span class="c1"># Create figure and axes</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">4.5</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">))</span>

<span class="c1"># Create count plot with hue using custom palette</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_temp</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Set&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Diagnosis&quot;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">custom_palette</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">ec</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">)</span>

<span class="c1"># Set title, labels, and legend</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Distribution of Diagnosis in Train and Test Data&quot;</span><span class="p">,</span>
           <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Diagnosis&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Count&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Set&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">title_fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="c1"># Add grid lines</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="c1"># Improve spacing</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/49dc9d3105d496bc0285a6e14801b04b444b6cbb12bf038bc7f72842fe1748f6.png" src="../_images/49dc9d3105d496bc0285a6e14801b04b444b6cbb12bf038bc7f72842fe1748f6.png" />
</div>
</div>
<div class="section" id="visualizing-feature-importance-and-rfe-rankings">
<h2><span class="section-number">11.5.1. </span>Visualizing Feature Importance and RFE Rankings<a class="headerlink" href="#visualizing-feature-importance-and-rfe-rankings" title="Permalink to this headline">#</a></h2>
<p>Visualizing the importance of features and their rankings can provide valuable insights into understanding the significance of different features in a dataset. In this section, we’ll demonstrate how to create two subplots: one displaying feature importances and another showing Recursive Feature Elimination (RFE) rankings using a RandomForestClassifier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span>

<span class="c1"># Create and fit a RandomForestClassifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">importance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Features&#39;</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">clf</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">})</span>
<span class="n">importance_df</span> <span class="o">=</span> <span class="n">importance_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s1">&#39;Features&#39;</span><span class="p">)</span>

<span class="n">n_features_to_select</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># Perform RFE</span>
<span class="n">rfe</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">clf</span><span class="p">,</span> <span class="n">n_features_to_select</span> <span class="o">=</span> <span class="n">n_features_to_select</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">rfe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Get feature rankings</span>
<span class="n">feature_rankings</span> <span class="o">=</span> <span class="n">rfe</span><span class="o">.</span><span class="n">ranking_</span>

<span class="c1"># Create figure and axes with custom style</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">9.5</span><span class="p">,</span> <span class="mi">14</span><span class="p">))</span>

<span class="n">_most_important</span> <span class="o">=</span> <span class="n">importance_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s1">&#39;Importance&#39;</span><span class="p">,</span>
                                                 <span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)[:</span><span class="n">n_features_to_select</span><span class="p">][</span><span class="s1">&#39;Features&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="c1"># Plot feature importances in the first subplot</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;LimeGreen&#39;</span> <span class="k">if</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">_most_important</span> <span class="k">else</span> <span class="s1">&#39;AliceBlue&#39;</span> <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">importance_df</span><span class="p">[</span><span class="s1">&#39;Features&#39;</span><span class="p">]]</span>
<span class="n">edge_colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DarkGreen&#39;</span> <span class="k">if</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">_most_important</span> <span class="k">else</span> <span class="s1">&#39;RoyalBlue&#39;</span> <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">importance_df</span><span class="p">[</span><span class="s1">&#39;Features&#39;</span><span class="p">]]</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">importance_df</span><span class="o">.</span><span class="n">Features</span><span class="p">,</span> <span class="n">importance_df</span><span class="o">.</span><span class="n">Importance</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
            <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">edge_colors</span><span class="p">,</span> <span class="n">hatch</span><span class="o">=</span><span class="s1">&#39;|||&#39;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Feature Importances&quot;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Relative Importance&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Features&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[[</span><span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">tick_bottom</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">tick_left</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">visible</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="c1"># Plot RFE feature rankings in the second subplot</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Salmon&#39;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">selected</span> <span class="k">else</span> <span class="s1">&#39;LimeGreen&#39;</span> <span class="k">for</span> <span class="n">selected</span> <span class="ow">in</span> <span class="n">rfe</span><span class="o">.</span><span class="n">support_</span><span class="p">]</span>
<span class="n">edge_colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DarkRed&#39;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">selected</span> <span class="k">else</span> <span class="s1">&#39;DarkGreen&#39;</span> <span class="k">for</span> <span class="n">selected</span> <span class="ow">in</span> <span class="n">rfe</span><span class="o">.</span><span class="n">support_</span><span class="p">]</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">feature_rankings</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
            <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">edge_colors</span><span class="p">,</span> <span class="n">hatch</span><span class="o">=</span><span class="s1">&#39;///&#39;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;RFE Feature Rankings&quot;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Ranking&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Feature&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">invert_xaxis</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[[</span><span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">tick_bottom</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">tick_left</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">visible</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ae5a2e33c7cbb853c4860957a1496bbbce21ffd487e1f2562c2bd0e5398a8616.png" src="../_images/ae5a2e33c7cbb853c4860957a1496bbbce21ffd487e1f2562c2bd0e5398a8616.png" />
</div>
</div>
<p>In this example, we first fit a RandomForestClassifier to the training data and calculate the feature importances. We then perform RFE using the same classifier to determine the rankings of the features. The most important features for both scenarios are highlighted using distinctive colors and hatch patterns. The two subplots display the feature importances and RFE rankings, respectively, providing a visual comparison of their significance. This visualization aids in making informed decisions about feature selection and understanding the impact of each feature on the model’s performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Features&#39;</span><span class="p">:</span><span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="s1">&#39;Rank&#39;</span><span class="p">:</span><span class="n">rfe</span><span class="o">.</span><span class="n">ranking_</span><span class="p">})</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;Features&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>\
<span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;PuBu&#39;</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Rank&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style type="text/css">
#T_e24a3_row0_col0 {
  background-color: #c0c9e2;
  color: #000000;
}
#T_e24a3_row1_col0 {
  background-color: #03456c;
  color: #f1f1f1;
}
#T_e24a3_row2_col0 {
  background-color: #187cb6;
  color: #f1f1f1;
}
#T_e24a3_row3_col0 {
  background-color: #9cb9d9;
  color: #000000;
}
#T_e24a3_row4_col0 {
  background-color: #88b1d4;
  color: #000000;
}
#T_e24a3_row5_col0 {
  background-color: #f8f1f8;
  color: #000000;
}
#T_e24a3_row6_col0 {
  background-color: #5c9fc9;
  color: #f1f1f1;
}
#T_e24a3_row7_col0, #T_e24a3_row8_col0, #T_e24a3_row10_col0, #T_e24a3_row11_col0, #T_e24a3_row20_col0, #T_e24a3_row22_col0, #T_e24a3_row23_col0, #T_e24a3_row25_col0, #T_e24a3_row26_col0, #T_e24a3_row29_col0 {
  background-color: #fff7fb;
  color: #000000;
}
#T_e24a3_row9_col0 {
  background-color: #045382;
  color: #f1f1f1;
}
#T_e24a3_row12_col0 {
  background-color: #73a9cf;
  color: #f1f1f1;
}
#T_e24a3_row13_col0 {
  background-color: #4295c3;
  color: #f1f1f1;
}
#T_e24a3_row14_col0 {
  background-color: #d0d1e6;
  color: #000000;
}
#T_e24a3_row15_col0 {
  background-color: #045e94;
  color: #f1f1f1;
}
#T_e24a3_row16_col0 {
  background-color: #0567a2;
  color: #f1f1f1;
}
#T_e24a3_row17_col0 {
  background-color: #2c89bd;
  color: #f1f1f1;
}
#T_e24a3_row18_col0 {
  background-color: #056faf;
  color: #f1f1f1;
}
#T_e24a3_row19_col0 {
  background-color: #023858;
  color: #f1f1f1;
}
#T_e24a3_row21_col0 {
  background-color: #e7e3f0;
  color: #000000;
}
#T_e24a3_row24_col0 {
  background-color: #afc1dd;
  color: #000000;
}
#T_e24a3_row27_col0 {
  background-color: #f0eaf4;
  color: #000000;
}
#T_e24a3_row28_col0 {
  background-color: #dbdaeb;
  color: #000000;
}
</style>
<table id="T_e24a3">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_e24a3_level0_col0" class="col_heading level0 col0" >Rank</th>
    </tr>
    <tr>
      <th class="index_name level0" >Features</th>
      <th class="blank col0" >&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_e24a3_level0_row0" class="row_heading level0 row0" >area error</th>
      <td id="T_e24a3_row0_col0" class="data row0 col0" >7</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row1" class="row_heading level0 row1" >compactness error</th>
      <td id="T_e24a3_row1_col0" class="data row1 col0" >20</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row2" class="row_heading level0 row2" >concave points error</th>
      <td id="T_e24a3_row2_col0" class="data row2 col0" >15</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row3" class="row_heading level0 row3" >concavity error</th>
      <td id="T_e24a3_row3_col0" class="data row3 col0" >9</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row4" class="row_heading level0 row4" >fractal dimension error</th>
      <td id="T_e24a3_row4_col0" class="data row4 col0" >10</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row5" class="row_heading level0 row5" >mean area</th>
      <td id="T_e24a3_row5_col0" class="data row5 col0" >2</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row6" class="row_heading level0 row6" >mean compactness</th>
      <td id="T_e24a3_row6_col0" class="data row6 col0" >12</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row7" class="row_heading level0 row7" >mean concave points</th>
      <td id="T_e24a3_row7_col0" class="data row7 col0" >1</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row8" class="row_heading level0 row8" >mean concavity</th>
      <td id="T_e24a3_row8_col0" class="data row8 col0" >1</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row9" class="row_heading level0 row9" >mean fractal dimension</th>
      <td id="T_e24a3_row9_col0" class="data row9 col0" >19</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row10" class="row_heading level0 row10" >mean perimeter</th>
      <td id="T_e24a3_row10_col0" class="data row10 col0" >1</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row11" class="row_heading level0 row11" >mean radius</th>
      <td id="T_e24a3_row11_col0" class="data row11 col0" >1</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row12" class="row_heading level0 row12" >mean smoothness</th>
      <td id="T_e24a3_row12_col0" class="data row12 col0" >11</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row13" class="row_heading level0 row13" >mean symmetry</th>
      <td id="T_e24a3_row13_col0" class="data row13 col0" >13</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row14" class="row_heading level0 row14" >mean texture</th>
      <td id="T_e24a3_row14_col0" class="data row14 col0" >6</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row15" class="row_heading level0 row15" >perimeter error</th>
      <td id="T_e24a3_row15_col0" class="data row15 col0" >18</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row16" class="row_heading level0 row16" >radius error</th>
      <td id="T_e24a3_row16_col0" class="data row16 col0" >17</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row17" class="row_heading level0 row17" >smoothness error</th>
      <td id="T_e24a3_row17_col0" class="data row17 col0" >14</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row18" class="row_heading level0 row18" >symmetry error</th>
      <td id="T_e24a3_row18_col0" class="data row18 col0" >16</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row19" class="row_heading level0 row19" >texture error</th>
      <td id="T_e24a3_row19_col0" class="data row19 col0" >21</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row20" class="row_heading level0 row20" >worst area</th>
      <td id="T_e24a3_row20_col0" class="data row20 col0" >1</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row21" class="row_heading level0 row21" >worst compactness</th>
      <td id="T_e24a3_row21_col0" class="data row21 col0" >4</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row22" class="row_heading level0 row22" >worst concave points</th>
      <td id="T_e24a3_row22_col0" class="data row22 col0" >1</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row23" class="row_heading level0 row23" >worst concavity</th>
      <td id="T_e24a3_row23_col0" class="data row23 col0" >1</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row24" class="row_heading level0 row24" >worst fractal dimension</th>
      <td id="T_e24a3_row24_col0" class="data row24 col0" >8</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row25" class="row_heading level0 row25" >worst perimeter</th>
      <td id="T_e24a3_row25_col0" class="data row25 col0" >1</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row26" class="row_heading level0 row26" >worst radius</th>
      <td id="T_e24a3_row26_col0" class="data row26 col0" >1</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row27" class="row_heading level0 row27" >worst smoothness</th>
      <td id="T_e24a3_row27_col0" class="data row27 col0" >3</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row28" class="row_heading level0 row28" >worst symmetry</th>
      <td id="T_e24a3_row28_col0" class="data row28 col0" >5</td>
    </tr>
    <tr>
      <th id="T_e24a3_level0_row29" class="row_heading level0 row29" >worst texture</th>
      <td id="T_e24a3_row29_col0" class="data row29 col0" >1</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
<div class="section" id="how-many-features-to-select">
<h2><span class="section-number">11.5.2. </span>How many Features to select?<a class="headerlink" href="#how-many-features-to-select" title="Permalink to this headline">#</a></h2>
<p>Feature selection is a crucial step in machine learning model development. It involves choosing a subset of relevant features from the original set to improve model performance, reduce overfitting, and enhance interpretability. Selecting the right number of features is a balance between complexity and information gain. In this section, we will explore an example of how to determine the optimal number of features to select using Recursive Feature Elimination (RFE) with a RandomForestClassifier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
    
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">selector</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(),</span> <span class="n">n_features_to_select</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">selector</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Number of Features to Select&#39;</span><span class="p">:</span> <span class="n">n</span><span class="p">,</span>
                            <span class="s1">&#39;Total number of features&#39;</span><span class="p">:</span> <span class="n">selector</span><span class="o">.</span><span class="n">n_features_in_</span><span class="p">,</span>
                            <span class="s1">&#39;Train F1 Score&#39;</span><span class="p">:</span> <span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">selector</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)),</span>
                            <span class="s1">&#39;Test F1 Score&#39;</span><span class="p">:</span> <span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">selector</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)),</span>
                            <span class="s1">&#39;Best Features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">rfe</span><span class="o">.</span><span class="n">support_</span><span class="p">]]})</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="n">df_temp</span><span class="p">],</span> <span class="n">ignore_index</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    <span class="k">del</span> <span class="n">df_temp</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Test F1 Score&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;Number of Features to Select&#39;</span><span class="p">],</span> <span class="n">ascending</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">])</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Greens&#39;</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Test F1 Score&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style type="text/css">
#T_234ba_row0_col3, #T_234ba_row1_col3, #T_234ba_row2_col3, #T_234ba_row3_col3, #T_234ba_row4_col3, #T_234ba_row5_col3, #T_234ba_row6_col3, #T_234ba_row7_col3, #T_234ba_row8_col3, #T_234ba_row9_col3 {
  background-color: #00441b;
  color: #f1f1f1;
}
#T_234ba_row10_col3 {
  background-color: #087432;
  color: #f1f1f1;
}
#T_234ba_row11_col3, #T_234ba_row12_col3, #T_234ba_row13_col3, #T_234ba_row14_col3, #T_234ba_row15_col3, #T_234ba_row16_col3, #T_234ba_row17_col3, #T_234ba_row18_col3 {
  background-color: #0c7735;
  color: #f1f1f1;
}
#T_234ba_row19_col3 {
  background-color: #39a257;
  color: #f1f1f1;
}
#T_234ba_row20_col3, #T_234ba_row21_col3 {
  background-color: #6bc072;
  color: #000000;
}
#T_234ba_row22_col3 {
  background-color: #afdfa8;
  color: #000000;
}
#T_234ba_row23_col3 {
  background-color: #b5e1ae;
  color: #000000;
}
#T_234ba_row24_col3 {
  background-color: #daf0d4;
  color: #000000;
}
#T_234ba_row25_col3 {
  background-color: #def2d9;
  color: #000000;
}
#T_234ba_row26_col3 {
  background-color: #f7fcf5;
  color: #000000;
}
</style>
<table id="T_234ba">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_234ba_level0_col0" class="col_heading level0 col0" >Number of Features to Select</th>
      <th id="T_234ba_level0_col1" class="col_heading level0 col1" >Total number of features</th>
      <th id="T_234ba_level0_col2" class="col_heading level0 col2" >Train F1 Score</th>
      <th id="T_234ba_level0_col3" class="col_heading level0 col3" >Test F1 Score</th>
      <th id="T_234ba_level0_col4" class="col_heading level0 col4" >Best Features</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_234ba_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_234ba_row0_col0" class="data row0 col0" >10</td>
      <td id="T_234ba_row0_col1" class="data row0 col1" >30</td>
      <td id="T_234ba_row0_col2" class="data row0 col2" >1.000000</td>
      <td id="T_234ba_row0_col3" class="data row0 col3" >0.958525</td>
      <td id="T_234ba_row0_col4" class="data row0 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_234ba_row1_col0" class="data row1 col0" >12</td>
      <td id="T_234ba_row1_col1" class="data row1 col1" >30</td>
      <td id="T_234ba_row1_col2" class="data row1 col2" >1.000000</td>
      <td id="T_234ba_row1_col3" class="data row1 col3" >0.958525</td>
      <td id="T_234ba_row1_col4" class="data row1 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_234ba_row2_col0" class="data row2 col0" >13</td>
      <td id="T_234ba_row2_col1" class="data row2 col1" >30</td>
      <td id="T_234ba_row2_col2" class="data row2 col2" >1.000000</td>
      <td id="T_234ba_row2_col3" class="data row2 col3" >0.958525</td>
      <td id="T_234ba_row2_col4" class="data row2 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_234ba_row3_col0" class="data row3 col0" >14</td>
      <td id="T_234ba_row3_col1" class="data row3 col1" >30</td>
      <td id="T_234ba_row3_col2" class="data row3 col2" >1.000000</td>
      <td id="T_234ba_row3_col3" class="data row3 col3" >0.958525</td>
      <td id="T_234ba_row3_col4" class="data row3 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_234ba_row4_col0" class="data row4 col0" >16</td>
      <td id="T_234ba_row4_col1" class="data row4 col1" >30</td>
      <td id="T_234ba_row4_col2" class="data row4 col2" >1.000000</td>
      <td id="T_234ba_row4_col3" class="data row4 col3" >0.958525</td>
      <td id="T_234ba_row4_col4" class="data row4 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_234ba_row5_col0" class="data row5 col0" >19</td>
      <td id="T_234ba_row5_col1" class="data row5 col1" >30</td>
      <td id="T_234ba_row5_col2" class="data row5 col2" >1.000000</td>
      <td id="T_234ba_row5_col3" class="data row5 col3" >0.958525</td>
      <td id="T_234ba_row5_col4" class="data row5 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_234ba_row6_col0" class="data row6 col0" >23</td>
      <td id="T_234ba_row6_col1" class="data row6 col1" >30</td>
      <td id="T_234ba_row6_col2" class="data row6 col2" >1.000000</td>
      <td id="T_234ba_row6_col3" class="data row6 col3" >0.958525</td>
      <td id="T_234ba_row6_col4" class="data row6 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_234ba_row7_col0" class="data row7 col0" >26</td>
      <td id="T_234ba_row7_col1" class="data row7 col1" >30</td>
      <td id="T_234ba_row7_col2" class="data row7 col2" >1.000000</td>
      <td id="T_234ba_row7_col3" class="data row7 col3" >0.958525</td>
      <td id="T_234ba_row7_col4" class="data row7 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_234ba_row8_col0" class="data row8 col0" >29</td>
      <td id="T_234ba_row8_col1" class="data row8 col1" >30</td>
      <td id="T_234ba_row8_col2" class="data row8 col2" >1.000000</td>
      <td id="T_234ba_row8_col3" class="data row8 col3" >0.958525</td>
      <td id="T_234ba_row8_col4" class="data row8 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_234ba_row9_col0" class="data row9 col0" >30</td>
      <td id="T_234ba_row9_col1" class="data row9 col1" >30</td>
      <td id="T_234ba_row9_col2" class="data row9 col2" >1.000000</td>
      <td id="T_234ba_row9_col3" class="data row9 col3" >0.958525</td>
      <td id="T_234ba_row9_col4" class="data row9 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row10" class="row_heading level0 row10" >10</th>
      <td id="T_234ba_row10_col0" class="data row10 col0" >9</td>
      <td id="T_234ba_row10_col1" class="data row10 col1" >30</td>
      <td id="T_234ba_row10_col2" class="data row10 col2" >1.000000</td>
      <td id="T_234ba_row10_col3" class="data row10 col3" >0.954128</td>
      <td id="T_234ba_row10_col4" class="data row10 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row11" class="row_heading level0 row11" >11</th>
      <td id="T_234ba_row11_col0" class="data row11 col0" >15</td>
      <td id="T_234ba_row11_col1" class="data row11 col1" >30</td>
      <td id="T_234ba_row11_col2" class="data row11 col2" >1.000000</td>
      <td id="T_234ba_row11_col3" class="data row11 col3" >0.953704</td>
      <td id="T_234ba_row11_col4" class="data row11 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row12" class="row_heading level0 row12" >12</th>
      <td id="T_234ba_row12_col0" class="data row12 col0" >17</td>
      <td id="T_234ba_row12_col1" class="data row12 col1" >30</td>
      <td id="T_234ba_row12_col2" class="data row12 col2" >1.000000</td>
      <td id="T_234ba_row12_col3" class="data row12 col3" >0.953704</td>
      <td id="T_234ba_row12_col4" class="data row12 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row13" class="row_heading level0 row13" >13</th>
      <td id="T_234ba_row13_col0" class="data row13 col0" >18</td>
      <td id="T_234ba_row13_col1" class="data row13 col1" >30</td>
      <td id="T_234ba_row13_col2" class="data row13 col2" >1.000000</td>
      <td id="T_234ba_row13_col3" class="data row13 col3" >0.953704</td>
      <td id="T_234ba_row13_col4" class="data row13 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row14" class="row_heading level0 row14" >14</th>
      <td id="T_234ba_row14_col0" class="data row14 col0" >20</td>
      <td id="T_234ba_row14_col1" class="data row14 col1" >30</td>
      <td id="T_234ba_row14_col2" class="data row14 col2" >1.000000</td>
      <td id="T_234ba_row14_col3" class="data row14 col3" >0.953704</td>
      <td id="T_234ba_row14_col4" class="data row14 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row15" class="row_heading level0 row15" >15</th>
      <td id="T_234ba_row15_col0" class="data row15 col0" >21</td>
      <td id="T_234ba_row15_col1" class="data row15 col1" >30</td>
      <td id="T_234ba_row15_col2" class="data row15 col2" >1.000000</td>
      <td id="T_234ba_row15_col3" class="data row15 col3" >0.953704</td>
      <td id="T_234ba_row15_col4" class="data row15 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row16" class="row_heading level0 row16" >16</th>
      <td id="T_234ba_row16_col0" class="data row16 col0" >22</td>
      <td id="T_234ba_row16_col1" class="data row16 col1" >30</td>
      <td id="T_234ba_row16_col2" class="data row16 col2" >1.000000</td>
      <td id="T_234ba_row16_col3" class="data row16 col3" >0.953704</td>
      <td id="T_234ba_row16_col4" class="data row16 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row17" class="row_heading level0 row17" >17</th>
      <td id="T_234ba_row17_col0" class="data row17 col0" >25</td>
      <td id="T_234ba_row17_col1" class="data row17 col1" >30</td>
      <td id="T_234ba_row17_col2" class="data row17 col2" >1.000000</td>
      <td id="T_234ba_row17_col3" class="data row17 col3" >0.953704</td>
      <td id="T_234ba_row17_col4" class="data row17 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row18" class="row_heading level0 row18" >18</th>
      <td id="T_234ba_row18_col0" class="data row18 col0" >27</td>
      <td id="T_234ba_row18_col1" class="data row18 col1" >30</td>
      <td id="T_234ba_row18_col2" class="data row18 col2" >1.000000</td>
      <td id="T_234ba_row18_col3" class="data row18 col3" >0.953704</td>
      <td id="T_234ba_row18_col4" class="data row18 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row19" class="row_heading level0 row19" >19</th>
      <td id="T_234ba_row19_col0" class="data row19 col0" >28</td>
      <td id="T_234ba_row19_col1" class="data row19 col1" >30</td>
      <td id="T_234ba_row19_col2" class="data row19 col2" >1.000000</td>
      <td id="T_234ba_row19_col3" class="data row19 col3" >0.948837</td>
      <td id="T_234ba_row19_col4" class="data row19 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row20" class="row_heading level0 row20" >20</th>
      <td id="T_234ba_row20_col0" class="data row20 col0" >8</td>
      <td id="T_234ba_row20_col1" class="data row20 col1" >30</td>
      <td id="T_234ba_row20_col2" class="data row20 col2" >1.000000</td>
      <td id="T_234ba_row20_col3" class="data row20 col3" >0.944954</td>
      <td id="T_234ba_row20_col4" class="data row20 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row21" class="row_heading level0 row21" >21</th>
      <td id="T_234ba_row21_col0" class="data row21 col0" >11</td>
      <td id="T_234ba_row21_col1" class="data row21 col1" >30</td>
      <td id="T_234ba_row21_col2" class="data row21 col2" >1.000000</td>
      <td id="T_234ba_row21_col3" class="data row21 col3" >0.944954</td>
      <td id="T_234ba_row21_col4" class="data row21 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row22" class="row_heading level0 row22" >22</th>
      <td id="T_234ba_row22_col0" class="data row22 col0" >7</td>
      <td id="T_234ba_row22_col1" class="data row22 col1" >30</td>
      <td id="T_234ba_row22_col2" class="data row22 col2" >1.000000</td>
      <td id="T_234ba_row22_col3" class="data row22 col3" >0.939535</td>
      <td id="T_234ba_row22_col4" class="data row22 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row23" class="row_heading level0 row23" >23</th>
      <td id="T_234ba_row23_col0" class="data row23 col0" >24</td>
      <td id="T_234ba_row23_col1" class="data row23 col1" >30</td>
      <td id="T_234ba_row23_col2" class="data row23 col2" >1.000000</td>
      <td id="T_234ba_row23_col3" class="data row23 col3" >0.938967</td>
      <td id="T_234ba_row23_col4" class="data row23 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row24" class="row_heading level0 row24" >24</th>
      <td id="T_234ba_row24_col0" class="data row24 col0" >5</td>
      <td id="T_234ba_row24_col1" class="data row24 col1" >30</td>
      <td id="T_234ba_row24_col2" class="data row24 col2" >1.000000</td>
      <td id="T_234ba_row24_col3" class="data row24 col3" >0.935185</td>
      <td id="T_234ba_row24_col4" class="data row24 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row25" class="row_heading level0 row25" >25</th>
      <td id="T_234ba_row25_col0" class="data row25 col0" >6</td>
      <td id="T_234ba_row25_col1" class="data row25 col1" >30</td>
      <td id="T_234ba_row25_col2" class="data row25 col2" >1.000000</td>
      <td id="T_234ba_row25_col3" class="data row25 col3" >0.934579</td>
      <td id="T_234ba_row25_col4" class="data row25 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
    <tr>
      <th id="T_234ba_level0_row26" class="row_heading level0 row26" >26</th>
      <td id="T_234ba_row26_col0" class="data row26 col0" >4</td>
      <td id="T_234ba_row26_col1" class="data row26 col1" >30</td>
      <td id="T_234ba_row26_col2" class="data row26 col2" >1.000000</td>
      <td id="T_234ba_row26_col3" class="data row26 col3" >0.930233</td>
      <td id="T_234ba_row26_col4" class="data row26 col4" >['mean radius' 'mean perimeter' 'mean concavity' 'mean concave points'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst concavity' 'worst concave points']</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>In this example, we use the Recursive Feature Elimination (RFE) technique with a RandomForestClassifier as the estimator. RFE works by recursively fitting the model and removing the least important features until the desired number of features is reached. The evaluation metrics, including the Train F1 Score and Test F1 Score, are recorded for each configuration.</p>
<p>The loop iterates through different numbers of features to select, and for each iteration, it fits the model using RFE and calculates the F1 scores for both the training and test sets. The results are stored in a DataFrame (<code class="docutils literal notranslate"><span class="pre">df_temp</span></code>) and then concatenated with the main DataFrame (<code class="docutils literal notranslate"><span class="pre">df</span></code>).</p>
<p>Finally, the DataFrame is sorted based on the Test F1 Score in descending order, which helps identify the configuration that yields the best performance on the test set. This process aids in determining the optimal number of features to select for achieving the highest model performance.</p>
<div class="warning admonition">
<p class="admonition-title">Note</p>
<p>Beyond the process of feature selection, there’s an additional avenue for enhancing model performance—fine-tuning. Fine-tuning involves the meticulous adjustment of hyperparameters and model configurations to achieve the utmost optimal results. By optimizing hyperparameters, you can achieve a more refined and effective model that’s tailored precisely to the dataset and the specific problem at hand. This iterative process of fine-tuning empowers you to squeeze out the last drops of performance, ensuring that your model operates at its highest potential.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_11"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="ENGG_680_C11S4.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">11.4. </span>Linear and Quadratic Discriminant Analyses</p>
      </div>
    </a>
    <a class="right-next"
       href="ENGG_680_C11S6.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11.6. </span>Practical Considerations in Dimensionality Reduction</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-feature-importance-and-rfe-rankings">11.5.1. Visualizing Feature Importance and RFE Rankings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-many-features-to-select">11.5.2. How many Features to select?</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hatef Dastour
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>