{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "# TensorFlow Basics\n",
    "\n",
    "Deep learning is a powerful field of artificial intelligence that uses neural networks to make sense of data and perform tasks like recognizing images, understanding natural language, and generating speech. These neural networks consist of intricate layers of nodes that perform complex calculations on data inputs and outputs. To efficiently handle this data and speed up these calculations, deep learning relies on a special data structure called **tensors**.\n",
    "\n",
    "Tensors can be thought of as a more advanced version of the familiar **arrays** we often use in programming and mathematics. Arrays are collections of elements organized in rows and columns, and tensors share a strong connection with them. Let's explore how they are similar {cite:p}`TensorFlowDocumentation`:\n",
    "\n",
    "\n",
    "## Array and Tensor Connection\n",
    "\n",
    "- **Multidimensional Flexibility:** Arrays, with their ability to have multiple dimensions, lay the foundation for tensors. In arrays, dimensions are like the arrangement of data in a musical score, with rows and columns. Tensors take this idea further, extending dimensions into a multi-axis arrangement that can adapt to any kind of data structure.\n",
    "\n",
    "- **Indexing and Access:** Just like you use indices to access elements in arrays, tensors work the same way for retrieving data. Elements inside both arrays and tensors are accessed and manipulated using indices, making data handling consistent.\n",
    "\n",
    "- **Mathematical Aptitude:** Arrays have a well-established reputation for their mathematical capabilities, crucial for performing various operations. Tensors, as their successors, continue this mathematical legacy, serving as the conduits through which deep learning networks perform complex numerical operations.\n",
    "\n",
    "- **Data Representation:** Similar to how arrays are used to represent data, tensors take center stage in deep learning. They excel at accurately encapsulating data, whether it's images, text, or sound. These versatile data structures channel the essence of information into the neural network's computational fabric.\n",
    "\n",
    "- **Transformations and Operations:** Both arrays and tensors are alike in their transformative nature. They gracefully adapt within their dimensions to accommodate a range of mathematical operations, such as addition, multiplication, and transformation. Just as arrays change during calculations, tensors efficiently absorb operations, enhancing the capabilities of neural networks.\n",
    "\n",
    "## Strong Ties to NumPy Arrays\n",
    "\n",
    "While tensors may seem like a novel concept in the context of deep learning, it's important to recognize their strong connection to arrays, which have long been fundamental in programming and mathematics. Arrays can be seen as simplified versions of tensors, often with fixed dimensions and data types. Tensors, on the other hand, are more flexible and dynamic, allowing for variable dimensions and data types. Tensors also have some additional features and functionalities that make them more suitable for deep learning, such as automatic differentiation, GPU support, and distributed training. However, tensors and arrays are still compatible and interchangeable, thanks to the NumPy library, which provides a common interface for both data structures. NumPy is a popular Python library that offers a variety of tools and functions for working with arrays and tensors. It allows you to easily create, manipulate, and convert arrays and tensors, as well as perform various mathematical and statistical operations on them. NumPy is widely used in scientific computing and data analysis, and it serves as the backbone of many other libraries and frameworks, including TensorFlow. TensorFlow is a leading deep learning framework that provides a comprehensive set of tools and features for building, training, and deploying neural networks. TensorFlow uses tensors as its main data structure, and it relies on NumPy for creating and converting tensors from and to arrays. This makes it easy to integrate TensorFlow with other libraries and frameworks that use arrays, such as Pandas, Scikit-learn, and Matplotlib. By using NumPy and TensorFlow together, you can leverage the power and flexibility of tensors, while also benefiting from the simplicity and familiarity of arrays {cite:p}`prakash2021programming`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AL2hzxorJiWy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b-tqXcJFp8u"
   },
   "source": [
    "`````{admonition} Definition\n",
    ":class: tip\n",
    "\n",
    "**Tensors** are specialized data structures that resemble **multi-dimensional arrays**, but with some key differences and advantages. Tensors have the following characteristics {cite:p}`TensorFlowDocumentation`:\n",
    "\n",
    "- They have a consistent data type, which is referred to as a 'dtype.' The available data types can be found in `tf.dtypes.DType`.\n",
    "- They are immutable, which means that you cannot modify the content of an existing tensor; instead, you create a new tensor when changes are needed. This is similar to how Python treats numbers and strings.\n",
    "- They can have variable dimensions and data types, which makes them more flexible and dynamic than arrays.\n",
    "- They have additional features and functionalities that make them more suitable for deep learning, such as automatic differentiation, GPU support, and distributed training.\n",
    "\n",
    "Tensors are the main data structure used by TensorFlow, a leading deep learning framework that provides a comprehensive set of tools and features for building, training, and deploying neural networks.\n",
    "\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRK5-9EpYbzG"
   },
   "source": [
    "Let's begin our journey into the world of TensorFlow by learning how to create basic tensors. Tensors are the fundamental data structures of TensorFlow, enabling us to work with data in a powerful and flexible way {cite:p}`TensorFlowDocumentation`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSHRFT6LJbxq"
   },
   "source": [
    "## Scalar or Rank-0 Tensor\n",
    "\n",
    "A scalar or rank-0 tensor is a special type of tensor that holds a single value and has no dimensions or axes {cite:p}`TensorFlowDocumentation`. It is the simplest form of a tensor, and it can be used to represent constants, such as numbers or strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5JcgLFR6gHv",
    "outputId": "30845414-e88a-408d-aa9b-6c3c762d309b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mRank-0 Tensor (Scalar) with Integer value:\u001b[0m\n",
      "tf.Tensor(680, shape=(), dtype=int32)\n",
      "\u001b[1;32m\n",
      "Rank-0 Tensor (Scalar) with Boolean value:\u001b[0m\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "\u001b[1;32m\n",
      "Rank-0 Tensor (Scalar) with String value:\u001b[0m\n",
      "tf.Tensor(b'Hello, ENGG 680!', shape=(), dtype=string)\n",
      "\u001b[1;32m\n",
      "Rank-0 Tensor (Scalar) with Float value:\u001b[0m\n",
      "tf.Tensor(3.14159, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "def print_bold(txt, c=31):\n",
    "    \"\"\"\n",
    "    Display text in bold with optional color.\n",
    "\n",
    "    Parameters:\n",
    "    - txt (str): The text to be displayed.\n",
    "    - c (int): Color code for the text (default is 31 for red).\n",
    "    \"\"\"\n",
    "    print(f\"\\033[1;{c}m\" + txt + \"\\033[0m\")\n",
    "\n",
    "# Creating a Rank-0 Tensor (Scalar) with an Integer value\n",
    "# By default, this will be an int32 tensor; more on \"dtypes\" below.\n",
    "rank_0_tensor = tf.constant(680)\n",
    "\n",
    "# Displaying the Rank-0 Tensor\n",
    "print_bold(\"Rank-0 Tensor (Scalar) with Integer value:\", 32)\n",
    "print(rank_0_tensor)\n",
    "\n",
    "# Creating a Rank-0 Tensor (Scalar) with a Boolean value\n",
    "# This will be a bool tensor with a specified dtype.\n",
    "rank_0_tensor_bool = tf.constant(True, dtype=tf.bool)\n",
    "\n",
    "# Displaying the Rank-0 Tensor\n",
    "print_bold(\"\\nRank-0 Tensor (Scalar) with Boolean value:\", 32)\n",
    "print(rank_0_tensor_bool)\n",
    "\n",
    "# Creating a Rank-0 Tensor (Scalar) with a String value\n",
    "# This will be a string tensor with a specified dtype.\n",
    "rank_0_tensor_string = tf.constant(\"Hello, ENGG 680!\", dtype=tf.string)\n",
    "\n",
    "# Displaying the Rank-0 Tensor\n",
    "print_bold(\"\\nRank-0 Tensor (Scalar) with String value:\", 32)\n",
    "print(rank_0_tensor_string)\n",
    "\n",
    "# Creating a Rank-0 Tensor (Scalar) with a Float value\n",
    "# This will be a float64 tensor with a specified dtype.\n",
    "rank_0_tensor_float = tf.constant(3.14159, dtype=tf.float64)\n",
    "\n",
    "# Displaying the Rank-0 Tensor\n",
    "print_bold(\"\\nRank-0 Tensor (Scalar) with Float value:\", 32)\n",
    "print(rank_0_tensor_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXYkn_JrIWiL"
   },
   "source": [
    "```{figure} tf_figs/scalar.png\n",
    "---\n",
    "width: 150px\n",
    "align: center\n",
    "---\n",
    "Tensors with a scalar nature and a shape represented as an empty set of parentheses ().\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdmPAn9fWYs5"
   },
   "source": [
    "## Vector or Rank-1 Tensor\n",
    "\n",
    "A vector or rank-1 tensor is a tensor that has only one dimension or axis. It can be seen as a sequence of values, similar to a list, that has a specific direction. For example, a vector can represent the coordinates of a point in a two-dimensional plane, or the velocity of an object in a three-dimensional space {cite:p}`TensorFlowDocumentation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oZos8o_R6oE7",
    "outputId": "c598092f-8d8e-4157-ea6b-ad17f3d5db8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mRank-1 Tensor (Vector) with Integer values:\u001b[0m\n",
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\n",
      "\u001b[1;31m\n",
      "Rank-1 Tensor (Vector) with String values:\u001b[0m\n",
      "tf.Tensor([b'Hello' b'ENGG' b'680'], shape=(3,), dtype=string)\n",
      "\u001b[1;31m\n",
      "Rank-1 Tensor (Vector) with Boolean values:\u001b[0m\n",
      "tf.Tensor([ True False  True], shape=(3,), dtype=bool)\n",
      "\u001b[1;31m\n",
      "Rank-1 Tensor (Vector) with Complex values:\u001b[0m\n",
      "tf.Tensor([1.+2.j 3.-4.j 5.+6.j], shape=(3,), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "def print_bold(txt, c=31):\n",
    "    \"\"\"\n",
    "    Display text in bold with optional color.\n",
    "\n",
    "    Parameters:\n",
    "    - txt (str): The text to be displayed.\n",
    "    - c (int): Color code for the text (default is 31 for red).\n",
    "    \"\"\"\n",
    "    print(f\"\\033[1;{c}m\" + txt + \"\\033[0m\")\n",
    "\n",
    "# Creating a Rank-1 Tensor (Vector) with integer values\n",
    "# We specify float values to make it a float tensor.\n",
    "rank_1_tensor = tf.constant([1, 2, 3, 4])\n",
    "\n",
    "# Displaying the Rank-1 Tensor\n",
    "print_bold(\"Rank-1 Tensor (Vector) with Integer values:\")\n",
    "print(rank_1_tensor)\n",
    "\n",
    "# Creating a Rank-1 Tensor (Vector) with string values\n",
    "# We specify string values to make it a string tensor.\n",
    "rank_1_tensor = tf.constant([\"Hello\", \"ENGG\", \"680\"])\n",
    "\n",
    "# Displaying the Rank-1 Tensor\n",
    "print_bold(\"\\nRank-1 Tensor (Vector) with String values:\")\n",
    "print(rank_1_tensor)\n",
    "\n",
    "# Creating a Rank-1 Tensor (Vector) with boolean values\n",
    "# We specify boolean values to make it a boolean tensor.\n",
    "rank_1_tensor = tf.constant([True, False, True])\n",
    "\n",
    "# Displaying the Rank-1 Tensor\n",
    "print_bold(\"\\nRank-1 Tensor (Vector) with Boolean values:\")\n",
    "print(rank_1_tensor)\n",
    "\n",
    "# Creating a Rank-1 Tensor (Vector) with complex values\n",
    "# We specify complex values to make it a complex tensor.\n",
    "rank_1_tensor = tf.constant([1 + 2j, 3 - 4j, 5 + 6j])\n",
    "\n",
    "# Displaying the Rank-1 Tensor\n",
    "print_bold(\"\\nRank-1 Tensor (Vector) with Complex values:\")\n",
    "print(rank_1_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVG7d1IXHQhF"
   },
   "source": [
    "```{figure} tf_figs/vector.png\n",
    "---\n",
    "width: 220px\n",
    "align: center\n",
    "---\n",
    "Tensors with a shape of 3 in the context of vector notation.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix or Rank-2 Tensor\n",
    "\n",
    "A matrix or rank-2 tensor is a tensor that has two dimensions or axes. It can be seen as a grid of values, similar to a two-dimensional array, that has a specific row and column structure. For example, a matrix can represent the pixels of an image, the coefficients of a linear system, or the features of a data set {cite:p}`TensorFlowDocumentation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnOIA_xb6u0M",
    "outputId": "b5a61fe7-2e7f-46c1-98d8-a94a49d25651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mRank-2 Tensor (Matrix) with Specific Dtype:\u001b[0m\n",
      "tf.Tensor(\n",
      "[[11 22]\n",
      " [33 44]\n",
      " [55 66]], shape=(3, 2), dtype=int16)\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Creating a Rank-2 Tensor (Matrix) with Specific Dtype\n",
    "# We define a 2x2 matrix and set the data type to float16.\n",
    "rank_2_tensor = tf.constant([[11, 22],\n",
    "                             [33, 44],\n",
    "                             [55, 66]], dtype=tf.int16)\n",
    "\n",
    "# Displaying the Rank-2 Tensor\n",
    "print_bold(\"Rank-2 Tensor (Matrix) with Specific Dtype:\")\n",
    "print(rank_2_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19m72qEPkfxi"
   },
   "source": [
    "```{figure} tf_figs/matrix.png\n",
    "---\n",
    "width: 120px\n",
    "align: center\n",
    "---\n",
    "A matrix with a shape of (3, 2).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to create rank-2 tensors or matrices in TensorFlow is to use the built-in functions that generate tensors with specific values. In this example, we will see how to create rank-2 tensors with random values, zeros, and ones using [**tf.random.uniform**](https://www.tensorflow.org/api_docs/python/tf/random/uniform), [**tf.zeros**](https://www.tensorflow.org/api_docs/python/tf/zeros), and [**tf.ones**](https://www.tensorflow.org/api_docs/python/tf/ones) respectively. These functions take a shape argument that specifies the number of rows and columns of the matrix. For example, shape=(3, 3) means a 3x3 matrix. We can then display the rank-2 tensors using the print function. Here is the code for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mRank-2 Tensor (Matrix) with Random Values:\u001b[0m\n",
      "tf.Tensor(\n",
      "[[0.8024781  0.70768654 0.7383542 ]\n",
      " [0.16242695 0.703591   0.7325984 ]\n",
      " [0.7425693  0.40302432 0.04241037]], shape=(3, 3), dtype=float32)\n",
      "\u001b[1;31m\n",
      "Rank-2 Tensor (Matrix) with Zeros:\u001b[0m\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]], shape=(4, 4), dtype=float32)\n",
      "\u001b[1;31m\n",
      "Rank-2 Tensor (Matrix) with Ones:\u001b[0m\n",
      "tf.Tensor(\n",
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]], shape=(5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Creating a Rank-2 Tensor (Matrix) with Random Values\n",
    "# We use tf.random.uniform to generate a 3x3 matrix with values between 0 and 1.\n",
    "rank_2_tensor_random = tf.random.uniform(shape=(3, 3))\n",
    "\n",
    "# Displaying the Rank-2 Tensor\n",
    "print_bold(\"Rank-2 Tensor (Matrix) with Random Values:\")\n",
    "print(rank_2_tensor_random)\n",
    "\n",
    "# Creating a Rank-2 Tensor (Matrix) with Zeros\n",
    "# We use tf.zeros to create a 4x4 matrix with all zeros.\n",
    "rank_2_tensor_zeros = tf.zeros(shape=(4, 4))\n",
    "\n",
    "# Displaying the Rank-2 Tensor\n",
    "print_bold(\"\\nRank-2 Tensor (Matrix) with Zeros:\")\n",
    "print(rank_2_tensor_zeros)\n",
    "\n",
    "# Creating a Rank-2 Tensor (Matrix) with Ones\n",
    "# We use tf.ones to create a 5x5 matrix with all ones.\n",
    "rank_2_tensor_ones = tf.ones(shape=(5, 5))\n",
    "\n",
    "# Displaying the Rank-2 Tensor\n",
    "print_bold(\"\\nRank-2 Tensor (Matrix) with Ones:\")\n",
    "print(rank_2_tensor_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjFvzcn4_ehD"
   },
   "source": [
    "Tensors Can Have More Axes: Here's an Example with Three Axes {cite:p}`TensorFlowDocumentation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sesW7gw6JkXy",
    "outputId": "5b5f09a1-6e78-4092-9b7a-b8616c366e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mRank-3 Tensor with Three Axes:\u001b[0m\n",
      "tf.Tensor(\n",
      "[[[11 12 13 14]\n",
      "  [15 16 17 18]]\n",
      "\n",
      " [[21 22 23 24]\n",
      "  [25 26 27 28]]\n",
      "\n",
      " [[31 32 33 34]\n",
      "  [35 36 37 38]]], shape=(3, 2, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Creating a Rank-3 Tensor with Three Axes\n",
    "# Here, we have a 3x2 grid of values, and\n",
    "# there's an outer dimension encompassing them.\n",
    "rank_3_tensor = tf.constant([[[11, 12, 13, 14], [15, 16, 17, 18]],\n",
    "                             [[21, 22, 23, 24], [25, 26, 27, 28]],\n",
    "                             [[31, 32, 33, 34], [35, 36, 37, 38]],\n",
    "                             ])\n",
    "\n",
    "# Displaying the Rank-3 Tensor\n",
    "print_bold(\"Rank-3 Tensor with Three Axes:\")\n",
    "print(rank_3_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rM2sTGIkoE3S"
   },
   "source": [
    "```{figure} tf_figs/3d_tensor.png\n",
    "---\n",
    "width: 500px\n",
    "align: center\n",
    "---\n",
    "Visualizing the above 3D Tensor.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Tensors to NumPy Arrays\n",
    "\n",
    "TensorFlow and NumPy are both libraries for scientific computing in Python that provide powerful array objects to store and manipulate multidimensional data. They have some similarities, such as:\n",
    "\n",
    "- They both support various data types, such as int16, float32, bool, etc. In this example, we specify the data type of the tensor as int16 using the dtype argument {cite:p}`TensorFlowDocumentation` {cite:p}`ramsundar2018tensorflow` .\n",
    "- They both have similar methods to create arrays with specific values, such as tf.ones, tf.zeros, np.ones, np.zeros, etc. In this example, we use tf.constant to create a tensor with constant values {cite:p}`TensorFlowDocumentation` {cite:p}`ramsundar2018tensorflow` .\n",
    "- They both have similar attributes to access the shape and size of the arrays, such as tensor.shape, numpy_array.shape, tensor.size, numpy_array.size, etc. In this example, we print the shape of the tensor and the NumPy arrays using the shape attribute {cite:p}`TensorFlowDocumentation` {cite:p}`ramsundar2018tensorflow` .\n",
    "- They both have similar methods to perform mathematical operations on the arrays, such as tf.add, tf.multiply, np.add, np.multiply, etc. In this example, we do not perform any operations, but we could do so if we wanted to {cite:p}`TensorFlowDocumentation` {cite:p}`ramsundar2018tensorflow` .\n",
    "\n",
    "However, they also have some differences, such as:\n",
    "\n",
    "- TensorFlow tensors are immutable, meaning that they cannot be modified once created. NumPy arrays are mutable, meaning that they can be modified in place. In this example, we cannot change the values of the tensor, but we can change the values of the NumPy arrays {cite:p}`TensorFlowDocumentation` {cite:p}`ramsundar2018tensorflow` .\n",
    "- TensorFlow tensors can be used to build and run computational graphs that can perform automatic differentiation and optimization for machine learning models {cite:p}`g√©ron2022hands` . NumPy arrays do not have this capability, and are mainly used for numerical analysis and data manipulation. In this example, we do not use any computational graphs, but we could do so if we wanted to build a machine learning model using TensorFlow {cite:p}`abadi2016tensorflow`.\n",
    "- TensorFlow tensors can be executed on different devices, such as CPUs, GPUs, or TPUs, to accelerate the computation {cite:p}`abadi2016tensorflow`. NumPy arrays can only be executed on CPUs, and do not support parallelization or distribution. In this example, we do not specify any device, but we could do so if we wanted to use a different device for the tensor computation {cite:p}`TensorFlowDocumentation` {cite:p}`ramsundar2018tensorflow` .\n",
    "\n",
    "To illustrate how to convert tensors to NumPy arrays, we will use the following code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mNumPy array:\u001b[0m\n",
      "array([[0, 6, 5],\n",
      "       [4, 2, 3]])\n",
      "\u001b[1;31m\n",
      "TensorFlow tensor:\u001b[0m\n",
      "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "array([[0, 6, 5],\n",
      "       [4, 2, 3]])>\n",
      "\u001b[1;31m\n",
      "NumPy array after adding 1:\u001b[0m\n",
      "array([[1, 7, 6],\n",
      "       [5, 3, 4]])\n",
      "\u001b[1;31m\n",
      "TensorFlow tensor after adding 1:\u001b[0m\n",
      "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "array([[1, 7, 6],\n",
      "       [5, 3, 4]])>\n",
      "\u001b[1;31m\n",
      "NumPy array after multiplying by 2:\u001b[0m\n",
      "array([[ 2, 14, 12],\n",
      "       [10,  6,  8]])\n",
      "\u001b[1;31m\n",
      "TensorFlow tensor after multiplying by 2:\u001b[0m\n",
      "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
      "array([[ 2, 14, 12],\n",
      "       [10,  6,  8]])>\n",
      "\u001b[1;31m\n",
      "NumPy array converted from TensorFlow tensor:\u001b[0m\n",
      "array([[ 2, 14, 12],\n",
      "       [10,  6,  8]])\n"
     ]
    }
   ],
   "source": [
    "# Import NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "\n",
    "def print_bold(txt, c=31):\n",
    "    \"\"\"\n",
    "    Display text in bold with optional color.\n",
    "\n",
    "    Parameters:\n",
    "    - txt (str): The text to be displayed.\n",
    "    - c (int): Color code for the text (default is 31 for red).\n",
    "    \"\"\"\n",
    "    print(f\"\\033[1;{c}m\" + txt + \"\\033[0m\")\n",
    "\n",
    "# Create a 2D array of shape (2, 3) with random values\n",
    "np_array = np.random.randint(0, 9, size=(2, 3))\n",
    "print_bold(\"NumPy array:\")\n",
    "pprint(np_array)\n",
    "\n",
    "# Convert the NumPy array to a TensorFlow tensor\n",
    "tf_tensor = tf.convert_to_tensor(np_array)\n",
    "print_bold(\"\\nTensorFlow tensor:\")\n",
    "pprint(tf_tensor)\n",
    "\n",
    "# Perform element-wise operations on both the array and the tensor\n",
    "np_array = np_array + 1  # Add 1 to each element\n",
    "tf_tensor = tf_tensor + 1  # Add 1 to each element\n",
    "print_bold(\"\\nNumPy array after adding 1:\")\n",
    "pprint(np_array)\n",
    "print_bold(\"\\nTensorFlow tensor after adding 1:\")\n",
    "pprint(tf_tensor)\n",
    "\n",
    "np_array = np_array * 2  # Multiply each element by 2\n",
    "tf_tensor = tf_tensor * 2  # Multiply each element by 2\n",
    "print_bold(\"\\nNumPy array after multiplying by 2:\")\n",
    "pprint(np_array)\n",
    "\n",
    "print_bold(\"\\nTensorFlow tensor after multiplying by 2:\")\n",
    "pprint(tf_tensor)\n",
    "\n",
    "# Convert the TensorFlow tensor back to a NumPy array\n",
    "np_array2 = tf_tensor.numpy()\n",
    "print_bold(\"\\nNumPy array converted from TensorFlow tensor:\")\n",
    "pprint(np_array2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Blue'><b>Example:</b></font> In this example,  we demonstrate that tensors are immutable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Import NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a 2D tensor of shape (2, 3) with constant values and int16 data type\n",
    "tensor = tf.constant([[1, 2, 3], [4, 5, 6]], dtype=tf.int16)\n",
    "print(\"TensorFlow tensor:\\n\", tensor)\n",
    "\n",
    "# Convert the tensor to a NumPy array using the tensor.numpy method\n",
    "array = tensor.numpy()\n",
    "print(\"NumPy array converted from TensorFlow tensor:\\n\", array)\n",
    "\n",
    "# Try to modify the first element of the first row of both the array and the tensor\n",
    "array[0, 0] = 100 # This works, as NumPy arrays are mutable\n",
    "tensor[0, 0] = 100 # This fails, as TensorFlow tensors are immutable\n",
    "```\n",
    "\n",
    "The output of this code is:\n",
    "\n",
    "```\n",
    "TensorFlow tensor:\n",
    " tf.Tensor(\n",
    "[[1 2 3]\n",
    " [4 5 6]], shape=(2, 3), dtype=int16)\n",
    "NumPy array converted from TensorFlow tensor:\n",
    " [[1 2 3]\n",
    " [4 5 6]]\n",
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "Cell In[30], line 12\n",
    "     11 array[0, 0] = 100 # This works, as NumPy arrays are mutable\n",
    "---> 12 tensor[0, 0] = 100 # This fails, as TensorFlow tensors are immutable\n",
    "\n",
    "TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the NumPy array can be modified in place, but the TensorFlow tensor cannot. This is because TensorFlow tensors are immutable, meaning that they cannot be changed once created {cite:p}`TensorFlowDocumentation`. This is a design choice that allows TensorFlow to optimize the computation and memory usage of tensors, especially when they are used in computational graphs. If you want to change the values of a tensor, you need to create a new tensor with the updated values. For example, you can use the tf.assign function to assign new values to a variable that holds a tensor {cite:p}`TensorFlowDocumentation` . Here is an example of how to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mTensorFlow Variable:\u001b[0m\n",
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int16, numpy=\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6]], dtype=int16)>\n",
      "\u001b[1;31m\n",
      "TensorFlow Variable after assigning 100 to the first element of the first row:\u001b[0m\n",
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int16, numpy=\n",
      "array([[100,   2,   3],\n",
      "       [  4,   5,   6]], dtype=int16)>\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a variable that holds a 2D tensor of shape (2, 3) with constant values and int16 data type\n",
    "var = tf.Variable([[1, 2, 3], [4, 5, 6]], dtype=tf.int16)\n",
    "print_bold(\"TensorFlow Variable:\")\n",
    "print(var)\n",
    "\n",
    "# Try to modify the first element of the first row of the variable using the tf.assign function\n",
    "var[0, 0].assign(100)  # This works, as variables can be updated using the assign method\n",
    "print_bold(\"\\nTensorFlow Variable after assigning 100 to the first element of the first row:\")\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the variable can be updated using the assign method, which creates a new tensor with the updated values and assigns it to the variable. This is different from modifying the tensor directly, which is not possible. This example demonstrates how to update the values of a tensor using the tf.assign function {cite:p}`TensorFlowDocumentation`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDmFtFM7k0R2"
   },
   "source": [
    "## Data Types in TensorFlow\n",
    "\n",
    "To examine the data type of a `tf.Tensor`, you can utilize the `Tensor.dtype` property. When generating a `tf.Tensor` from a Python object, you have the option to specify the data type if desired {cite:p}`TensorFlowDocumentation`.\n",
    "\n",
    "In cases where you don't specify a data type, TensorFlow automatically selects an appropriate one to accommodate your data. For instance, TensorFlow converts Python integers to `tf.int32` and Python floating-point numbers to `tf.float32`. In other scenarios, TensorFlow applies the same conventions as NumPy does when converting to arrays {cite:p}`TensorFlowDocumentation`.\n",
    "\n",
    "Moreover, TensorFlow permits you to perform type casting, enabling you to switch between different data types as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5mSTDWbelUvu",
    "outputId": "28740d39-7819-4fe9-b6af-bf4654df40ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mOriginal Float64 Tensor:\u001b[0m\n",
      "tf.Tensor([2.2 3.3 4.4], shape=(3,), dtype=float64)\n",
      "\u001b[1;31m\n",
      "Float64 Tensor cast to Float16:\u001b[0m\n",
      "tf.Tensor([2.2 3.3 4.4], shape=(3,), dtype=float16)\n",
      "\u001b[1;31m\n",
      "Float16 Tensor cast to Uint8:\u001b[0m\n",
      "tf.Tensor([2 3 4], shape=(3,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a tensor with float64 data type\n",
    "the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)\n",
    "print_bold(\"Original Float64 Tensor:\")\n",
    "print(the_f64_tensor)\n",
    "\n",
    "# Cast the float64 tensor to float16\n",
    "the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)\n",
    "print_bold(\"\\nFloat64 Tensor cast to Float16:\")\n",
    "print(the_f16_tensor)\n",
    "\n",
    "# Cast the float16 tensor to uint8 (unsigned 8-bit integer)\n",
    "# This will lead to loss of decimal precision\n",
    "the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)\n",
    "print_bold(\"\\nFloat16 Tensor cast to Uint8:\")\n",
    "print(the_u8_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1yBlJsVlFSu"
   },
   "source": [
    "## Broadcasting\n",
    "\n",
    "Broadcasting is a concept adopted from the [equivalent feature in NumPy](https://numpy.org/doc/stable/user/basics.broadcasting.html). In essence, broadcasting enables smaller tensors to be automatically expanded to match the dimensions of larger tensors when performing combined operations on them {cite:p}`TensorFlowDocumentation`.\n",
    "\n",
    "The most straightforward and frequent scenario occurs when you try to multiply or add a tensor by a scalar value. In this instance, the scalar value is broadcasted, causing it to take on the same shape as the other tensor in the operation. This seamless extension of dimensions facilitates efficient computation of operations involving tensors with varying shapes {cite:p}`TensorFlowDocumentation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8sypqmagHQN",
    "outputId": "3aa37a32-6ec2-49aa-aebd-485731225e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mOriginal Tensor:\u001b[0m\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "\u001b[1;31m\n",
      "Result 1 (Scalar Broadcasting):\u001b[0m\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
      "\u001b[1;31m\n",
      "Result 2 (Scalar Broadcasting using Operator):\u001b[0m\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
      "\u001b[1;31m\n",
      "Result 3 (Tensor Broadcasting):\u001b[0m\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a constant tensor\n",
    "x = tf.constant([1, 2, 3])\n",
    "print_bold(\"Original Tensor:\")\n",
    "print(x)\n",
    "\n",
    "# Define scalar and tensor constants\n",
    "y = tf.constant(2)\n",
    "z = tf.constant([2, 2, 2])\n",
    "\n",
    "# Perform the same computation using different expressions\n",
    "result1 = tf.multiply(x, 2)  # Broadcasting scalar to tensor\n",
    "result2 = x * y  # Broadcasting scalar to tensor using operator\n",
    "result3 = x * z  # Broadcasting tensor to tensor\n",
    "\n",
    "# Print the results\n",
    "print_bold(\"\\nResult 1 (Scalar Broadcasting):\")\n",
    "print(result1)\n",
    "print_bold(\"\\nResult 2 (Scalar Broadcasting using Operator):\")\n",
    "print(result2)\n",
    "print_bold(\"\\nResult 3 (Tensor Broadcasting):\")\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0SBoR6voWcb"
   },
   "source": [
    "Similarly, axes with a length of 1 can be extended to align with the dimensions of other arguments during operations. This extension can be applied to both operands simultaneously within a single computation {cite:p}`TensorFlowDocumentation`.\n",
    "\n",
    "In the example, a 3x1 matrix is multiplied element-wise with a 1x4 matrix, resulting in a 3x4 matrix. It's worth noting that the leading 1 in the matrix dimensions is not strictly required. For instance, the shape of matrix `y` can be expressed as `[4]`, highlighting that broadcasting effectively accounts for dimensions of length 1, regardless of whether they are explicitly stated {cite:p}`TensorFlowDocumentation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6sGmkPg3XANr",
    "outputId": "a9d60136-2b60-49f3-c0db-76d779258da1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mOriginal Tensor:\u001b[0m\n",
      "tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n",
      "\u001b[1;31m\n",
      "Reshaped x:\u001b[0m\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]], shape=(5, 1), dtype=int32)\n",
      "\u001b[1;31m\n",
      "y:\u001b[0m\n",
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\n",
      "\u001b[1;31mResult of Element-wise Multiplication:\u001b[0m\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]\n",
      " [ 4  8 12 16]\n",
      " [ 5 10 15 20]], shape=(5, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a tensor\n",
    "x = tf.constant([1, 2, 3, 4, 5])\n",
    "print_bold(\"Original Tensor:\")\n",
    "print(x)\n",
    "x = tf.reshape(x, [5, 1])\n",
    "print_bold(\"\\nReshaped x:\")\n",
    "print(x)\n",
    "\n",
    "# Create a tensor with values ranging from 1 to 4\n",
    "y = tf.range(1, 5)\n",
    "print_bold(\"\\ny:\")\n",
    "print(y)\n",
    "\n",
    "# Perform element-wise multiplication using broadcasting\n",
    "result = tf.multiply(x, y)\n",
    "print_bold(\"Result of Element-wise Multiplication:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's express the mathematical representation of the element-wise multiplication operation performed in the provided TensorFlow code:\n",
    "\n",
    "Given the tensors $ x $ and $ y $:\n",
    "\n",
    "\\begin{equation} x = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\\\ 5 \\end{bmatrix} \\end{equation}\n",
    "\n",
    "\\begin{equation} y = \\begin{bmatrix} 1 & 2 & 3 & 4 \\end{bmatrix} \\end{equation}\n",
    "\n",
    "The element-wise multiplication $ \\text{result} $ is obtained by broadcasting $ y $ across the columns of $ x $:\n",
    "\n",
    "\\begin{equation} \\text{result} = \\begin{bmatrix} 1 \\times 1 & 1 \\times 2 & 1 \\times 3 & 1 \\times 4 \\\\ 2 \\times 1 & 2 \\times 2 & 2 \\times 3 & 2 \\times 4 \\\\ 3 \\times 1 & 3 \\times 2 & 3 \\times 3 & 3 \\times 4 \\\\ 4 \\times 1 & 4 \\times 2 & 4 \\times 3 & 4 \\times 4 \\\\ 5 \\times 1 & 5 \\times 2 & 5 \\times 3 & 5 \\times 4 \\end{bmatrix} \\end{equation}\n",
    "\n",
    "Simplifying the multiplication results in the final element-wise product matrix:\n",
    "\n",
    "\\begin{equation} \\text{result} = \\begin{bmatrix} 1 & 2 & 3 & 4 \\\\ 2 & 4 & 6 & 8 \\\\ 3 & 6 & 9 & 12 \\\\ 4 & 8 & 12 & 16 \\\\ 5 & 10 & 15 & 20 \\end{bmatrix} \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7NyG7LAutT0"
   },
   "source": [
    "```{figure} tf_figs/tf_broadcast.png\n",
    "---\n",
    "width: 500px\n",
    "align: center\n",
    "---\n",
    "A broadcasted addition occurs when a tensor with shape [5, 1] is combined with another tensor of shape [1, 4], resulting in a new tensor with shape [5, 4].\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V3KgSJcKDRz"
   },
   "source": [
    "Here is the same operation conducted without utilizing broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elrF6v63igY8",
    "outputId": "0b1e9395-8ad2-4e83-f8fb-5f1228ca12e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mElement-wise Multiplication Without Broadcasting:\u001b[0m\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]\n",
      " [ 4  8 12 16]\n",
      " [ 5 10 15 20]], shape=(5, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define tensors for multiplication without broadcasting\n",
    "x_stretch = tf.constant([[1, 1, 1, 1],\n",
    "                         [2, 2, 2, 2],\n",
    "                         [3, 3, 3, 3],\n",
    "                         [4, 4, 4, 4],\n",
    "                         [5, 5, 5, 5]])\n",
    "\n",
    "y_stretch = tf.constant([[1, 2, 3, 4],\n",
    "                         [1, 2, 3, 4],\n",
    "                         [1, 2, 3, 4],\n",
    "                         [1, 2, 3, 4],\n",
    "                         [1, 2, 3, 4]])\n",
    "\n",
    "# Perform element-wise multiplication without broadcasting\n",
    "result = x_stretch * y_stretch\n",
    "\n",
    "# Print the result\n",
    "print_bold(\"Element-wise Multiplication Without Broadcasting:\")\n",
    "print(result)  # Operator overloading performs element-wise multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14KobqYu85gi"
   },
   "source": [
    "In the majority of cases, broadcasting proves to be efficient in terms of both time and space. This efficiency arises from the fact that the broadcast operation doesn't physically create expanded tensors in memory {cite:p}`TensorFlowDocumentation`.\n",
    "\n",
    "To observe the visual representation of broadcasting, you can use the `tf.broadcast_to` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GW2Q59_r8hZ6",
    "outputId": "75f329b6-6fcb-45bb-95d9-35e3a82e1bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mBroadcasted Tensor:\u001b[0m\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Use tf.broadcast_to to demonstrate broadcasting\n",
    "broadcasted_tensor = tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3])\n",
    "\n",
    "# Print the broadcasted tensor\n",
    "print_bold(\"Broadcasted Tensor:\")\n",
    "print(broadcasted_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2bAMMQY-jpP"
   },
   "source": [
    "`````{admonition} Remark\n",
    ":class: important\n",
    "\n",
    "Unlike certain mathematical operations, the `broadcast_to` function doesn't implement memory-saving mechanisms. In this case, you are essentially creating the expanded tensor in memory {cite:p}`TensorFlowDocumentation`.\n",
    "\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Shapes and Indexing\n",
    "\n",
    "Tensors have shapes that describe how many elements they contain along each dimension. To work with tensors effectively, we need to understand some concepts related to their shapes {cite:p}`TensorFlowDocumentation`:\n",
    "\n",
    "* **Shape**: The shape of a tensor is a vector that shows the length (number of elements) of each dimension. For example, a tensor with shape `[2, 3]` has two dimensions, and each dimension has three elements.\n",
    "* **Rank**: The rank of a tensor is the number of dimensions it has. A scalar (a single number) has rank 0, a vector (a list of numbers) has rank 1, and a matrix (a table of numbers) has rank 2. The rank of a tensor is also the length of its shape vector.\n",
    "* **Axis** or **Dimension**: An axis or a dimension of a tensor is a specific direction or dimension that the tensor has. For example, a matrix has two axes: the first axis (axis 0) is the rows, and the second axis (axis 1) is the columns. We can use the axis index to access or modify a slice of a tensor along that axis.\n",
    "* **Size**: The size of a tensor is the total number of elements it contains. We can calculate the size of a tensor by multiplying the elements of its shape vector. For example, a tensor with shape `[2, 3]` has a size of 6.\n",
    "\n",
    "These concepts help us understand the structure and dimensions of tensors, which are essential for working with TensorFlow {cite:p}`TensorFlowDocumentation`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Tensor Shapes with `tf.TensorShape` Objects\n",
    "\n",
    "Both tensors and `tf.TensorShape` objects have properties that allow us to access information about their shapes {cite:p}`TensorFlowDocumentation`:\n",
    "\n",
    "* **`ndim`**: This property returns the rank of the tensor, which is the number of dimensions it has. For example, a scalar has `ndim` of 0, a vector has `ndim` of 1, and a matrix has `ndim` of 2.\n",
    "* **`shape`**: This property gives a tuple of integers that represent the length of each dimension of the tensor. For example, a tensor with shape `(2, 3)` has two dimensions, and each dimension has three elements.\n",
    "* **`as_list()`**: This method converts the shape tuple to a Python list, which can be useful for manipulating or indexing the shape. For example, we can use `as_list()` to get the first element of the shape tuple, which is the size of the first dimension of the tensor.\n",
    "\n",
    "Let's see how we can use these properties to access the shapes of tensors {cite:p}`TensorFlowDocumentation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of every element:\t\t\t\t <dtype: 'float32'>\n",
      "Number of axes:\t\t\t\t\t 4\n",
      "Shape of tensor:\t\t\t\t (3, 2, 4, 5)\n",
      "Elements along axis 0 of tensor:\t\t 3\n",
      "Elements along the last axis of tensor:\t\t 5\n",
      "Total number of elements (3*2*4*5):\t\t 120\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Creating a Rank-4 Tensor\n",
    "rank_4_tensor = tf.zeros([3, 2, 4, 5])\n",
    "\n",
    "# Accessing shape information\n",
    "shape_object = rank_4_tensor.shape\n",
    "rank = rank_4_tensor.ndim\n",
    "shape_list = rank_4_tensor.shape.as_list()\n",
    "\n",
    "# Accessing shape and other information\n",
    "print(\"Type of every element:\" + 4*'\\t', rank_4_tensor.dtype)\n",
    "print(\"Number of axes:\" + 5*'\\t', rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\"  + 4*'\\t', rank_4_tensor.shape)\n",
    "print(\"Elements along axis 0 of tensor:\"  + 2*'\\t', rank_4_tensor.shape[0])\n",
    "print(\"Elements along the last axis of tensor:\"  + 2*'\\t', rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elements (3*2*4*5):\"  + 2*'\\t', tf.size(rank_4_tensor).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} tf_figs/4d_tensor.png\n",
    "---\n",
    "width: 450px\n",
    "align: center\n",
    "---\n",
    "A rank-4 tensor, shape: [3, 2, 4, 5]. Image courtesy of TensorFlow documentation {cite:p}`TensorFlowDocumentation`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Tensors\n",
    "\n",
    "### Single-Axis Indexing\n",
    "\n",
    "TensorFlow employs standard Python indexing conventions, akin to [indexing a list or a string in Python](https://docs.python.org/3/tutorial/introduction.html#strings), and similar to NumPy indexing {cite:p}`TensorFlowDocumentation`.\n",
    "\n",
    "Here are the fundamental rules {cite:p}`TensorFlowDocumentation`:\n",
    "\n",
    "* Indexing begins at `0`.\n",
    "* Negative indices count in reverse from the end.\n",
    "* Slices are defined using colons, `:`, in the format `start:stop:step`.\n",
    "\n",
    "These indexing principles facilitate efficient access and manipulation of tensor elements, enabling you to work with tensors just like you would with arrays or lists in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mOriginal Tensor:\u001b[0m\n",
      "[  0   1   1   2   3   4   8  18  21  25 101 201]\n",
      "First: 0\n",
      "Second: 1\n",
      "Last: 201\n",
      "Everything: [  0   1   1   2   3   4   8  18  21  25 101 201]\n",
      "Before 4: [0 1 1 2]\n",
      "From 4 to the end: [  3   4   8  18  21  25 101 201]\n",
      "From 2, before 7: [1 2 3 4 8]\n",
      "Every other item: [  0   1   3   8  21 101]\n",
      "Reversed: [201 101  25  21  18   8   4   3   2   1   1   0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Creating a tensor\n",
    "tensor = tf.constant([0, 1, 1, 2, 3, 4, 8, 18, 21, 25, 101, 201])\n",
    "print_bold(\"Original Tensor:\")\n",
    "print(tensor.numpy())  # Displaying the original tensor\n",
    "\n",
    "# Indexing operations\n",
    "print(\"First:\", tensor[0].numpy())           # Access the first element (index 0)\n",
    "print(\"Second:\", tensor[1].numpy())          # Access the second element (index 1)\n",
    "print(\"Last:\", tensor[-1].numpy())           # Access the last element using negative index\n",
    "print(\"Everything:\", tensor[:].numpy())      # Access all elements (the entire tensor)\n",
    "print(\"Before 4:\", tensor[:4].numpy())       # Access elements up to but not including index 4\n",
    "print(\"From 4 to the end:\", tensor[4:].numpy())  # Access elements from index 4 to the end\n",
    "print(\"From 2, before 7:\", tensor[2:7].numpy())  # Access elements starting from index 2 up to but not including index 7\n",
    "print(\"Every other item:\", tensor[::2].numpy())  # Access every other element (step size of 2)\n",
    "print(\"Reversed:\", tensor[::-1].numpy())     # Access elements in reverse order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- `tensor[0].numpy()` retrieves the first element of the tensor, which is `0`.\n",
    "- `tensor[1].numpy()` retrieves the second element, which is `1`.\n",
    "- `tensor[-1].numpy()` retrieves the last element, which is `201`, using negative indexing.\n",
    "- `tensor[:]` accesses the entire tensor, resulting in `[0, 1, 1, 2, 3, 4, 8, 18, 21, 25, 101, 201]`.\n",
    "- `tensor[:4]` gets elements up to but not including index 4, resulting in `[0, 1, 1, 2]`.\n",
    "- `tensor[4:]` retrieves elements from index 4 to the end, giving `[3, 4, 8, 18, 21, 25, 101, 201]`.\n",
    "- `tensor[2:7]` accesses elements starting from index 2 up to but not including index 7, yielding `[1, 2, 3, 4, 8]`.\n",
    "- `tensor[::2]` retrieves every other element with a step size of 2, resulting in `[0, 1, 3, 8, 21, 101]`.\n",
    "- `tensor[::-1]` accesses the elements in reverse order, giving `[201, 101, 25, 21, 18, 8, 4, 3, 2, 1, 1, 0]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Axis Indexing\n",
    "\n",
    "For tensors with higher ranks (more dimensions), indexing involves passing multiple indices {cite:p}`TensorFlowDocumentation`. Crucially, the same rules as in the single-axis case apply to each axis independently. This means that you can apply the familiar indexing rules to each axis of the tensor, allowing for precise element selection within multi-dimensional structures {cite:p}`TensorFlowDocumentation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mOriginal Tensor:\u001b[0m\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\u001b[1;31m\n",
      "Scalar Value at (1, 1):\u001b[0m\n",
      "5\n",
      "\u001b[1;31m\n",
      "Second row:\u001b[0m\n",
      "[4 5 6]\n",
      "\u001b[1;31m\n",
      "Second column:\u001b[0m\n",
      "[2 5]\n",
      "\u001b[1;31m\n",
      "Last row:\u001b[0m\n",
      "[4 5 6]\n",
      "\u001b[1;31m\n",
      "First item in last column:\u001b[0m\n",
      "3\n",
      "\u001b[1;31m\n",
      "Skip the first row:\u001b[0m\n",
      "[[4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# Creating a Rank-2 Tensor\n",
    "rank_2_tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Displaying the original tensor\n",
    "print_bold(\"Original Tensor:\")\n",
    "print(rank_2_tensor.numpy())\n",
    "\n",
    "# Indexing to retrieve a scalar value\n",
    "print_bold(\"\\nScalar Value at (1, 1):\")\n",
    "print(rank_2_tensor[1, 1].numpy())\n",
    "# Indexing using a combination of integers and slices\n",
    "print_bold(\"\\nSecond row:\")\n",
    "print(rank_2_tensor[1, :].numpy())\n",
    "print_bold(\"\\nSecond column:\")\n",
    "print(rank_2_tensor[:, 1].numpy())\n",
    "print_bold(\"\\nLast row:\")\n",
    "print(rank_2_tensor[-1, :].numpy())\n",
    "print_bold(\"\\nFirst item in last column:\")\n",
    "print(rank_2_tensor[0, -1].numpy())\n",
    "print_bold(\"\\nSkip the first row:\")\n",
    "print(rank_2_tensor[1:, :].numpy())  # Outputs [[4 5 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mRank-3 Tensor with Three Axes:\u001b[0m\n",
      "tf.Tensor(\n",
      "[[[11 12 13 14]\n",
      "  [15 16 17 18]]\n",
      "\n",
      " [[21 22 23 24]\n",
      "  [25 26 27 28]]\n",
      "\n",
      " [[31 32 33 34]\n",
      "  [35 36 37 38]]], shape=(3, 2, 4), dtype=int32)\n",
      "\u001b[1;31m\n",
      "2D Tensor along All Axes:\u001b[0m\n",
      "tf.Tensor(\n",
      "[[14 18]\n",
      " [24 28]\n",
      " [34 38]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Creating a Rank-3 Tensor with Three Axes\n",
    "# Here, we have a 3x2 grid of values, and\n",
    "# there's an outer dimension encompassing them.\n",
    "rank_3_tensor = tf.constant([[[11, 12, 13, 14], [15, 16, 17, 18]],\n",
    "                             [[21, 22, 23, 24], [25, 26, 27, 28]],\n",
    "                             [[31, 32, 33, 34], [35, 36, 37, 38]],\n",
    "                             ])\n",
    "\n",
    "# Displaying the Rank-3 Tensor\n",
    "print_bold(\"Rank-3 Tensor with Three Axes:\")\n",
    "print(rank_3_tensor)\n",
    "\n",
    "# Indexing along all axes to retrieve a 2D tensor\n",
    "print_bold(\"\\n2D Tensor along All Axes:\")\n",
    "print(rank_3_tensor[:, :, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} tf_figs/Multiaxis_indexing.png\n",
    "---\n",
    "width: 450px\n",
    "align: center\n",
    "---\n",
    "Selecting the final feature from all 2d slices.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Tensor Shapes\n",
    "\n",
    "The ability to reshape a tensor is incredibly valuable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape as TensorShape object: (5, 1)\n",
      "Shape as Python list: [5, 1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Creating a tensor\n",
    "x = tf.constant([[101], [102], [103], [104], [105]])\n",
    "\n",
    "# Accessing shape information using shape property\n",
    "shape_object = x.shape\n",
    "print(\"Shape as TensorShape object:\", shape_object)\n",
    "\n",
    "# Converting TensorShape object to a Python list\n",
    "shape_list = x.shape.as_list()\n",
    "print(\"Shape as Python list:\", shape_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Facilitating the transformation of tensor structures into novel configurations is a task of inherent importance. Notably, the `tf.reshape` operation stands out for its efficiency and resource efficiency, distinctively characterized by its avoidance of redundant data replication.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: (5, 1)\n",
      "Reshaped Shape: (1, 5)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Creating a tensor\n",
    "x = tf.constant([[101], [102], [103], [104], [105]])\n",
    "\n",
    "# Reshaping the tensor to a new shape\n",
    "reshaped = tf.reshape(x, [1, 5])\n",
    "\n",
    "# Displaying original and reshaped shapes\n",
    "print(\"Original Shape:\", x.shape)\n",
    "print(\"Reshaped Shape:\", reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When reshaping a tensor in TensorFlow, the underlying data retains its original arrangement in memory. Instead of physically reorganizing the data, a new tensor with the desired shape is generated, while still referencing the same data in memory. TensorFlow follows a memory layout known as \"row-major,\" which means that the elements of a row are stored adjacently in memory. Consequently, incrementing the index on the rightmost side corresponds to traversing through memory in contiguous steps, effectively moving to the next element in the same row. This approach optimizes memory access patterns and aligns with the structure commonly used in C-style programming languages {cite:p}`TensorFlowDocumentation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mRank-3 Tensor with Three Axes:\u001b[0m\n",
      "tf.Tensor(\n",
      "[[[11 12 13 14]\n",
      "  [15 16 17 18]]\n",
      "\n",
      " [[21 22 23 24]\n",
      "  [25 26 27 28]]\n",
      "\n",
      " [[31 32 33 34]\n",
      "  [35 36 37 38]]], shape=(3, 2, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Creating a Rank-3 Tensor with Three Axes\n",
    "# Here, we have a 3x2 grid of values, and\n",
    "# there's an outer dimension encompassing them.\n",
    "rank_3_tensor = tf.constant([[[11, 12, 13, 14], [15, 16, 17, 18]],\n",
    "                             [[21, 22, 23, 24], [25, 26, 27, 28]],\n",
    "                             [[31, 32, 33, 34], [35, 36, 37, 38]],\n",
    "                             ])\n",
    "\n",
    "# Displaying the Rank-3 Tensor\n",
    "print_bold(\"Rank-3 Tensor with Three Axes:\")\n",
    "print(rank_3_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening a tensor provides insight into the sequence in which its elements are organized within memory {cite:p}`TensorFlowDocumentation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([11 12 13 14 15 16 17 18 21 22 23 24 25 26 27 28 31 32 33 34 35 36 37 38], shape=(24,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the tensor using '-1'\n",
    "# The '-1' indicates TensorFlow should determine the size along this axis automatically\n",
    "flattened_tensor = tf.reshape(rank_3_tensor, [-1])\n",
    "\n",
    "# Print the flattened tensor\n",
    "print(flattened_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} tf_figs/flattening_rank_3_tensor.png\n",
    "---\n",
    "width: 700px\n",
    "align: center\n",
    "---\n",
    "Flattening a rank 3 tensor.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we're using the -1 value in the shape argument of the tf.reshape function. This value essentially tells TensorFlow to calculate the size along that axis so that the total number of elements remains constant. The comments explain how the -1 value works and its purpose in the reshaping process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, the `tf.reshape` function is most useful when you need to merge or split neighboring axes, or when you want to add or remove dimensions with a size of `1` {cite:p}`TensorFlowDocumentation`.\n",
    "\n",
    "For the given 3x2x5 tensor, reshaping it into a (3x2)x5 format or into a 3x(2x5) format are both logical operations. This is because the reshaping maintains separate slices that do not overlap, allowing you to rearrange the data without mixing elements {cite:p}`TensorFlowDocumentation`:\n",
    "\n",
    "- Reshaping to (3x2)x5: This results in three rows of two-by-five matrices, effectively combining the inner dimensions. Each new row holds a set of elements that originally resided in different inner matrices.\n",
    "- Reshaping to 3x(2x5): This keeps the outermost dimension (3) intact while splitting the second dimension (2x5) into separate inner matrices. Each new column of the reshaped tensor contains elements from one of the original 2x5 matrices. Both reshaping approaches maintain the data integrity and relationships between elements {cite:p}`TensorFlowDocumentation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mReshape to (6, 4):\u001b[0m\n",
      "tf.Tensor(\n",
      "[[11 12 13 14]\n",
      " [15 16 17 18]\n",
      " [21 22 23 24]\n",
      " [25 26 27 28]\n",
      " [31 32 33 34]\n",
      " [35 36 37 38]], shape=(6, 4), dtype=int32)\n",
      "\u001b[1;31m\n",
      "Reshape to (3, 8):\u001b[0m\n",
      "tf.Tensor(\n",
      "[[11 12 13 14 15 16 17 18]\n",
      " [21 22 23 24 25 26 27 28]\n",
      " [31 32 33 34 35 36 37 38]], shape=(3, 8), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print_bold('Reshape to (6, 4):')\n",
    "print(tf.reshape(rank_3_tensor, [3*2, 4]))\n",
    "print_bold('\\nReshape to (3, 8):')\n",
    "print(tf.reshape(rank_3_tensor, [3, -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} tf_figs/tf_reshape.png\n",
    "---\n",
    "width: 400px\n",
    "align: center\n",
    "---\n",
    "Visualizing reshaping `rank_3_tensor` tensor.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping a tensor can be successfully performed for any new shape that maintains the same total count of elements. However, it's important to note that reshaping won't yield meaningful results if the arrangement of axes isn't honored {cite:p}`TensorFlowDocumentation`.\n",
    "\n",
    "If you intend to rearrange the order of axes, using `tf.reshape` won't suffice. Instead, for swapping or permuting axes, the appropriate function to use is `tf.transpose`. Reshaping merely alters the dimensions while preserving the sequence of elements, ensuring that you maintain the correct data relationships. Conversely, when you need to modify the order of the dimensions, such as swapping axes, `tf.transpose` is the suitable choice to achieve that specific transformation {cite:p}`TensorFlowDocumentation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot reorder axes with reshape:\n",
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]\n",
      "  [10 11 12 13 14]]\n",
      "\n",
      " [[15 16 17 18 19]\n",
      "  [20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32) \n",
      "\n",
      "Incorrect dimensions specified:\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4  5]\n",
      " [ 6  7  8  9 10 11]\n",
      " [12 13 14 15 16 17]\n",
      " [18 19 20 21 22 23]\n",
      " [24 25 26 27 28 29]], shape=(5, 6), dtype=int32) \n",
      "\n",
      "Incompatible reshape dimensions:\n",
      "InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a Rank-3 tensor\n",
    "rank_3_tensor = tf.constant([\n",
    "    [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]],\n",
    "    [[10, 11, 12, 13, 14], [15, 16, 17, 18, 19]],\n",
    "    [[20, 21, 22, 23, 24], [25, 26, 27, 28, 29]],\n",
    "])\n",
    "\n",
    "# Examples of incorrect reshaping\n",
    "\n",
    "# You can't reorder axes with reshape.\n",
    "print(\"Cannot reorder axes with reshape:\")\n",
    "print(tf.reshape(rank_3_tensor, [2, 3, 5]), \"\\n\")\n",
    "\n",
    "# Incorrect dimensions specified.\n",
    "print(\"Incorrect dimensions specified:\")\n",
    "print(tf.reshape(rank_3_tensor, [5, 6]), \"\\n\")\n",
    "\n",
    "# Incompatible reshape dimensions.\n",
    "try:\n",
    "    tf.reshape(rank_3_tensor, [7, -1])\n",
    "except Exception as e:\n",
    "    print(\"Incompatible reshape dimensions:\")\n",
    "    print(f\"{type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{cite:p}`TensorFlowDocumentation`\n",
    "\n",
    "```{figure} tf_figs/tf_reshape_bad.png\n",
    "---\n",
    "width: 600px\n",
    "align: center\n",
    "---\n",
    "Visualizing reshaping `rank_3_tensor` tensor (incorrect reshaping). Image courtesy of TensorFlow documentation {cite:p}`TensorFlowDocumentation`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05bBVBVYV0y6"
   },
   "source": [
    "## Ragged Tensors\n",
    "\n",
    "A tensor that possesses varying numbers of elements along a specific axis is referred to as \"ragged.\" To handle such data, the `tf.ragged.RaggedTensor` class comes into play {cite:p}`TensorFlowDocumentation`.\n",
    "\n",
    "For instance, the following data structure cannot be accurately represented using a standard tensor {cite:p}`TensorFlowDocumentation`:\n",
    "\n",
    "\n",
    "```{figure} tf_figs/ragged.png\n",
    "---\n",
    "width: 200px\n",
    "align: center\n",
    "---\n",
    "A `tf.RaggedTensor` with a shape of [4, None] aptly addresses this scenario.  Image courtesy of TensorFlow documentation {cite:p}`TensorFlowDocumentation`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsbTjoFfNVBF",
    "outputId": "0999a727-5942-4e6e-d2e2-3011164c6b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: ValueError: Can't convert non-rectangular Python sequence to Tensor.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a ragged list\n",
    "ragged_list = [\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]]\n",
    "\n",
    "# Attempt to create a tensor from the ragged list\n",
    "try:\n",
    "    tensor = tf.constant(ragged_list)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", f\"{type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cm9KuEeMLGI"
   },
   "source": [
    "Instead create a `tf.RaggedTensor` using `tf.ragged.constant`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhF3QV3jiqTj",
    "outputId": "d28dcc45-18c9-41fa-a2d9-22ca34792dea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragged Tensor:\n",
      "<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a ragged list\n",
    "ragged_list = [\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]]\n",
    "\n",
    "# Create a tf.RaggedTensor using tf.ragged.constant\n",
    "ragged_tensor = tf.ragged.constant(ragged_list)\n",
    "\n",
    "# Print the ragged tensor\n",
    "print(\"Ragged Tensor:\")\n",
    "print(ragged_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFgHduHVNoIE"
   },
   "source": [
    "The shape of a `tf.RaggedTensor` will contain some axes with unknown lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eo_3wJUWNgqB",
    "outputId": "251eb6e1-e712-4fb1-af49-0cfce716c363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, None)\n"
     ]
    }
   ],
   "source": [
    "print(ragged_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn more about ragged tensors [here](https://www.tensorflow.org/guide/ragged_tensor)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
