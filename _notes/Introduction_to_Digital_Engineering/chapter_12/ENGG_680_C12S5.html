

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>12.5. Building a Logistic Regression Model &#8212; Introduction to Digital Engineering</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_12/ENGG_680_C12S5';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="12.6. Multilayer Perceptron (MLP)" href="ENGG_680_C12S6.html" />
    <link rel="prev" title="12.4. Building a linear Regression Model" href="ENGG_680_C12S4.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../Introduction.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_01/ReadMe.html">1. Introduction to Python Programming</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S1.html">1.1. Variable names, Expressions and statements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S2.html">1.2. Fundamental Concepts and Operations in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S3.html">1.3. Functions</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_02/ReadMe.html">2. Control Flow: Conditionals, Recursion, and Iteration</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG_680_C02S1.html">2.1. Conditionals and recursion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG_680_C02S2.html">2.2. Iteration</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_03/ReadMe.html">3. Data Structures and File Handling in Python</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S1.html">3.1. Strings in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S2.html">3.2. Python Lists</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S3.html">3.3. Python Dictionaries: Key-Value Pairs in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S4.html">3.4. Python Tuples: Immutable Sequences in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S5.html">3.5. Python Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S6.html">3.6. Files in Python (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_04/ReadMe.html">4. Classes and Objects</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S1.html">4.1. Introduction to Classes and Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S2.html">4.2. Inheritance and Polymorphism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S3.html">4.3. Encapsulation and Abstraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S4.html">4.4. Copying Objects (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S5.html">4.5. Magic Methods (Dunder Methods) in Python (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S6.html">4.6. Examples of Classes (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_05/ReadMe.html">5. Introduction to NumPy</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S1.html">5.1. Basics of Numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S2.html">5.2. NumPy Function Reference and Usage Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S3.html">5.3. Advanced Numpy Concepts (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_06/ReadMe.html">6. Working with Data using Pandas</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S1.html">6.1. An Introduction to Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S2.html">6.2. DataFrame and Series Indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S3.html">6.3. Pandas Data Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S4.html">6.4. Handling Missing Data in Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S5.html">6.5. Combining Datasets using Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S6.html">6.6. Aggregation and Grouping in Pandas</a></li>

</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_07/ReadMe.html">7. Data Visualization using Python</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S1.html">7.1. Getting started with Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S2.html">7.2. Matplotlib Styles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S3.html">7.3. Matplotlib interfaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S4.html">7.4. Adjusting the Plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S5.html">7.5. Seaborn plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S6.html">7.6. Python Plotting Guide</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_08/ReadMe.html">8. An Introduction to Computer Vision</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S1.html">8.1. Getting Started with OpenCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S2.html">8.2. Geometric Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S3.html">8.3. Image Thresholding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S4.html">8.4. Image Filtering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S5.html">8.5. Drawing Functions (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S6.html">8.6. Morphological Transformations (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_09/ReadMe.html">9. An Introduction to Machine Learning</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S1.html">9.1. Statistical Metrics and Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S2.html">9.2. An Introduction to Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S3.html">9.3. Multiple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S4.html">9.4. Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S5.html">9.5. K-Nearest Neighbors (K-NN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S6.html">9.6. Resampling Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S7.html">9.7. Support Vector Machines</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_10/ReadMe.html">10. Tree-Based Methods</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S1.html">10.1. Fundamental Structure of Decision Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S2.html">10.2. Regression Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S3.html">10.3. Classification Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S4.html">10.4. Regression Trees and Linear Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S5.html">10.5. Enhancing Decision Trees with Bagging: An Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S6.html">10.6. Random Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S7.html">10.7. Gradient Boosting</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_11/ReadMe.html">11. Dimensionality Reduction and Feature Selection</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S1.html">11.1. Introduction to Dimensionality Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S2.html">11.2. Principal Components Analysis (PCA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S3.html">11.3. t-Distributed Stochastic Neighbor Embedding (t-SNE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S4.html">11.4. Linear and Quadratic Discriminant Analyses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S5.html">11.5. Recursive Feature Elimination (RFE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S6.html">11.6. Practical Considerations in Dimensionality Reduction</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="ReadMe.html">12. Introduction to Deep Learning</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S1.html">12.1. Understanding Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S2.html">12.2. Fundamentals of Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S3.html">12.3. Tensors and Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S4.html">12.4. Building a linear Regression Model</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">12.5. Building a Logistic Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S6.html">12.6. Multilayer Perceptron (MLP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S7.html">12.7. Image classification with TensorFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S8.html">12.8. Image Augmentations with TensorFlow</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../appendixes/ReadMe.html">13. Appendices</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendixes/SampleQuestions_1.html">13.1. Sample Questions 1</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../References.html">14. References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Building a Logistic Regression Model</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocess-the-data">12.5.1. Preprocess the Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">12.5.2. Logistic Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-logistic-regression">12.5.2.1. Understanding Logistic Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-log-loss-function">12.5.2.2. The Log Loss Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-gradient-descent-update-rule">12.5.2.3. The Gradient Descent Update Rule</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-model">12.5.2.4. Training the Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-performance">12.5.2.5. Evaluating Performance</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="tex2jax_ignore mathjax_ignore section" id="building-a-logistic-regression-model">
<h1><span class="section-number">12.5. </span>Building a Logistic Regression Model<a class="headerlink" href="#building-a-logistic-regression-model" title="Permalink to this headline">#</a></h1>
<p>In the realm of machine learning, logistic regression is a foundational algorithm frequently utilized for classification tasks. Its simplicity and effectiveness make it an essential tool in a data scientist’s toolkit. In this section, we will explore the process of creating a logistic regression model using TensorFlow, a leading library for deep learning and numerical computation. By the end of this guide, you’ll have a comprehensive understanding of how to construct, train, and evaluate a logistic regression model, enabling you to tackle binary classification challenges with confidence. Let’s embark on this journey to uncover the inner workings of logistic regression within the TensorFlow framework.</p>
<p><font color='Blue'><b>Example:</b></font> The Wisconsin Breast Cancer dataset, accessible at <a class="reference external" href="https://archive.ics.uci.edu/dataset/10/breast-cancer-wisconsin">https://archive.ics.uci.edu/dataset/10/breast-cancer-wisconsin</a>, is a widely recognized repository of medical data hosted by the UCI Machine Learning Repository. This dataset holds paramount significance in medical research as it offers critical insights into breast cancer diagnosis. The dataset contains a collection of attributes derived from digitized images of fine needle aspirates (FNAs) of breast masses. With a binary classification objective of distinguishing between malignant and benign cases, this dataset has become an integral part of developing predictive models for breast cancer diagnosis. The Wisconsin Breast Cancer dataset plays a pivotal role in advancing both medical diagnostics and machine learning applications in the field of healthcare.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Attribute</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Clump Thickness</p></td>
<td><p>Clump thickness is a subjective measure of how thickly the cells are clustered.</p></td>
</tr>
<tr class="row-odd"><td><p>Uniformity of Cell Size</p></td>
<td><p>Uniformity of cell size refers to the variability in the size of the cells within the cluster.</p></td>
</tr>
<tr class="row-even"><td><p>Uniformity of Cell Shape</p></td>
<td><p>Uniformity of cell shape denotes the variability in the shape of the cells within the cluster.</p></td>
</tr>
<tr class="row-odd"><td><p>Marginal Adhesion</p></td>
<td><p>Marginal adhesion assesses the level of cell adhesion to neighboring cells.</p></td>
</tr>
<tr class="row-even"><td><p>Single Epithelial Cell Size</p></td>
<td><p>Single epithelial cell size characterizes the size of individual epithelial cells.</p></td>
</tr>
<tr class="row-odd"><td><p>Bare Nuclei</p></td>
<td><p>Bare nuclei represents the number of nuclei that are not surrounded by cytoplasm.</p></td>
</tr>
<tr class="row-even"><td><p>Bland Chromatin</p></td>
<td><p>Bland chromatin evaluates the regularity of chromatin distribution in the nuclei.</p></td>
</tr>
<tr class="row-odd"><td><p>Normal Nucleoli</p></td>
<td><p>Normal nucleoli indicates the presence of prominent nucleoli in the nuclei.</p></td>
</tr>
<tr class="row-even"><td><p>Mitoses</p></td>
<td><p>Mitoses quantifies the number of mitotic figures present in the cell nuclei.</p></td>
</tr>
<tr class="row-odd"><td><p>Class</p></td>
<td><p>The target variable classifies cases into benign (2) and malignant (4) categories.</p></td>
</tr>
</tbody>
</table>
<p>Our main focus will be to define a custom logistic regression class, harnessing TensorFlow’s capabilities to construct, train, and evaluate the model. To put our logistic regression class to the test, we will employ a well-known dataset as an illustrative example. This dataset is the “Wisconsin Breast Cancer dataset” from the UCI Machine Learning Repository. By utilizing this example, we aim to not only comprehend the process of crafting a logistic regression model but also witness its effectiveness in practice, shedding light on its predictive prowess in binary classification scenarios.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># URL to the Wisconsin Breast Cancer dataset</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data&#39;</span>

<span class="c1"># Defining the features of interest</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;radius&#39;</span><span class="p">,</span> <span class="s1">&#39;texture&#39;</span><span class="p">,</span> <span class="s1">&#39;perimeter&#39;</span><span class="p">,</span> <span class="s1">&#39;area&#39;</span><span class="p">,</span> <span class="s1">&#39;smoothness&#39;</span><span class="p">,</span> <span class="s1">&#39;compactness&#39;</span><span class="p">,</span>
            <span class="s1">&#39;concavity&#39;</span><span class="p">,</span> <span class="s1">&#39;concave_points&#39;</span><span class="p">,</span> <span class="s1">&#39;symmetry&#39;</span><span class="p">,</span> <span class="s1">&#39;fractal_dimension&#39;</span><span class="p">]</span>

<span class="c1"># Constructing column names based on feature attributes</span>
<span class="n">column_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;diagnosis&#39;</span><span class="p">]</span>

<span class="c1"># Looping through attribute types and features to create column names</span>
<span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;se&#39;</span><span class="p">,</span> <span class="s1">&#39;worst&#39;</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">:</span>
        <span class="n">column_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="n">attr</span><span class="p">)</span>

<span class="c1"># Load the dataset and display its information and head</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">column_names</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
<span class="n">display</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 569 entries, 0 to 568
Data columns (total 32 columns):
 #   Column                   Non-Null Count  Dtype  
---  ------                   --------------  -----  
 0   id                       569 non-null    int64  
 1   diagnosis                569 non-null    object 
 2   radius_mean              569 non-null    float64
 3   texture_mean             569 non-null    float64
 4   perimeter_mean           569 non-null    float64
 5   area_mean                569 non-null    float64
 6   smoothness_mean          569 non-null    float64
 7   compactness_mean         569 non-null    float64
 8   concavity_mean           569 non-null    float64
 9   concave_points_mean      569 non-null    float64
 10  symmetry_mean            569 non-null    float64
 11  fractal_dimension_mean   569 non-null    float64
 12  radius_se                569 non-null    float64
 13  texture_se               569 non-null    float64
 14  perimeter_se             569 non-null    float64
 15  area_se                  569 non-null    float64
 16  smoothness_se            569 non-null    float64
 17  compactness_se           569 non-null    float64
 18  concavity_se             569 non-null    float64
 19  concave_points_se        569 non-null    float64
 20  symmetry_se              569 non-null    float64
 21  fractal_dimension_se     569 non-null    float64
 22  radius_worst             569 non-null    float64
 23  texture_worst            569 non-null    float64
 24  perimeter_worst          569 non-null    float64
 25  area_worst               569 non-null    float64
 26  smoothness_worst         569 non-null    float64
 27  compactness_worst        569 non-null    float64
 28  concavity_worst          569 non-null    float64
 29  concave_points_worst     569 non-null    float64
 30  symmetry_worst           569 non-null    float64
 31  fractal_dimension_worst  569 non-null    float64
dtypes: float64(30), int64(1), object(1)
memory usage: 142.4+ KB
None
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>diagnosis</th>
      <th>radius_mean</th>
      <th>texture_mean</th>
      <th>perimeter_mean</th>
      <th>area_mean</th>
      <th>smoothness_mean</th>
      <th>compactness_mean</th>
      <th>concavity_mean</th>
      <th>concave_points_mean</th>
      <th>...</th>
      <th>radius_worst</th>
      <th>texture_worst</th>
      <th>perimeter_worst</th>
      <th>area_worst</th>
      <th>smoothness_worst</th>
      <th>compactness_worst</th>
      <th>concavity_worst</th>
      <th>concave_points_worst</th>
      <th>symmetry_worst</th>
      <th>fractal_dimension_worst</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>842302</td>
      <td>M</td>
      <td>17.99</td>
      <td>10.38</td>
      <td>122.80</td>
      <td>1001.0</td>
      <td>0.11840</td>
      <td>0.27760</td>
      <td>0.3001</td>
      <td>0.14710</td>
      <td>...</td>
      <td>25.38</td>
      <td>17.33</td>
      <td>184.60</td>
      <td>2019.0</td>
      <td>0.1622</td>
      <td>0.6656</td>
      <td>0.7119</td>
      <td>0.2654</td>
      <td>0.4601</td>
      <td>0.11890</td>
    </tr>
    <tr>
      <th>1</th>
      <td>842517</td>
      <td>M</td>
      <td>20.57</td>
      <td>17.77</td>
      <td>132.90</td>
      <td>1326.0</td>
      <td>0.08474</td>
      <td>0.07864</td>
      <td>0.0869</td>
      <td>0.07017</td>
      <td>...</td>
      <td>24.99</td>
      <td>23.41</td>
      <td>158.80</td>
      <td>1956.0</td>
      <td>0.1238</td>
      <td>0.1866</td>
      <td>0.2416</td>
      <td>0.1860</td>
      <td>0.2750</td>
      <td>0.08902</td>
    </tr>
    <tr>
      <th>2</th>
      <td>84300903</td>
      <td>M</td>
      <td>19.69</td>
      <td>21.25</td>
      <td>130.00</td>
      <td>1203.0</td>
      <td>0.10960</td>
      <td>0.15990</td>
      <td>0.1974</td>
      <td>0.12790</td>
      <td>...</td>
      <td>23.57</td>
      <td>25.53</td>
      <td>152.50</td>
      <td>1709.0</td>
      <td>0.1444</td>
      <td>0.4245</td>
      <td>0.4504</td>
      <td>0.2430</td>
      <td>0.3613</td>
      <td>0.08758</td>
    </tr>
    <tr>
      <th>3</th>
      <td>84348301</td>
      <td>M</td>
      <td>11.42</td>
      <td>20.38</td>
      <td>77.58</td>
      <td>386.1</td>
      <td>0.14250</td>
      <td>0.28390</td>
      <td>0.2414</td>
      <td>0.10520</td>
      <td>...</td>
      <td>14.91</td>
      <td>26.50</td>
      <td>98.87</td>
      <td>567.7</td>
      <td>0.2098</td>
      <td>0.8663</td>
      <td>0.6869</td>
      <td>0.2575</td>
      <td>0.6638</td>
      <td>0.17300</td>
    </tr>
    <tr>
      <th>4</th>
      <td>84358402</td>
      <td>M</td>
      <td>20.29</td>
      <td>14.34</td>
      <td>135.10</td>
      <td>1297.0</td>
      <td>0.10030</td>
      <td>0.13280</td>
      <td>0.1980</td>
      <td>0.10430</td>
      <td>...</td>
      <td>22.54</td>
      <td>16.67</td>
      <td>152.20</td>
      <td>1575.0</td>
      <td>0.1374</td>
      <td>0.2050</td>
      <td>0.4000</td>
      <td>0.1625</td>
      <td>0.2364</td>
      <td>0.07678</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 32 columns</p>
</div></div></div>
</div>
<p>To assess the performance of your model on unseen data, it’s essential to split the dataset into training and test sets. This can be achieved using the <code class="docutils literal notranslate"><span class="pre">pandas</span></code> library’s <a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html"><code class="docutils literal notranslate"><span class="pre">DataFrame.sample</span></code></a> method for sampling a fraction of the data for training, and then the remaining data becomes the test set. It’s important to separate the features from the target labels during this process. The test set serves as a representative sample of unseen data that is used to evaluate how well your model generalizes beyond the training data. You can accomplish this by creating <code class="docutils literal notranslate"><span class="pre">x_train</span></code>, <code class="docutils literal notranslate"><span class="pre">y_train</span></code>, <code class="docutils literal notranslate"><span class="pre">x_test</span></code>, and <code class="docutils literal notranslate"><span class="pre">y_test</span></code> variables, where <code class="docutils literal notranslate"><span class="pre">x_train</span></code> and <code class="docutils literal notranslate"><span class="pre">x_test</span></code> contain the feature data for training and testing, and <code class="docutils literal notranslate"><span class="pre">y_train</span></code> and <code class="docutils literal notranslate"><span class="pre">y_test</span></code> hold the corresponding target labels. This split helps ensure that your model’s performance is measured on data it has never encountered during training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Splitting the dataset into train and test sets</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="c1"># The `id` column can be dropped since each row is unique</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:],</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:],</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Display the number of entries in train and test sets</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of entries in train set:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of entries in test set:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of entries in train set: 427
Number of entries in test set: 142
</pre></div>
</div>
</div>
</div>
<div class="section" id="preprocess-the-data">
<h2><span class="section-number">12.5.1. </span>Preprocess the Data<a class="headerlink" href="#preprocess-the-data" title="Permalink to this headline">#</a></h2>
<p>The dataset consists of ten measurements for each tumor example, encompassing mean, standard error, and largest values. The target column, labeled <code class="docutils literal notranslate"><span class="pre">&quot;diagnosis&quot;</span></code>, contains categorical values denoting tumor diagnoses: <code class="docutils literal notranslate"><span class="pre">'M'</span></code> for malignant tumors and <code class="docutils literal notranslate"><span class="pre">'B'</span></code> for benign tumors. To prepare this categorical data for model training, it must be converted into a numerical binary format. The <a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html"><code class="docutils literal notranslate"><span class="pre">pandas.Series.map</span></code></a> function facilitates this mapping, transforming the categorical values into numerical equivalents <span id="id1">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<div class="warning admonition">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">tf.convert_to_tensor</span></code> function in TensorFlow is a utility that converts a given input, such as a Python object or a NumPy array, into a TensorFlow tensor. A tensor is a multi-dimensional array that serves as the fundamental data structure for representing and performing computations on data in TensorFlow <span id="id2">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<p>When you pass data to the <code class="docutils literal notranslate"><span class="pre">tf.convert_to_tensor</span></code> function, it automatically converts the data into a tensor with the appropriate data type. For example, if you provide a NumPy array containing floating-point numbers, the function will create a tensor with the corresponding data type, such as <code class="docutils literal notranslate"><span class="pre">tf.float32</span></code>. This conversion ensures that the data is compatible with TensorFlow’s computational graph and various tensor operations <span id="id3">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<p>Here’s a simple example of how <code class="docutils literal notranslate"><span class="pre">tf.convert_to_tensor</span></code> works:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Convert a Python list to a tensor</span>
<span class="n">python_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">python_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</pre></div>
</div>
<p>In this example, the Python list <code class="docutils literal notranslate"><span class="pre">python_list</span></code> is converted to a TensorFlow tensor with the specified data type <code class="docutils literal notranslate"><span class="pre">tf.float32</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">tf.convert_to_tensor</span></code> function is particularly useful when you need to ensure that your data is in the correct format to be processed by TensorFlow operations and models. It simplifies the process of moving data between different Python data structures and TensorFlow tensors, making it easier to work with TensorFlow’s computational graph.</p>
</div>
<p>Once the categorical column is mapped, the entire dataset can be converted into a tensor using the <code class="docutils literal notranslate"><span class="pre">tf.convert_to_tensor</span></code> function. This conversion to a tensor is a crucial step in making the data compatible with TensorFlow operations and model training. After completing these preprocessing steps, the data is ready for further use in creating and training a logistic regression model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="c1"># To make the results reproducible, set the random seed value.</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">22</span><span class="p">)</span>

<span class="c1"># Convert target labels to numerical binary format</span>
<span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;B&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;B&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>

<span class="c1"># Convert data to TensorFlow tensors</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In this code snippet, the target labels <code class="docutils literal notranslate"><span class="pre">'B'</span></code> and <code class="docutils literal notranslate"><span class="pre">'M'</span></code> in the <code class="docutils literal notranslate"><span class="pre">y_train</span></code> and <code class="docutils literal notranslate"><span class="pre">y_test</span></code> data are mapped to numerical binary values (<code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>, respectively) using the <code class="docutils literal notranslate"><span class="pre">map</span></code> function. Then, the data is converted to TensorFlow tensors using <code class="docutils literal notranslate"><span class="pre">tf.convert_to_tensor</span></code>, ensuring that the data is in the appropriate format for TensorFlow computations and operations. The <code class="docutils literal notranslate"><span class="pre">dtype</span></code> parameter is used to specify the desired data type of the resulting tensors, which is set to <code class="docutils literal notranslate"><span class="pre">tf.float32</span></code> in this case.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Select a subset of mean-based features for visualization</span>
<span class="n">mean_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;radius_mean&#39;</span><span class="p">,</span> <span class="s1">&#39;texture_mean&#39;</span><span class="p">,</span> <span class="s1">&#39;perimeter_mean&#39;</span><span class="p">,</span> <span class="s1">&#39;area_mean&#39;</span><span class="p">,</span> <span class="s1">&#39;diagnosis&#39;</span><span class="p">]</span>

<span class="c1"># Combine features and target labels for visualization</span>
<span class="n">train_vis_data</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="n">mean_features</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Create pair plot</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;ticks&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">train_vis_data</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;diagnosis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\hatef\anaconda3\envs\jbook\lib\site-packages\seaborn\axisgrid.py:118: UserWarning: The figure layout has changed to tight
  self._figure.tight_layout(*args, **kwargs)
</pre></div>
</div>
<img alt="../_images/0c9df3420145a1c84270081b1b6ecdb3f690652357c8c69cf77af67dbac4d15d.png" src="../_images/0c9df3420145a1c84270081b1b6ecdb3f690652357c8c69cf77af67dbac4d15d.png" />
</div>
</div>
<p>In this code, a subset of mean-based features (e.g., <code class="docutils literal notranslate"><span class="pre">radius_mean</span></code>, <code class="docutils literal notranslate"><span class="pre">texture_mean</span></code>, etc.) are selected for visualization using the <code class="docutils literal notranslate"><span class="pre">sns.pairplot</span></code> function from the Seaborn library. These features are combined with the target labels (<code class="docutils literal notranslate"><span class="pre">'B'</span></code> for benign and <code class="docutils literal notranslate"><span class="pre">'M'</span></code> for malignant) to create a dataframe (<code class="docutils literal notranslate"><span class="pre">train_vis_data</span></code>) that is used for visualization. The <code class="docutils literal notranslate"><span class="pre">hue</span></code> parameter in the <code class="docutils literal notranslate"><span class="pre">pairplot</span></code> function is set to <code class="docutils literal notranslate"><span class="pre">'diagnosis'</span></code>, which uses colors to differentiate between benign and malignant cases. The resulting pair plot provides insights into how different pairs of mean-based features relate to the target diagnosis.</p>
<p>The generated pair plot above provides insightful visualizations of the relationships between various features and the diagnosis. Notably, features like radius, perimeter, and area exhibit strong positive correlations, which is unsurprising given their inherent mathematical interdependence. Furthermore, the pair plot indicates that malignant diagnoses tend to exhibit right-skewed distributions across several features.</p>
<p>In addition to visualizations, it’s essential to examine the overall statistics of the dataset. A noteworthy observation is that each feature covers a markedly diverse range of values, which underscores the need for normalization to ensure that the model can effectively capture relationships across these distinct scales.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_dataset</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()[:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">style</span>\
<span class="o">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Reds&#39;</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">])</span>\
<span class="o">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;PuBu&#39;</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;std&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style type="text/css">
#T_cf838_row0_col1 {
  background-color: #67000d;
  color: #f1f1f1;
}
#T_cf838_row0_col2 {
  background-color: #023858;
  color: #f1f1f1;
}
#T_cf838_row1_col1, #T_cf838_row2_col1, #T_cf838_row3_col1, #T_cf838_row4_col1, #T_cf838_row5_col1, #T_cf838_row6_col1, #T_cf838_row7_col1, #T_cf838_row8_col1, #T_cf838_row9_col1 {
  background-color: #fff5f0;
  color: #000000;
}
#T_cf838_row1_col2, #T_cf838_row2_col2, #T_cf838_row3_col2, #T_cf838_row4_col2, #T_cf838_row5_col2, #T_cf838_row6_col2, #T_cf838_row7_col2, #T_cf838_row8_col2, #T_cf838_row9_col2 {
  background-color: #fff7fb;
  color: #000000;
}
</style>
<table id="T_cf838">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_cf838_level0_col0" class="col_heading level0 col0" >count</th>
      <th id="T_cf838_level0_col1" class="col_heading level0 col1" >mean</th>
      <th id="T_cf838_level0_col2" class="col_heading level0 col2" >std</th>
      <th id="T_cf838_level0_col3" class="col_heading level0 col3" >min</th>
      <th id="T_cf838_level0_col4" class="col_heading level0 col4" >25%</th>
      <th id="T_cf838_level0_col5" class="col_heading level0 col5" >50%</th>
      <th id="T_cf838_level0_col6" class="col_heading level0 col6" >75%</th>
      <th id="T_cf838_level0_col7" class="col_heading level0 col7" >max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_cf838_level0_row0" class="row_heading level0 row0" >id</th>
      <td id="T_cf838_row0_col0" class="data row0 col0" >427.000000</td>
      <td id="T_cf838_row0_col1" class="data row0 col1" >27560139.709602</td>
      <td id="T_cf838_row0_col2" class="data row0 col2" >116273451.255968</td>
      <td id="T_cf838_row0_col3" class="data row0 col3" >8670.000000</td>
      <td id="T_cf838_row0_col4" class="data row0 col4" >865427.500000</td>
      <td id="T_cf838_row0_col5" class="data row0 col5" >905539.000000</td>
      <td id="T_cf838_row0_col6" class="data row0 col6" >8810829.000000</td>
      <td id="T_cf838_row0_col7" class="data row0 col7" >911320502.000000</td>
    </tr>
    <tr>
      <th id="T_cf838_level0_row1" class="row_heading level0 row1" >radius_mean</th>
      <td id="T_cf838_row1_col0" class="data row1 col0" >427.000000</td>
      <td id="T_cf838_row1_col1" class="data row1 col1" >14.143307</td>
      <td id="T_cf838_row1_col2" class="data row1 col2" >3.528717</td>
      <td id="T_cf838_row1_col3" class="data row1 col3" >6.981000</td>
      <td id="T_cf838_row1_col4" class="data row1 col4" >11.695000</td>
      <td id="T_cf838_row1_col5" class="data row1 col5" >13.430000</td>
      <td id="T_cf838_row1_col6" class="data row1 col6" >15.940000</td>
      <td id="T_cf838_row1_col7" class="data row1 col7" >28.110000</td>
    </tr>
    <tr>
      <th id="T_cf838_level0_row2" class="row_heading level0 row2" >texture_mean</th>
      <td id="T_cf838_row2_col0" class="data row2 col0" >427.000000</td>
      <td id="T_cf838_row2_col1" class="data row2 col1" >19.244684</td>
      <td id="T_cf838_row2_col2" class="data row2 col2" >4.113131</td>
      <td id="T_cf838_row2_col3" class="data row2 col3" >10.380000</td>
      <td id="T_cf838_row2_col4" class="data row2 col4" >16.330000</td>
      <td id="T_cf838_row2_col5" class="data row2 col5" >18.840000</td>
      <td id="T_cf838_row2_col6" class="data row2 col6" >21.680000</td>
      <td id="T_cf838_row2_col7" class="data row2 col7" >33.810000</td>
    </tr>
    <tr>
      <th id="T_cf838_level0_row3" class="row_heading level0 row3" >perimeter_mean</th>
      <td id="T_cf838_row3_col0" class="data row3 col0" >427.000000</td>
      <td id="T_cf838_row3_col1" class="data row3 col1" >92.067588</td>
      <td id="T_cf838_row3_col2" class="data row3 col2" >24.314314</td>
      <td id="T_cf838_row3_col3" class="data row3 col3" >43.790000</td>
      <td id="T_cf838_row3_col4" class="data row3 col4" >75.235000</td>
      <td id="T_cf838_row3_col5" class="data row3 col5" >86.870000</td>
      <td id="T_cf838_row3_col6" class="data row3 col6" >106.000000</td>
      <td id="T_cf838_row3_col7" class="data row3 col7" >188.500000</td>
    </tr>
    <tr>
      <th id="T_cf838_level0_row4" class="row_heading level0 row4" >area_mean</th>
      <td id="T_cf838_row4_col0" class="data row4 col0" >427.000000</td>
      <td id="T_cf838_row4_col1" class="data row4 col1" >656.318970</td>
      <td id="T_cf838_row4_col2" class="data row4 col2" >348.910575</td>
      <td id="T_cf838_row4_col3" class="data row4 col3" >143.500000</td>
      <td id="T_cf838_row4_col4" class="data row4 col4" >420.050000</td>
      <td id="T_cf838_row4_col5" class="data row4 col5" >553.500000</td>
      <td id="T_cf838_row4_col6" class="data row4 col6" >790.850000</td>
      <td id="T_cf838_row4_col7" class="data row4 col7" >2499.000000</td>
    </tr>
    <tr>
      <th id="T_cf838_level0_row5" class="row_heading level0 row5" >smoothness_mean</th>
      <td id="T_cf838_row5_col0" class="data row5 col0" >427.000000</td>
      <td id="T_cf838_row5_col1" class="data row5 col1" >0.096336</td>
      <td id="T_cf838_row5_col2" class="data row5 col2" >0.014368</td>
      <td id="T_cf838_row5_col3" class="data row5 col3" >0.052630</td>
      <td id="T_cf838_row5_col4" class="data row5 col4" >0.085850</td>
      <td id="T_cf838_row5_col5" class="data row5 col5" >0.095660</td>
      <td id="T_cf838_row5_col6" class="data row5 col6" >0.105000</td>
      <td id="T_cf838_row5_col7" class="data row5 col7" >0.163400</td>
    </tr>
    <tr>
      <th id="T_cf838_level0_row6" class="row_heading level0 row6" >compactness_mean</th>
      <td id="T_cf838_row6_col0" class="data row6 col0" >427.000000</td>
      <td id="T_cf838_row6_col1" class="data row6 col1" >0.103660</td>
      <td id="T_cf838_row6_col2" class="data row6 col2" >0.053519</td>
      <td id="T_cf838_row6_col3" class="data row6 col3" >0.023440</td>
      <td id="T_cf838_row6_col4" class="data row6 col4" >0.063515</td>
      <td id="T_cf838_row6_col5" class="data row6 col5" >0.091820</td>
      <td id="T_cf838_row6_col6" class="data row6 col6" >0.129650</td>
      <td id="T_cf838_row6_col7" class="data row6 col7" >0.345400</td>
    </tr>
    <tr>
      <th id="T_cf838_level0_row7" class="row_heading level0 row7" >concavity_mean</th>
      <td id="T_cf838_row7_col0" class="data row7 col0" >427.000000</td>
      <td id="T_cf838_row7_col1" class="data row7 col1" >0.088330</td>
      <td id="T_cf838_row7_col2" class="data row7 col2" >0.079659</td>
      <td id="T_cf838_row7_col3" class="data row7 col3" >0.000000</td>
      <td id="T_cf838_row7_col4" class="data row7 col4" >0.029570</td>
      <td id="T_cf838_row7_col5" class="data row7 col5" >0.059990</td>
      <td id="T_cf838_row7_col6" class="data row7 col6" >0.129750</td>
      <td id="T_cf838_row7_col7" class="data row7 col7" >0.426800</td>
    </tr>
    <tr>
      <th id="T_cf838_level0_row8" class="row_heading level0 row8" >concave_points_mean</th>
      <td id="T_cf838_row8_col0" class="data row8 col0" >427.000000</td>
      <td id="T_cf838_row8_col1" class="data row8 col1" >0.048727</td>
      <td id="T_cf838_row8_col2" class="data row8 col2" >0.038536</td>
      <td id="T_cf838_row8_col3" class="data row8 col3" >0.000000</td>
      <td id="T_cf838_row8_col4" class="data row8 col4" >0.019650</td>
      <td id="T_cf838_row8_col5" class="data row8 col5" >0.033900</td>
      <td id="T_cf838_row8_col6" class="data row8 col6" >0.074095</td>
      <td id="T_cf838_row8_col7" class="data row8 col7" >0.201200</td>
    </tr>
    <tr>
      <th id="T_cf838_level0_row9" class="row_heading level0 row9" >symmetry_mean</th>
      <td id="T_cf838_row9_col0" class="data row9 col0" >427.000000</td>
      <td id="T_cf838_row9_col1" class="data row9 col1" >0.180460</td>
      <td id="T_cf838_row9_col2" class="data row9 col2" >0.026378</td>
      <td id="T_cf838_row9_col3" class="data row9 col3" >0.120300</td>
      <td id="T_cf838_row9_col4" class="data row9 col4" >0.161700</td>
      <td id="T_cf838_row9_col5" class="data row9 col5" >0.178400</td>
      <td id="T_cf838_row9_col6" class="data row9 col6" >0.194700</td>
      <td id="T_cf838_row9_col7" class="data row9 col7" >0.290600</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Given the disparate ranges among the features, it is advantageous to perform data normalization to standardize them. Normalization ensures that each feature has a mean of zero and a standard deviation of one, mitigating the influence of differing scales on the model’s performance. This process, also referred to as <a class="reference external" href="https://developers.google.com/machine-learning/glossary#feature-scaling">feature scaling</a>, aids in improving the convergence speed of optimization algorithms and helps the model effectively learn relationships among the features <span id="id4">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Normalize</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Initialize the mean and standard deviation for normalization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_std</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Normalize the input</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span>

    <span class="k">def</span> <span class="nf">unnorm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Unnormalize the input</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span>

<span class="c1"># Create a Normalize instance for the training data</span>
<span class="n">norm_x</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>

<span class="c1"># Normalize the training and test data</span>
<span class="n">x_train_norm</span><span class="p">,</span> <span class="n">x_test_norm</span> <span class="o">=</span> <span class="n">norm_x</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span> <span class="n">norm_x</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_dataset_norm</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">train_dataset_norm</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">x_train_norm</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">train_dataset_norm</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">()[:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">style</span>\
<span class="o">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Reds&#39;</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">])</span>\
<span class="o">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;PuBu&#39;</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;std&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style type="text/css">
#T_74d60_row0_col1 {
  background-color: #6b010e;
  color: #f1f1f1;
}
#T_74d60_row0_col2 {
  background-color: #f2ecf5;
  color: #000000;
}
#T_74d60_row1_col1 {
  background-color: #67000d;
  color: #f1f1f1;
}
#T_74d60_row1_col2 {
  background-color: #67a4cc;
  color: #f1f1f1;
}
#T_74d60_row2_col1 {
  background-color: #fc8060;
  color: #f1f1f1;
}
#T_74d60_row2_col2 {
  background-color: #2c89bd;
  color: #f1f1f1;
}
#T_74d60_row3_col1 {
  background-color: #fcc1a8;
  color: #000000;
}
#T_74d60_row3_col2 {
  background-color: #5a9ec9;
  color: #f1f1f1;
}
#T_74d60_row4_col1 {
  background-color: #fca588;
  color: #000000;
}
#T_74d60_row4_col2 {
  background-color: #93b5d6;
  color: #000000;
}
#T_74d60_row5_col1 {
  background-color: #f85d42;
  color: #f1f1f1;
}
#T_74d60_row5_col2 {
  background-color: #4c99c5;
  color: #f1f1f1;
}
#T_74d60_row6_col1 {
  background-color: #fc8767;
  color: #f1f1f1;
}
#T_74d60_row6_col2 {
  background-color: #023858;
  color: #f1f1f1;
}
#T_74d60_row7_col1 {
  background-color: #fc9272;
  color: #000000;
}
#T_74d60_row7_col2 {
  background-color: #c5cce3;
  color: #000000;
}
#T_74d60_row8_col1 {
  background-color: #fff5f0;
  color: #000000;
}
#T_74d60_row8_col2 {
  background-color: #fff7fb;
  color: #000000;
}
#T_74d60_row9_col1 {
  background-color: #fff2ec;
  color: #000000;
}
#T_74d60_row9_col2 {
  background-color: #dad9ea;
  color: #000000;
}
</style>
<table id="T_74d60">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_74d60_level0_col0" class="col_heading level0 col0" >count</th>
      <th id="T_74d60_level0_col1" class="col_heading level0 col1" >mean</th>
      <th id="T_74d60_level0_col2" class="col_heading level0 col2" >std</th>
      <th id="T_74d60_level0_col3" class="col_heading level0 col3" >min</th>
      <th id="T_74d60_level0_col4" class="col_heading level0 col4" >25%</th>
      <th id="T_74d60_level0_col5" class="col_heading level0 col5" >50%</th>
      <th id="T_74d60_level0_col6" class="col_heading level0 col6" >75%</th>
      <th id="T_74d60_level0_col7" class="col_heading level0 col7" >max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_74d60_level0_row0" class="row_heading level0 row0" >radius_mean</th>
      <td id="T_74d60_row0_col0" class="data row0 col0" >427.000000</td>
      <td id="T_74d60_row0_col1" class="data row0 col1" >0.000001</td>
      <td id="T_74d60_row0_col2" class="data row0 col2" >1.001173</td>
      <td id="T_74d60_row0_col3" class="data row0 col3" >-2.032099</td>
      <td id="T_74d60_row0_col4" class="data row0 col4" >-0.694637</td>
      <td id="T_74d60_row0_col5" class="data row0 col5" >-0.202380</td>
      <td id="T_74d60_row0_col6" class="data row0 col6" >0.509761</td>
      <td id="T_74d60_row0_col7" class="data row0 col7" >3.962652</td>
    </tr>
    <tr>
      <th id="T_74d60_level0_row1" class="row_heading level0 row1" >texture_mean</th>
      <td id="T_74d60_row1_col0" class="data row1 col0" >427.000000</td>
      <td id="T_74d60_row1_col1" class="data row1 col1" >0.000001</td>
      <td id="T_74d60_row1_col2" class="data row1 col2" >1.001173</td>
      <td id="T_74d60_row1_col3" class="data row1 col3" >-2.157743</td>
      <td id="T_74d60_row1_col4" class="data row1 col4" >-0.709459</td>
      <td id="T_74d60_row1_col5" class="data row1 col5" >-0.098503</td>
      <td id="T_74d60_row1_col6" class="data row1 col6" >0.592779</td>
      <td id="T_74d60_row1_col7" class="data row1 col7" >3.545330</td>
    </tr>
    <tr>
      <th id="T_74d60_level0_row2" class="row_heading level0 row2" >perimeter_mean</th>
      <td id="T_74d60_row2_col0" class="data row2 col0" >427.000000</td>
      <td id="T_74d60_row2_col1" class="data row2 col1" >-0.000000</td>
      <td id="T_74d60_row2_col2" class="data row2 col2" >1.001173</td>
      <td id="T_74d60_row2_col3" class="data row2 col3" >-1.987892</td>
      <td id="T_74d60_row2_col4" class="data row2 col4" >-0.693103</td>
      <td id="T_74d60_row2_col5" class="data row2 col5" >-0.214017</td>
      <td id="T_74d60_row2_col6" class="data row2 col6" >0.573685</td>
      <td id="T_74d60_row2_col7" class="data row2 col7" >3.970728</td>
    </tr>
    <tr>
      <th id="T_74d60_level0_row3" class="row_heading level0 row3" >area_mean</th>
      <td id="T_74d60_row3_col0" class="data row3 col0" >427.000000</td>
      <td id="T_74d60_row3_col1" class="data row3 col1" >-0.000000</td>
      <td id="T_74d60_row3_col2" class="data row3 col2" >1.001173</td>
      <td id="T_74d60_row3_col3" class="data row3 col3" >-1.471496</td>
      <td id="T_74d60_row3_col4" class="data row3 col4" >-0.677957</td>
      <td id="T_74d60_row3_col5" class="data row3 col5" >-0.295032</td>
      <td id="T_74d60_row3_col6" class="data row3 col6" >0.386026</td>
      <td id="T_74d60_row3_col7" class="data row3 col7" >5.287436</td>
    </tr>
    <tr>
      <th id="T_74d60_level0_row4" class="row_heading level0 row4" >smoothness_mean</th>
      <td id="T_74d60_row4_col0" class="data row4 col0" >427.000000</td>
      <td id="T_74d60_row4_col1" class="data row4 col1" >-0.000000</td>
      <td id="T_74d60_row4_col2" class="data row4 col2" >1.001173</td>
      <td id="T_74d60_row4_col3" class="data row4 col3" >-3.045437</td>
      <td id="T_74d60_row4_col4" class="data row4 col4" >-0.730675</td>
      <td id="T_74d60_row4_col5" class="data row4 col5" >-0.047116</td>
      <td id="T_74d60_row4_col6" class="data row4 col6" >0.603693</td>
      <td id="T_74d60_row4_col7" class="data row4 col7" >4.672990</td>
    </tr>
    <tr>
      <th id="T_74d60_level0_row5" class="row_heading level0 row5" >compactness_mean</th>
      <td id="T_74d60_row5_col0" class="data row5 col0" >427.000000</td>
      <td id="T_74d60_row5_col1" class="data row5 col1" >0.000000</td>
      <td id="T_74d60_row5_col2" class="data row5 col2" >1.001173</td>
      <td id="T_74d60_row5_col3" class="data row5 col3" >-1.500661</td>
      <td id="T_74d60_row5_col4" class="data row5 col4" >-0.750982</td>
      <td id="T_74d60_row5_col5" class="data row5 col5" >-0.221484</td>
      <td id="T_74d60_row5_col6" class="data row5 col6" >0.486198</td>
      <td id="T_74d60_row5_col7" class="data row5 col7" >4.522211</td>
    </tr>
    <tr>
      <th id="T_74d60_level0_row6" class="row_heading level0 row6" >concavity_mean</th>
      <td id="T_74d60_row6_col0" class="data row6 col0" >427.000000</td>
      <td id="T_74d60_row6_col1" class="data row6 col1" >-0.000000</td>
      <td id="T_74d60_row6_col2" class="data row6 col2" >1.001173</td>
      <td id="T_74d60_row6_col3" class="data row6 col3" >-1.110156</td>
      <td id="T_74d60_row6_col4" class="data row6 col4" >-0.738512</td>
      <td id="T_74d60_row6_col5" class="data row6 col5" >-0.356186</td>
      <td id="T_74d60_row6_col6" class="data row6 col6" >0.520576</td>
      <td id="T_74d60_row6_col7" class="data row6 col7" >4.253978</td>
    </tr>
    <tr>
      <th id="T_74d60_level0_row7" class="row_heading level0 row7" >concave_points_mean</th>
      <td id="T_74d60_row7_col0" class="data row7 col0" >427.000000</td>
      <td id="T_74d60_row7_col1" class="data row7 col1" >-0.000000</td>
      <td id="T_74d60_row7_col2" class="data row7 col2" >1.001173</td>
      <td id="T_74d60_row7_col3" class="data row7 col3" >-1.265936</td>
      <td id="T_74d60_row7_col4" class="data row7 col4" >-0.755424</td>
      <td id="T_74d60_row7_col5" class="data row7 col5" >-0.385206</td>
      <td id="T_74d60_row7_col6" class="data row7 col6" >0.659070</td>
      <td id="T_74d60_row7_col7" class="data row7 col7" >3.961287</td>
    </tr>
    <tr>
      <th id="T_74d60_level0_row8" class="row_heading level0 row8" >symmetry_mean</th>
      <td id="T_74d60_row8_col0" class="data row8 col0" >427.000000</td>
      <td id="T_74d60_row8_col1" class="data row8 col1" >-0.000001</td>
      <td id="T_74d60_row8_col2" class="data row8 col2" >1.001173</td>
      <td id="T_74d60_row8_col3" class="data row8 col3" >-2.283321</td>
      <td id="T_74d60_row8_col4" class="data row8 col4" >-0.712013</td>
      <td id="T_74d60_row8_col5" class="data row8 col5" >-0.078176</td>
      <td id="T_74d60_row8_col6" class="data row8 col6" >0.540479</td>
      <td id="T_74d60_row8_col7" class="data row8 col7" >4.180298</td>
    </tr>
    <tr>
      <th id="T_74d60_level0_row9" class="row_heading level0 row9" >fractal_dimension_mean</th>
      <td id="T_74d60_row9_col0" class="data row9 col0" >427.000000</td>
      <td id="T_74d60_row9_col1" class="data row9 col1" >-0.000001</td>
      <td id="T_74d60_row9_col2" class="data row9 col2" >1.001173</td>
      <td id="T_74d60_row9_col3" class="data row9 col3" >-1.835488</td>
      <td id="T_74d60_row9_col4" class="data row9 col4" >-0.723857</td>
      <td id="T_74d60_row9_col5" class="data row9 col5" >-0.174530</td>
      <td id="T_74d60_row9_col6" class="data row9 col6" >0.455538</td>
      <td id="T_74d60_row9_col7" class="data row9 col7" >5.010195</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
<div class="section" id="logistic-regression">
<h2><span class="section-number">12.5.2. </span>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">#</a></h2>
<p>Before building a logistic regression model, it’s important to grasp its fundamental concepts, especially when compared to traditional linear regression <span id="id5">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<div class="section" id="understanding-logistic-regression">
<h3><span class="section-number">12.5.2.1. </span>Understanding Logistic Regression<a class="headerlink" href="#understanding-logistic-regression" title="Permalink to this headline">#</a></h3>
<p>While linear regression generates outputs without any bounds, [logistic regression produces outputs that are confined to the <span class="math notranslate nohighlight">\((0, 1)\)</span> range. These outputs represent the probabilities of examples belonging to the <em>positive</em> class <span id="id6">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<p>In the context of logistic regression, the outputs from linear regression, which span from <span class="math notranslate nohighlight">\((-∞, ∞)\)</span>, are transformed into probabilities ranging from <span class="math notranslate nohighlight">\((0, 1)\)</span>. This transformation is symmetric, so reversing the sign of the linear output gives the inverse of the original probability <span id="id7">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<p>Let’s denote <span class="math notranslate nohighlight">\(Y\)</span> as the probability of being in class <code class="docutils literal notranslate"><span class="pre">1</span></code> (malignant tumor). This transformation is achieved by interpreting the linear regression output as the <a class="reference external" href="https://developers.google.com/machine-learning/glossary#log-odds">log odds</a> ratio of being in class <code class="docutils literal notranslate"><span class="pre">1</span></code> as opposed to class <code class="docutils literal notranslate"><span class="pre">0</span></code>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-0705f3f9-74cb-40b2-8c6c-155a88e579c6">
<span class="eqno">(12.22)<a class="headerlink" href="#equation-0705f3f9-74cb-40b2-8c6c-155a88e579c6" title="Permalink to this equation">#</a></span>\[\begin{equation}
\ln\left(\frac{Y}{1-Y}\right) = wX + b
\end{equation}\]</div>
<p>By defining <span class="math notranslate nohighlight">\(wX + b = z\)</span>, the equation can be solved for <span class="math notranslate nohighlight">\(Y\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-5de1cec7-fe47-4736-8cb4-58cb342a0e36">
<span class="eqno">(12.23)<a class="headerlink" href="#equation-5de1cec7-fe47-4736-8cb4-58cb342a0e36" title="Permalink to this equation">#</a></span>\[\begin{equation}
Y = \frac{e^z}{1 + e^z} = \frac{1}{1 + e^{-z}}
\end{equation}\]</div>
<p>The term <span class="math notranslate nohighlight">\(\frac{1}{1 + e^{-z}}\)</span> is referred to as the <a class="reference external" href="https://developers.google.com/machine-learning/glossary#sigmoid_function">sigmoid function</a> <span class="math notranslate nohighlight">\(\sigma(z)\)</span>. Consequently, the logistic regression equation simplifies to <span class="math notranslate nohighlight">\(Y = \sigma(wX + b)\)</span>.</p>
<p>When working with datasets featuring high-dimensional feature matrices, the equation is adapted to a matrix-vector form <span id="id8">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-4d379ce0-0ee0-4e3c-9418-bac624556b04">
<span class="eqno">(12.24)<a class="headerlink" href="#equation-4d379ce0-0ee0-4e3c-9418-bac624556b04" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathbf{Y} = \sigma(\mathbf{X}w + b)
\end{equation}\]</div>
<p>Here:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y}\)</span>: target vector with dimensions <span class="math notranslate nohighlight">\((m \times 1)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{X}\)</span>: feature matrix with dimensions <span class="math notranslate nohighlight">\((m \times n)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(w\)</span>: weight vector with dimensions <span class="math notranslate nohighlight">\((n \times 1)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(b\)</span>: bias</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma\)</span>: sigmoid function applied element-wise</p></li>
</ul>
<p>Previously, we discussed sthe sigmoid function. To revisit the sigmoid function, we can employ <code class="docutils literal notranslate"><span class="pre">tf.math.sigmoid</span></code> to visualize it. This function effectively transforms the linear output range <span class="math notranslate nohighlight">\((-∞, ∞)\)</span> into the bounded range <span class="math notranslate nohighlight">\((0, 1)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;../mystyle.mplstyle&#39;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Create the plot using subplots</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">4.5</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Sigmoid&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span> <span class="s1">&#39;Sigmoid (x)&#39;</span><span class="p">,</span>
           <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Sigmoid Activation Function&#39;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/48a7402b7cc5953eec0c5eb474d74bd00acbeca60c1be3e96e5b90d1b1455a1b.png" src="../_images/48a7402b7cc5953eec0c5eb474d74bd00acbeca60c1be3e96e5b90d1b1455a1b.png" />
</div>
</div>
</div>
<div class="section" id="the-log-loss-function">
<h3><span class="section-number">12.5.2.2. </span>The Log Loss Function<a class="headerlink" href="#the-log-loss-function" title="Permalink to this headline">#</a></h3>
<p>The <a class="reference external" href="https://developers.google.com/machine-learning/glossary#Log_Loss">log loss</a>, also known as binary cross-entropy loss, stands as the optimal choice for a binary classification problem involving logistic regression. For each individual example, the log loss serves to quantify the resemblance between a predicted probability and the true value of that example. This computation is determined by the following equation <span id="id9">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b06ab3b1-27a3-44ef-821d-483eae017c9f">
<span class="eqno">(12.25)<a class="headerlink" href="#equation-b06ab3b1-27a3-44ef-821d-483eae017c9f" title="Permalink to this equation">#</a></span>\[\begin{equation}
L = -\frac{1}{m}\sum_{i=1}^{m} \left[ y_i \cdot \log(\hat{y}_i) + (1 - y_i) \cdot \log(1 - \hat{y}_i) \right]
\end{equation}\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( \hat{y} \)</span>: a vector of predicted probabilities</p></li>
<li><p><span class="math notranslate nohighlight">\( y \)</span>: a vector of true target values</p></li>
</ul>
<p>To compute the log loss, you can make use of the <code class="docutils literal notranslate"><span class="pre">tf.nn.sigmoid_cross_entropy_with_logits</span></code> function. This function applies the sigmoid activation automatically to the regression output, simplifying the process of log loss calculation <span id="id10">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">log_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the log loss function.</span>

<span class="sd">    Args:</span>
<span class="sd">        y_pred (tensor): Predicted probabilities.</span>
<span class="sd">        y (tensor): True target values.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tensor: Mean log loss.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Compute the binary cross-entropy (log loss) using sigmoid cross-entropy</span>
    <span class="n">ce</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>

    <span class="c1"># Calculate the mean of the cross-entropy values</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">ce</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="the-gradient-descent-update-rule">
<h3><span class="section-number">12.5.2.3. </span>The Gradient Descent Update Rule<a class="headerlink" href="#the-gradient-descent-update-rule" title="Permalink to this headline">#</a></h3>
<p>The TensorFlow Core APIs provide convenient support for automatic differentiation through the use of <code class="docutils literal notranslate"><span class="pre">tf.GradientTape</span></code>. For those interested in understanding the mathematical underpinnings of the gradient updates in logistic regression, here’s a concise explanation <span id="id11">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>:</p>
<p>Recall from the previous section that each <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> can be expressed in terms of the inputs as <span class="math notranslate nohighlight">\(\sigma(\mathbf{X_i} \mathbf{w} + b)\)</span>.</p>
<p>The ultimate objective is to discover optimal values <span class="math notranslate nohighlight">\(w^*\)</span> and <span class="math notranslate nohighlight">\(b^*\)</span> that minimize the log loss <span id="id12">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-de25dace-5a62-4421-a21b-6f240bc21173">
<span class="eqno">(12.26)<a class="headerlink" href="#equation-de25dace-5a62-4421-a21b-6f240bc21173" title="Permalink to this equation">#</a></span>\[\begin{equation}
L = -\frac{1}{m}\sum_{i=1}^{m} \left[ y_i \cdot \log(\sigma(\mathbf{X_i} \mathbf{w} + b)) + (1 - y_i) \cdot \log(1 - \sigma(\mathbf{X_i} \mathbf{w} + b)) \right]
\end{equation}\]</div>
<p>Upon calculating the gradient of <span class="math notranslate nohighlight">\(L\)</span> with respect to <span class="math notranslate nohighlight">\(w\)</span>, the result is as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-16ecfeaa-0d3c-44f2-9fb5-90bfd3d723ad">
<span class="eqno">(12.27)<a class="headerlink" href="#equation-16ecfeaa-0d3c-44f2-9fb5-90bfd3d723ad" title="Permalink to this equation">#</a></span>\[\begin{equation}
\frac{\partial L}{\partial w} = \frac{1}{m} \left( \sigma(\mathbf{X} \mathbf{w} + b) - \mathbf{y} \right) \mathbf{X}
\end{equation}\]</div>
<p>Similarly, upon calculating the gradient of <span class="math notranslate nohighlight">\(L\)</span> with respect to <span class="math notranslate nohighlight">\(b\)</span>, you obtain:</p>
<div class="amsmath math notranslate nohighlight" id="equation-0f32e9e2-425a-4d72-a658-30698a0136d6">
<span class="eqno">(12.28)<a class="headerlink" href="#equation-0f32e9e2-425a-4d72-a658-30698a0136d6" title="Permalink to this equation">#</a></span>\[\begin{equation}
\frac{\partial L}{\partial b} = \frac{1}{m}\sum_{i=1}^{m} \sigma(\mathbf{X_i} \mathbf{w} + b) - y_i
\end{equation}\]</div>
<p>In essence, these gradient expressions represent the direction and magnitude of adjustments needed to iteratively fine-tune the weights <span class="math notranslate nohighlight">\(w\)</span> and bias <span class="math notranslate nohighlight">\(b\)</span> in order to minimize the log loss and consequently enhance the model’s predictive accuracy <span id="id13">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<p>Now, let’s construct the logistic regression model <span id="id14">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">built</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the model output.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (tensor): Input data.</span>
<span class="sd">            train (bool): Whether the model is being used for training or not.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tensor: Model output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Initialize the model parameters on the first call</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">built</span><span class="p">:</span>
            <span class="c1"># Randomly generate the weights and the bias term</span>
            <span class="n">rand_w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">],</span> <span class="n">seed</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>
            <span class="n">rand_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[],</span> <span class="n">seed</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">rand_w</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">rand_b</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">built</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Compute the model output</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">z</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>For validation, ensure that the untrained model produces output values within the range of <code class="docutils literal notranslate"><span class="pre">(0,</span> <span class="pre">1)</span></code> for a small subset of the training data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create an instance of the LogisticRegression class</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="c1"># Get model predictions for a small subset of the normalized training data</span>
<span class="n">subset_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">subset_x</span> <span class="o">=</span> <span class="n">x_train_norm</span><span class="p">[:</span><span class="n">subset_size</span><span class="p">]</span>

<span class="c1"># Compute model predictions</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">log_reg</span><span class="p">(</span><span class="n">subset_x</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Convert predictions to a NumPy array</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># Display the predictions</span>
<span class="nb">print</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.9994984  0.9978607  0.29620087 0.01979048 0.3314926 ]
</pre></div>
</div>
</div>
</div>
<p>Next, proceed by creating an accuracy function that computes the ratio of accurately classified instances during training. To extract classifications from the predicted probabilities, establish a threshold where all probabilities exceeding the threshold are assigned to class <code class="docutils literal notranslate"><span class="pre">1</span></code>. This threshold is a tunable hyperparameter, which defaults to <code class="docutils literal notranslate"><span class="pre">0.5</span></code> <span id="id15">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_class</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">thresh</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Predict the class based on predicted probabilities.</span>

<span class="sd">    Args:</span>
<span class="sd">        y_pred (tensor): Predicted probabilities.</span>
<span class="sd">        thresh (float): Threshold for classification.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tensor: Predicted class labels.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Return a tensor with 1 if y_pred &gt; threshold, and 0 otherwise</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="n">thresh</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the accuracy of predictions.</span>

<span class="sd">    Args:</span>
<span class="sd">        y_pred (tensor): Predicted values.</span>
<span class="sd">        y (tensor): True labels.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tensor: Accuracy value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Transform predicted values into probabilities using sigmoid function</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

    <span class="c1"># Convert predicted probabilities to class labels</span>
    <span class="n">y_pred_class</span> <span class="o">=</span> <span class="n">predict_class</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

    <span class="c1"># Check where predicted class matches true class and convert to float</span>
    <span class="n">check_equal</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y_pred_class</span> <span class="o">==</span> <span class="n">y</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># Calculate accuracy as the mean of matches</span>
    <span class="n">acc_val</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">check_equal</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">acc_val</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="training-the-model">
<h3><span class="section-number">12.5.2.4. </span>Training the Model<a class="headerlink" href="#training-the-model" title="Permalink to this headline">#</a></h3>
<p>Employing mini-batches for training yields advantages in terms of memory efficiency and quicker convergence. Leveraging the <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> API grants access to valuable functions designed for batching and shuffling data. This API empowers you to craft intricate input pipelines by assembling straightforward, reusable components <span id="id16">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># Create a training dataset from normalized features and labels</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">x_train_norm</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

<span class="c1"># Create a testing dataset from normalized features and labels</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">x_test_norm</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This code prepares the training and testing datasets by converting the normalized features and labels into slices using <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.from_tensor_slices()</span></code>. Subsequently, the datasets are shuffled for randomness using the <code class="docutils literal notranslate"><span class="pre">shuffle()</span></code> function and then batched into manageable mini-batches using the <code class="docutils literal notranslate"><span class="pre">batch()</span></code> function. The defined <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> determines the number of examples in each mini-batch.</p>
<p>Subsequently, we’ll construct a training loop that sequentially adjusts the parameters of the logistic regression model. This adjustment is performed by utilizing the log loss function and calculating its gradients with respect to the input data <span id="id17">[<a class="reference internal" href="../References.html#id120" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set training parameters</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">train_losses</span><span class="p">,</span> <span class="n">test_losses</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="n">train_accs</span><span class="p">,</span> <span class="n">test_accs</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="c1"># Set up the training loop and begin training</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">batch_losses_train</span><span class="p">,</span> <span class="n">batch_accs_train</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="n">batch_losses_test</span><span class="p">,</span> <span class="n">batch_accs_test</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="c1"># Iterate over the training data</span>
    <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">y_pred_batch</span> <span class="o">=</span> <span class="n">log_reg</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
            <span class="n">batch_loss</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_pred_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
        <span class="n">batch_acc</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">y_pred_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>

        <span class="c1"># Update the parameters with respect to the gradient calculations</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">batch_loss</span><span class="p">,</span> <span class="n">log_reg</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">g</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">log_reg</span><span class="o">.</span><span class="n">variables</span><span class="p">):</span>
            <span class="n">v</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">g</span><span class="p">)</span>

        <span class="c1"># Keep track of batch-level training performance</span>
        <span class="n">batch_losses_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_loss</span><span class="p">)</span>
        <span class="n">batch_accs_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_acc</span><span class="p">)</span>

    <span class="c1"># Iterate over the testing data</span>
    <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">test_dataset</span><span class="p">:</span>
        <span class="n">y_pred_batch</span> <span class="o">=</span> <span class="n">log_reg</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
        <span class="n">batch_loss</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_pred_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
        <span class="n">batch_acc</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">y_pred_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>

        <span class="c1"># Keep track of batch-level testing performance</span>
        <span class="n">batch_losses_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_loss</span><span class="p">)</span>
        <span class="n">batch_accs_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_acc</span><span class="p">)</span>

    <span class="c1"># Keep track of epoch-level model performance</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">batch_losses_train</span><span class="p">)</span>
    <span class="n">train_acc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">batch_accs_train</span><span class="p">)</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">batch_losses_test</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">batch_accs_test</span><span class="p">)</span>
    <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
    <span class="n">train_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span>
    <span class="n">test_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_loss</span><span class="p">)</span>
    <span class="n">test_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_acc</span><span class="p">)</span>

    <span class="c1"># Print progress every 20 epochs</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, Training log loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 0, Training log loss: 0.661
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 20, Training log loss: 0.418
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 40, Training log loss: 0.269
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 60, Training log loss: 0.178
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 80, Training log loss: 0.137
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 100, Training log loss: 0.116
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 120, Training log loss: 0.106
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 140, Training log loss: 0.096
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 160, Training log loss: 0.094
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 180, Training log loss: 0.089
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="evaluating-performance">
<h3><span class="section-number">12.5.2.5. </span>Evaluating Performance<a class="headerlink" href="#evaluating-performance" title="Permalink to this headline">#</a></h3>
<p>Monitor the evolution of your model’s loss and accuracy metrics as training progresses.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># Create a figure and a set of subplots</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">9.5</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="c1"># Define style colors</span>
<span class="n">style_colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;RoyalBlue&#39;</span><span class="p">,</span> <span class="s1">&#39;OrangeRed&#39;</span><span class="p">]</span>

<span class="c1"># Plot labels and titles</span>
<span class="n">plot_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="s1">&#39;Accuracy&#39;</span><span class="p">]</span>
<span class="n">plot_titles</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Log Loss vs Training Iterations&#39;</span><span class="p">,</span> <span class="s1">&#39;Accuracy vs Training Iterations&#39;</span><span class="p">]</span>

<span class="c1"># Loop through plots</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">title</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">plot_labels</span><span class="p">,</span> <span class="n">plot_titles</span><span class="p">)):</span>
    <span class="c1"># Plot training and testing metrics</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">train_losses</span> <span class="k">if</span> <span class="n">label</span> <span class="o">==</span> <span class="s1">&#39;Loss&#39;</span> <span class="k">else</span> <span class="n">train_accs</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training &quot;</span> <span class="o">+</span> <span class="n">label</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="n">style_colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">test_losses</span> <span class="k">if</span> <span class="n">label</span> <span class="o">==</span> <span class="s1">&#39;Loss&#39;</span> <span class="k">else</span> <span class="n">test_accs</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Testing &quot;</span> <span class="o">+</span> <span class="n">label</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="n">style_colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

<span class="c1"># Add a common title</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Model Performance during Training&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="c1"># Adjust layout for better spacing</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">rect</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/f9332ce3cf25aae39a188b602041bbbb20a09f640313840620472df8b82c1b39.png" src="../_images/f9332ce3cf25aae39a188b602041bbbb20a09f640313840620472df8b82c1b39.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final training log loss: </span><span class="si">{</span><span class="n">train_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final testing log Loss: </span><span class="si">{</span><span class="n">test_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final training accuracy: </span><span class="si">{</span><span class="n">train_accs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final testing accuracy: </span><span class="si">{</span><span class="n">test_accs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Final training log loss: 0.089
Final testing log Loss: 0.077
Final training accuracy: 0.968
Final testing accuracy: 0.979
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Final Training Log Loss</strong>: This value of 0.089 represents the logarithmic loss (log loss) of the model’s predictions on the training dataset. A lower log loss signifies that the predicted probabilities align well with the true labels.</p></li>
<li><p><strong>Final Testing Log Loss</strong>: With a value of 0.077, this log loss pertains to the model’s performance on the testing dataset. Similar to the training log loss, a lower value indicates accurate predictions on unseen data.</p></li>
<li><p><strong>Final Training Accuracy</strong>: This accuracy value of 0.968 signifies the proportion of correctly classified instances in the training dataset. A higher accuracy indicates better model performance.</p></li>
<li><p><strong>Final Testing Accuracy</strong>: The value of 0.979 represents the accuracy of the model on the testing dataset. A higher testing accuracy suggests that the model generalizes well to new, unseen data.</p></li>
</ul>
<p>The model demonstrates remarkable accuracy by achieving low loss in classifying tumors within the training dataset and successfully generalizes its performance to the previously unseen test data. To delve deeper into the analysis, considering error rates can offer additional insights beyond overall accuracy. The false positive rate (FPR) and false negative rate (FNR) are two significant error rates for binary classification tasks.</p>
<p>For this particular problem, the FPR denotes the proportion of predictions for malignant tumors among those that are genuinely benign. Conversely, the FNR represents the proportion of predictions for benign tumors among those that are truly malignant.</p>
<p>To compute a confusion matrix, you can utilize <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix"><code class="docutils literal notranslate"><span class="pre">sklearn.metrics.confusion_matrix</span></code></a> from the scikit-learn library. This matrix evaluates the classification’s accuracy and can be visualized using Matplotlib:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>

<span class="k">def</span> <span class="nf">show_confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_classes</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Display a normalized confusion matrix using a heatmap.</span>

<span class="sd">    Args:</span>
<span class="sd">        y (tensor): True labels.</span>
<span class="sd">        y_classes (tensor): Predicted class labels.</span>
<span class="sd">        title (str): Title for the confusion matrix.</span>
<span class="sd">        ax (matplotlib.axes.Axes): Axes to plot on.</span>
<span class="sd">        cmap (str): Colormap for the heatmap.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">confusion</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_classes</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">confusion_normalized</span> <span class="o">=</span> <span class="n">confusion</span> <span class="o">/</span> <span class="n">confusion</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">axis_labels</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span>
        <span class="n">confusion_normalized</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">axis_labels</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">axis_labels</span><span class="p">,</span>
        <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;.4f&#39;</span><span class="p">,</span> <span class="n">square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
        <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;shrink&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">})</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Predicted label&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;True label&quot;</span><span class="p">,</span>
               <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Confusion Matrix: </span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Get predicted classes for training and testing</span>
<span class="n">y_pred_train</span><span class="p">,</span> <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">log_reg</span><span class="p">(</span><span class="n">x_train_norm</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">log_reg</span><span class="p">(</span><span class="n">x_test_norm</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">train_classes</span><span class="p">,</span> <span class="n">test_classes</span> <span class="o">=</span> <span class="n">predict_class</span><span class="p">(</span><span class="n">y_pred_train</span><span class="p">),</span> <span class="n">predict_class</span><span class="p">(</span><span class="n">y_pred_test</span><span class="p">)</span>

<span class="c1"># Create subplots for the confusion matrices</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">9.5</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">))</span>
<span class="n">show_confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">train_classes</span><span class="p">,</span> <span class="s1">&#39;Training&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
<span class="n">show_confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_classes</span><span class="p">,</span> <span class="s1">&#39;Testing&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Greens&#39;</span><span class="p">)</span>

<span class="c1"># Adjust layout for better spacing</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e099bc5b20363d92248ac38b2d2ad734fe61c49d2c48557b9145328e1da27f76.png" src="../_images/e099bc5b20363d92248ac38b2d2ad734fe61c49d2c48557b9145328e1da27f76.png" />
</div>
</div>
<p>This code defines the <code class="docutils literal notranslate"><span class="pre">show_confusion_matrix</span></code> function, generates predicted classes for training and testing, and displays the confusion matrices using subplots. The added comments explain the purpose of each function and step, enhancing the code’s readability.</p>
<p>Observe the error rate measurements and interpret their significance in the context of this example. In many medical testing studies such as cancer detection, having a high false positive rate to ensure a low false negative rate is perfectly acceptable and in fact encouraged since the risk of missing a malignant tumor diagnosis (false negative) is a lot worse than misclassifying a benign tumor as malignant (false positive).</p>
<p>In order to control for the FPR and FNR, try changing the threshold hyperparameter before classifying the probability predictions. A lower threshold increases the model’s overall chances of making a malignant tumor classification. This inevitably increases the number of false positives and the FPR but it also helps to decrease the number of false negatives and the FNR.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_12"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="ENGG_680_C12S4.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">12.4. </span>Building a linear Regression Model</p>
      </div>
    </a>
    <a class="right-next"
       href="ENGG_680_C12S6.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">12.6. </span>Multilayer Perceptron (MLP)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocess-the-data">12.5.1. Preprocess the Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">12.5.2. Logistic Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-logistic-regression">12.5.2.1. Understanding Logistic Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-log-loss-function">12.5.2.2. The Log Loss Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-gradient-descent-update-rule">12.5.2.3. The Gradient Descent Update Rule</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-model">12.5.2.4. Training the Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-performance">12.5.2.5. Evaluating Performance</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hatef Dastour
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>