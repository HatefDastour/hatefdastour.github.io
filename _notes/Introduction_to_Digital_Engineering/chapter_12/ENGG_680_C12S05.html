

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>12.5. Tensors in Various Operations (Ops) &#8212; Introduction to Digital Engineering</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_12/ENGG_680_C12S05';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="12.6. Building a linear Regression Model" href="ENGG_680_C12S06.html" />
    <link rel="prev" title="12.4. Introduction to Variables" href="ENGG_680_C12S04.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../Introduction.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Introduction to Digital Engineering - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Introduction to Digital Engineering - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_01/ReadMe.html">1. Introduction to Python Programming</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S1.html">1.1. Variable names, Expressions and statements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S2.html">1.2. Fundamental Concepts and Operations in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S3.html">1.3. Functions</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_02/ReadMe.html">2. Control Flow: Conditionals, Recursion, and Iteration</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG_680_C02S1.html">2.1. Conditionals and recursion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG_680_C02S2.html">2.2. Iteration</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_03/ReadMe.html">3. Data Structures and File Handling in Python</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S1.html">3.1. Strings in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S2.html">3.2. Python Lists</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S3.html">3.3. Python Dictionaries: Key-Value Pairs in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S4.html">3.4. Python Tuples: Immutable Sequences in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S5.html">3.5. Python Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S6.html">3.6. Files in Python (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_04/ReadMe.html">4. Classes and Objects</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S1.html">4.1. Introduction to Classes and Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S2.html">4.2. Inheritance and Polymorphism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S3.html">4.3. Encapsulation and Abstraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S4.html">4.4. Copying Objects (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S5.html">4.5. Magic Methods (Dunder Methods) in Python (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S6.html">4.6. Examples of Classes (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_05/ReadMe.html">5. Introduction to NumPy</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S1.html">5.1. Basics of Numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S2.html">5.2. NumPy Function Reference and Usage Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S3.html">5.3. Advanced Numpy Concepts (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_06/ReadMe.html">6. Working with Data using Pandas</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S1.html">6.1. An Introduction to Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S2.html">6.2. DataFrame and Series Indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S3.html">6.3. Pandas Data Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S4.html">6.4. Handling Missing Data in Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S5.html">6.5. Combining Datasets using Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S6.html">6.6. Aggregation and Grouping in Pandas</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_07/ReadMe.html">7. Data Visualization using Python</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S1.html">7.1. Getting started with Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S2.html">7.2. Matplotlib Styles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S3.html">7.3. Matplotlib interfaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S4.html">7.4. Adjusting the Plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S5.html">7.5. Seaborn plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S6.html">7.6. Python Plotting Guide</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_08/ReadMe.html">8. An Introduction to Computer Vision</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S1.html">8.1. Getting Started with OpenCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S2.html">8.2. Geometric Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S3.html">8.3. Image Thresholding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S4.html">8.4. Image Filtering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S5.html">8.5. Drawing Functions (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_09/ReadMe.html">9. An Introduction to Machine Learning</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S1.html">9.1. Prologue: Statistical Metrics and Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S2.html">9.2. An Introduction to Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S3.html">9.3. Multiple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S4.html">9.4. Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S5.html">9.5. K-Nearest Neighbors (K-NN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S6.html">9.6. Resampling Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S7.html">9.7. Support Vector Machines</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_10/ReadMe.html">10. Tree-Based Methods</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S1.html">10.1. Fundamental Structure of Decision Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S2.html">10.2. Regression Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S3.html">10.3. Classification Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S4.html">10.4. Regression Trees and Linear Models (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S5.html">10.5. Enhancing Decision Trees with Bagging: An Introduction (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S6.html">10.6. Random Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S7.html">10.7. Gradient Boosting</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_11/ReadMe.html">11. Dimensionality Reduction and Feature Selection</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S1.html">11.1. Introduction to Dimensionality Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S2.html">11.2. Principal Components Analysis (PCA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S3.html">11.3. t-Distributed Stochastic Neighbor Embedding (t-SNE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S4.html">11.4. Linear and Quadratic Discriminant Analyses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S5.html">11.5. Recursive Feature Elimination (RFE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S6.html">11.6. Practical Considerations in Dimensionality Reduction</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="ReadMe.html">12. Introduction to Deep Learning</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S01.html">12.1. Understanding Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S02.html">12.2. Fundamentals of Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S03.html">12.3. TensorFlow Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S04.html">12.4. Introduction to Variables</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">12.5. Tensors in Various Operations (Ops)</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S06.html">12.6. Building a linear Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S07.html">12.7. Building a Logistic Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S08.html">12.8. Multilayer Perceptron (MLP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S09.html">12.9. Deep Learning Architectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S10.html">12.10. Image classification with TensorFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S11.html">12.11. Image Augmentations with TensorFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S12.html">12.12. Enhancing Image Classification Precision Through TensorFlow and Data Augmentation Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S13.html">12.13. Brief Overview of Additional Topics</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../appendixes/ReadMe.html">13. Appendices</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendixes/SampleQuestions_1.html">13.1. Sample Questions 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendixes/SampleQuestions_2.html">13.2. Sample Questions 2</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../References.html">14. References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Tensors in Various Operations (Ops)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#math-operations">12.5.1. Math Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#array-operations">12.5.2. Array Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#string-operations">12.5.3. String Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#control-flow-operations">12.5.4. Control Flow Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reduction-operations">12.5.5. Reduction Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sparse-operations">12.5.6. Sparse Operations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sparse-tensors">12.5.6.1. Sparse Tensors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">12.5.6.2. Sparse Operations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-network-operations">12.5.7. Neural Network Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variable-operations">12.5.8. Variable Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i-o-operations">12.5.9. I/O Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-and-signal-processing-operations">12.5.10. Image and Signal Processing Operations</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="tensors-in-various-operations-ops">
<h1><span class="section-number">12.5. </span>Tensors in Various Operations (Ops)<a class="headerlink" href="#tensors-in-various-operations-ops" title="Permalink to this heading">#</a></h1>
<p>Tensors are the fundamental building blocks of TensorFlow, and they can be manipulated by a wide range of operations, commonly abbreviated as “Ops.” These operations cover essential tasks such as computation, transformation, and manipulation of data <span id="id1">[<a class="reference internal" href="../References.html#id54" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>. The following are some of the main categories of operations in TensorFlow:</p>
<ol class="arabic simple">
<li><p><strong>Math Operations:</strong></p>
<ul class="simple">
<li><p>These operations perform basic arithmetic, algebraic, trigonometric, and other mathematical functions on tensors.</p></li>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.add</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.subtract</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.multiply</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.divide</span></code>, etc.</p></li>
</ul>
</li>
<li><p><strong>Array Operations:</strong></p>
<ul class="simple">
<li><p>These operations change the shape, size, order, and content of tensors in various ways, such as reshaping, slicing, stacking, concatenating, splitting, and indexing.</p></li>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.reshape</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.concat</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.slice</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.gather</span></code>, etc.</p></li>
</ul>
</li>
<li><p><strong>String Operations:</strong></p>
<ul class="simple">
<li><p>These operations handle string tensors (<code class="docutils literal notranslate"><span class="pre">tf.string</span></code>), and perform tasks such as splitting, joining, length, and conversion to numbers.</p></li>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.strings.split</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.strings.join</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.strings.length</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.strings.to_number</span></code>, etc.</p></li>
</ul>
</li>
<li><p><strong>Control Flow Operations:</strong></p>
<ul class="simple">
<li><p>These operations enable conditional execution and looping of tensors, using constructs such as <code class="docutils literal notranslate"><span class="pre">if</span></code>, <code class="docutils literal notranslate"><span class="pre">while</span></code>, and <code class="docutils literal notranslate"><span class="pre">case</span></code>.</p></li>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.cond</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.while_loop</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.case</span></code>, etc.</p></li>
</ul>
</li>
<li><p><strong>Reduction Operations:</strong></p>
<ul class="simple">
<li><p>These operations reduce tensors along specified dimensions, by applying functions such as sum, mean, max, min, etc.</p></li>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.reduce_sum</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.reduce_mean</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.reduce_max</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.reduce_min</span></code>, etc.</p></li>
</ul>
</li>
<li><p><strong>Sparse Operations:</strong></p>
<ul class="simple">
<li><p>These operations are designed for sparse tensors, which store tensors with many zeros efficiently by only keeping the non-zero values and their indices.</p></li>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.sparse.reduce_sum</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.sparse.to_dense</span></code>, etc.</p></li>
</ul>
</li>
<li><p><strong>Neural Network Operations:</strong></p>
<ul class="simple">
<li><p>These operations are specifically tailored for building and training neural networks, and include activation functions, loss functions, optimizers, and layers.</p></li>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.nn.relu</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.nn.softmax</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Dense</span></code>, etc.</p></li>
</ul>
</li>
<li><p><strong>Variable Operations:</strong></p>
<ul class="simple">
<li><p>These operations deal with the creation, modification, and management of variables, which are mutable tensors that can store and update values.</p></li>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.assign</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.assign_add</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.train.Optimizer</span></code>, etc.</p></li>
</ul>
</li>
<li><p><strong>I/O Operations:</strong></p>
<ul class="simple">
<li><p>These operations facilitate the reading and writing of data from various sources, such as files, queues, or networks.</p></li>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.io.read_file</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.io.decode_image</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.io.write_file</span></code>, etc.</p></li>
</ul>
</li>
<li><p><strong>Image and Signal Processing Operations:</strong></p>
<ul class="simple">
<li><p>These operations are specific to image and signal processing tasks, and include functions for resizing, cropping, filtering, and transforming images and signals.</p></li>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.image.resize</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.image.crop_and_resize</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.signal.fft</span></code>, etc.</p></li>
</ul>
</li>
</ol>
<p>These categories provide a comprehensive overview of the operations available in TensorFlow, which can be used for different purposes and applications involving data manipulation, mathematical computations, and machine learning.</p>
<div class="warning admonition">
<p class="admonition-title">Note</p>
<p>To access the full list of symbols in TensorFlow 2, you can visit the [TensorFlow API documentation] and browse through the categories and modules. Alternatively, you can use the search bar to find a specific symbol by name or keyword.</p>
</div>
<section id="math-operations">
<h2><span class="section-number">12.5.1. </span>Math Operations<a class="headerlink" href="#math-operations" title="Permalink to this heading">#</a></h2>
<p>Math operations are a subset of TensorFlow operations that perform basic arithmetic, algebraic, trigonometric, and other mathematical functions on tensors. Math operations can be useful for various purposes and applications involving numerical computations and analysis.</p>
<p>Some of the common math operations are <span id="id2">[<a class="reference internal" href="../References.html#id54" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>:</p>
<ul class="simple">
<li><p><strong>Arithmetic Operations:</strong> These operations perform element-wise addition, subtraction, multiplication, and division of tensors, as well as other arithmetic functions such as power, modulus, and sign.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.add</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.subtract</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.multiply</span></code>, and <code class="docutils literal notranslate"><span class="pre">tf.divide</span></code> perform element-wise addition, subtraction, multiplication, and division of tensors, respectively. <code class="docutils literal notranslate"><span class="pre">tf.pow</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.mod</span></code>, and <code class="docutils literal notranslate"><span class="pre">tf.sign</span></code> perform element-wise power, modulus, and sign of tensors, respectively.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Perform element-wise addition of two tensors</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 7, 9], dtype=int32)&gt;</span>

<span class="c1"># Perform element-wise power of a tensor</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 4,  9, 16], dtype=int32)&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 4,  9, 16])&gt;
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Linear Algebra Operations:</strong> These operations perform matrix and vector operations, such as dot product, matrix multiplication, transpose, determinant, inverse, and decomposition.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.linalg.matmul</span></code> performs matrix multiplication of two tensors. <code class="docutils literal notranslate"><span class="pre">tf.linalg.inv</span></code> computes the inverse of a square matrix tensor. <code class="docutils literal notranslate"><span class="pre">tf.linalg.eigh</span></code> computes the eigenvalues and eigenvectors of a symmetric matrix tensor.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">print_bold</span><span class="p">(</span><span class="n">txt</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">31</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Display text in bold with optional color.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - txt (str): The text to be displayed.</span>
<span class="sd">    - c (int): Color code for the text (default is 31 for red).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[1;</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">m&quot;</span> <span class="o">+</span> <span class="n">txt</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[0m&quot;</span><span class="p">)</span>

<span class="c1"># Perform matrix multiplication of two tensors</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<span class="n">result_ab</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Matrix multiplication of two tensors:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result_ab</span><span class="p">)</span>

<span class="c1"># Compute the inverse of a square matrix tensor</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">inv_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">The inverse of a square matrix tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inv_c</span><span class="p">)</span>

<span class="c1"># Compute the eigenvalues and eigenvectors of a symmetric matrix tensor</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">eigvals_d</span><span class="p">,</span> <span class="n">eigvecs_d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">The eigenvalues:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">eigvals_d</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">The eigenvectors:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">eigvecs_d</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Matrix multiplication of two tensors:</span>
tf.Tensor(
[[19 22]
 [43 50]], shape=(2, 2), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">The inverse of a square matrix tensor:</span>
tf.Tensor(
[[-2.0000002   1.0000001 ]
 [ 1.5000001  -0.50000006]], shape=(2, 2), dtype=float32)

<span class=" -Color -Color-Bold -Color-Bold-Red">The eigenvalues:</span>
tf.Tensor([-0.23606804  4.2360687 ], shape=(2,), dtype=float32)

<span class=" -Color -Color-Bold -Color-Bold-Red">The eigenvectors:</span>
tf.Tensor(
[[-0.85065085 -0.52573115]
 [ 0.52573115 -0.85065085]], shape=(2, 2), dtype=float32)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Trigonometric and Hyperbolic Operations:</strong> These operations perform trigonometric and hyperbolic functions on tensors, such as sine, cosine, tangent, arcsine, arccosine, arctangent, sinh, cosh, tanh, etc.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.sin</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.cos</span></code>, and <code class="docutils literal notranslate"><span class="pre">tf.tan</span></code> perform element-wise sine, cosine, and tangent of tensors, respectively. <code class="docutils literal notranslate"><span class="pre">tf.asin</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.acos</span></code>, and <code class="docutils literal notranslate"><span class="pre">tf.atan</span></code> perform element-wise arcsine, arccosine, and arctangent of tensors, respectively. <code class="docutils literal notranslate"><span class="pre">tf.sinh</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.cosh</span></code>, and <code class="docutils literal notranslate"><span class="pre">tf.tanh</span></code> perform element-wise hyperbolic sine, cosine, and tangent of tensors, respectively.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">print_bold</span><span class="p">(</span><span class="n">txt</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">31</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Display text in bold with optional color.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - txt (str): The text to be displayed.</span>
<span class="sd">    - c (int): Color code for the text (default is 31 for red).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[1;</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">m&quot;</span> <span class="o">+</span> <span class="n">txt</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[0m&quot;</span><span class="p">)</span>

<span class="c1"># Perform element-wise sine of a tensor</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">])</span>
<span class="n">sin_x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Element-wise sine of a tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sin_x</span><span class="p">)</span>

<span class="c1"># Perform element-wise arctangent of a tensor</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float&#39;</span><span class="p">)</span>
<span class="n">atan_y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">atan</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Element-wise arctangent of a tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">atan_y</span><span class="p">)</span>

<span class="c1"># Perform element-wise hyperbolic tangent of a tensor</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float&#39;</span><span class="p">)</span>
<span class="n">tanh_z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Element-wise hyperbolic tangent of a tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tanh_z</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Element-wise sine of a tensor:</span>
tf.Tensor([ 0.000000e+00  1.000000e+00 -8.742278e-08], shape=(3,), dtype=float32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Element-wise arctangent of a tensor:</span>
tf.Tensor([-0.7853982  0.         0.7853982], shape=(3,), dtype=float32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Element-wise hyperbolic tangent of a tensor:</span>
tf.Tensor([-0.7615942  0.         0.7615942], shape=(3,), dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>These are some examples of Math Operations in TensorFlow, which can be used for various purposes and applications involving data manipulation, mathematical computations, and machine learning. For more information and examples, you can refer to the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math">TensorFlow documentation</a>.</p>
<div class="warning admonition">
<p class="admonition-title">Note</p>
<p>There are many more operations that you can use to perform various mathematical computations and transformations on tensors. You can find the complete list of all the math operations in the <a class="reference external" href="https://www.tensorflow.org/api_docs/cc/group/math-ops">TensorFlow API documentation</a> or the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math">TensorFlow math module</a>. You can also use the <code class="docutils literal notranslate"><span class="pre">tf.keras.backend</span></code> module to access some additional math operations that are compatible with different backends, such as TensorFlow, Theano, or CNTK. You can find more details and examples of using <code class="docutils literal notranslate"><span class="pre">tf.keras.backend</span></code> <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/backend">here</a>.</p>
</div>
</section>
<section id="array-operations">
<h2><span class="section-number">12.5.2. </span>Array Operations<a class="headerlink" href="#array-operations" title="Permalink to this heading">#</a></h2>
<p>Array operations are a subset of TensorFlow operations that change the shape, size, order, and content of tensors in various ways, such as reshaping, slicing, stacking, concatenating, splitting, and indexing. Array operations can be useful for various purposes and applications involving data manipulation and transformation.</p>
<p>Some of the common array operations are <span id="id3">[<a class="reference internal" href="../References.html#id54" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>:</p>
<ul class="simple">
<li><p><strong>Reshaping:</strong> These operations change the shape of a tensor without changing its underlying data. They can be useful for changing the dimensionality or layout of a tensor.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.reshape</span></code> changes the shape of a tensor to a specified shape. <code class="docutils literal notranslate"><span class="pre">tf.expand_dims</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.squeeze</span></code> add or remove dimensions of size 1 from a tensor, respectively.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Change the shape of a tensor to a specified shape</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">reshaped_x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Change the shape of a tensor to a specified shape:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">reshaped_x</span><span class="p">)</span>

<span class="c1"># Add a dimension of size 1 to a tensor</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">expanded_y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Add a dimension of size 1 to a tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">expanded_y</span><span class="p">)</span>

<span class="c1"># Remove dimensions of size 1 from a tensor</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="n">squeezed_z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Remove dimensions of size 1 from a tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">squeezed_z</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Change the shape of a tensor to a specified shape:</span>
tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Add a dimension of size 1 to a tensor:</span>
tf.Tensor([[1 2 3]], shape=(1, 3), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Remove dimensions of size 1 from a tensor:</span>
tf.Tensor([1 2 3], shape=(3,), dtype=int32)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Slicing and Indexing:</strong> These operations extract or modify a subset of a tensor based on indices or ranges. They can be useful for accessing or updating specific elements or regions of a tensor.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.slice</span></code> extracts a slice of a tensor based on a starting position and a size. <code class="docutils literal notranslate"><span class="pre">tf.gather</span></code> gathers elements from a tensor based on indices. <code class="docutils literal notranslate"><span class="pre">tf.scatter_nd</span></code> scatters values into a new tensor based on indices.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Extract a slice of a tensor based on a starting position and a size</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="n">sliced_x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Extract a slice of a tensor based on a starting position and a size:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sliced_x</span><span class="p">)</span>

<span class="c1"># Gather elements from a tensor based on indices</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span>
<span class="n">gathered_y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Gather elements from a tensor based on indices:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gathered_y</span><span class="p">)</span>

<span class="c1"># Scatter values into a new tensor based on indices</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">scattered_z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">scatter_nd</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]],</span> <span class="n">updates</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">])</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Scatter values into a new tensor based on indices:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scattered_z</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Extract a slice of a tensor based on a starting position and a size:</span>
tf.Tensor(
[[2 3]
 [5 6]], shape=(2, 2), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Gather elements from a tensor based on indices:</span>
tf.Tensor([10 30 50], shape=(3,), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Scatter values into a new tensor based on indices:</span>
tf.Tensor([1 0 2 3], shape=(4,), dtype=int32)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Stacking and Concatenating:</strong> These operations combine multiple tensors along a specified axis. They can be useful for merging or expanding tensors.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.stack</span></code> stacks a list of tensors along a new axis. <code class="docutils literal notranslate"><span class="pre">tf.concat</span></code> concatenates a list of tensors along an existing axis.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Stack a list of tensors along a new axis</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">stacked_tensors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Stack a list of tensors along a new axis:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stacked_tensors</span><span class="p">)</span>

<span class="c1"># Concatenate a list of tensors along an existing axis</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">])</span>
<span class="n">concatenated_tensors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Concatenate a list of tensors along an existing axis:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">concatenated_tensors</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Stack a list of tensors along a new axis:</span>
tf.Tensor(
[[1 2 3]
 [4 5 6]], shape=(2, 3), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Concatenate a list of tensors along an existing axis:</span>
tf.Tensor([1 2 3 4 5 6 7 8 9], shape=(9,), dtype=int32)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Splitting and Unstacking:</strong> These operations divide a tensor into multiple tensors along a specified axis. They can be useful for splitting or reducing tensors.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.split</span></code> splits a tensor into a list of tensors of equal size along a specified axis. <code class="docutils literal notranslate"><span class="pre">tf.unstack</span></code> unstacks a tensor along a specified axis and returns a list of tensors.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Split a tensor into a list of tensors of equal size along a specified axis</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="n">split_tensors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Split a tensor into a list of tensors of equal size along a specified axis:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">split_tensors</span><span class="p">)</span>

<span class="c1"># Unstack a tensor along a specified axis and return a list of tensors</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">unstacked_tensors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Unstack a tensor along a specified axis and return a list of tensors:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">unstacked_tensors</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Split a tensor into a list of tensors of equal size along a specified axis:</span>
[&lt;tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[1, 2, 3]])&gt;, &lt;tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[4, 5, 6]])&gt;, &lt;tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[7, 8, 9]])&gt;]

<span class=" -Color -Color-Bold -Color-Bold-Red">Unstack a tensor along a specified axis and return a list of tensors:</span>
[&lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 4])&gt;, &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 5])&gt;, &lt;tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 6])&gt;]
</pre></div>
</div>
</div>
</div>
<p>These are some examples of Array Operations in TensorFlow, which can be used for various purposes and applications involving data manipulation, transformation, and reshaping. For more information and examples, you can refer to the <a class="reference external" href="https://www.tensorflow.org/api_docs/cc/group/array-ops">TensorFlow documentation</a>.</p>
</section>
<section id="string-operations">
<h2><span class="section-number">12.5.3. </span>String Operations<a class="headerlink" href="#string-operations" title="Permalink to this heading">#</a></h2>
<p>String operations are a subset of array operations that handle string tensors (<code class="docutils literal notranslate"><span class="pre">tf.string</span></code>). A string tensor is a tensor of type <code class="docutils literal notranslate"><span class="pre">tf.string</span></code> that can store byte strings of arbitrary lengths. String tensors can be scalars, vectors, or higher-rank tensors, and they can be created from Python strings or byte literals <span id="id4">[<a class="reference internal" href="../References.html#id54" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<p>Some of the common string operations are <span id="id5">[<a class="reference internal" href="../References.html#id54" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>:</p>
<ul class="simple">
<li><p><strong>Splitting and Joining:</strong> These operations split a string tensor into a list of substrings, or join a list of string tensors into a single string tensor. They can be useful for tokenizing, parsing, or concatenating strings.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.strings.split</span></code> splits a string tensor into a ragged tensor of substrings, based on a delimiter. <code class="docutils literal notranslate"><span class="pre">tf.strings.join</span></code> joins a list of string tensors into a single string tensor, with an optional separator.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Split a string tensor by whitespace</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="s2">&quot;Hello Calgary!&quot;</span><span class="p">)</span>
<span class="n">split_strings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Split a string tensor by whitespace:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">split_strings</span><span class="p">)</span>

<span class="c1"># Join a list of string tensors with a comma</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="s2">&quot;Red&quot;</span><span class="p">,</span> <span class="s2">&quot;Green&quot;</span><span class="p">,</span> <span class="s2">&quot;Blue&quot;</span><span class="p">])</span>
<span class="n">joined_strings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Join a list of string tensors with a comma:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">joined_strings</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Split a string tensor by whitespace:</span>
tf.Tensor([b&#39;Hello&#39; b&#39;Calgary!&#39;], shape=(2,), dtype=string)

<span class=" -Color -Color-Bold -Color-Bold-Red">Join a list of string tensors with a comma:</span>
tf.Tensor(b&#39;RedGreenBlue&#39;, shape=(), dtype=string)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Length and Hashing:</strong> These operations compute the length or the hash value of a string tensor. They can be useful for filtering, sorting, or hashing strings.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.strings.length</span></code> returns the length of each string in a tensor, in bytes or Unicode characters. <code class="docutils literal notranslate"><span class="pre">tf.strings.to_hash_bucket</span></code> assigns each string in a tensor to a hash bucket, based on its hash value.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Get the length of each string in bytes</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="s2">&quot;Hello&quot;</span><span class="p">,</span> <span class="s2">&quot;こんにちは&quot;</span><span class="p">,</span> <span class="s2">&quot;你好&quot;</span><span class="p">])</span>
<span class="n">length_bytes</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">length</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;BYTE&quot;</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Get the length of each string in bytes:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">length_bytes</span><span class="p">)</span>

<span class="c1"># Get the length of each string in Unicode characters</span>
<span class="n">length_unicode</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">length</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;UTF8_CHAR&quot;</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Get the length of each string in Unicode characters:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">length_unicode</span><span class="p">)</span>

<span class="c1"># Assign each string to a hash bucket</span>
<span class="n">hash_buckets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">to_hash_bucket</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">num_buckets</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Assign each string to a hash bucket:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">hash_buckets</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Get the length of each string in bytes:</span>
tf.Tensor([ 5 15  6], shape=(3,), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Get the length of each string in Unicode characters:</span>
tf.Tensor([5 5 2], shape=(3,), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Assign each string to a hash bucket:</span>
tf.Tensor([1 8 3], shape=(3,), dtype=int64)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Conversion and Encoding:</strong> These operations convert a string tensor to a different type or format, such as numbers, booleans, or base64. They can be useful for parsing, encoding, or decoding strings.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.strings.to_number</span></code> converts each string in a tensor to a numeric tensor of a specified dtype. <code class="docutils literal notranslate"><span class="pre">tf.io.encode_base64</span></code> encodes each string in a tensor to base64 format.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Convert each string to a float tensor</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="s2">&quot;1.0&quot;</span><span class="p">,</span> <span class="s2">&quot;3.14&quot;</span><span class="p">,</span> <span class="s2">&quot;2.718&quot;</span><span class="p">])</span>
<span class="n">float_tensors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">to_number</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Convert each string to a float tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">float_tensors</span><span class="p">)</span>

<span class="c1"># Encode each string to base64</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="s2">&quot;Hello&quot;</span><span class="p">,</span> <span class="s2">&quot;world&quot;</span><span class="p">])</span>
<span class="n">base64_encoded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">encode_base64</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Encode each string to base64:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">base64_encoded</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Convert each string to a float tensor:</span>
tf.Tensor([1.    3.14  2.718], shape=(3,), dtype=float32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Encode each string to base64:</span>
tf.Tensor([b&#39;SGVsbG8&#39; b&#39;d29ybGQ&#39;], shape=(2,), dtype=string)
</pre></div>
</div>
</div>
</div>
<p>These are some of the string operations available in TensorFlow, which can be used for different purposes and applications involving string manipulation and processing. For more information, please refer to the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/strings">TensorFlow documentation</a>.</p>
</section>
<section id="control-flow-operations">
<h2><span class="section-number">12.5.4. </span>Control Flow Operations<a class="headerlink" href="#control-flow-operations" title="Permalink to this heading">#</a></h2>
<p>Control flow operations are a subset of TensorFlow operations that enable conditional execution and looping of tensors, using constructs such as <code class="docutils literal notranslate"><span class="pre">if</span></code>, <code class="docutils literal notranslate"><span class="pre">while</span></code>, and <code class="docutils literal notranslate"><span class="pre">case</span></code>. Control flow operations can be useful for various purposes and applications involving dynamic and complex logic and computation.</p>
<p>Some of the common control flow operations are <span id="id6">[<a class="reference internal" href="../References.html#id54" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>:</p>
<ul class="simple">
<li><p><strong>Conditional Execution:</strong> These operations execute a branch of tensors based on a condition. They can be useful for implementing branching logic or decision making.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.cond</span></code> executes one of two tensors based on a boolean predicate. <code class="docutils literal notranslate"><span class="pre">tf.where</span></code> returns elements from one of two tensors based on a boolean mask.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Execute one of two tensors based on a boolean predicate</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">result_cond</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="n">y</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Execute one of two tensors based on a boolean predicate:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result_cond</span><span class="p">)</span>

<span class="c1"># Return elements from one of two tensors based on a boolean mask</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">])</span>
<span class="n">result_where</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Return elements from one of two tensors based on a boolean mask:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result_where</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Execute one of two tensors based on a boolean predicate:</span>
tf.Tensor(3, shape=(), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Return elements from one of two tensors based on a boolean mask:</span>
tf.Tensor([1 5 3], shape=(3,), dtype=int32)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Looping:</strong> These operations execute a tensor or a list of tensors repeatedly until a condition is met. They can be useful for implementing iterative or recursive computation.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.while_loop</span></code> executes a body tensor while a condition tensor is true. <code class="docutils literal notranslate"><span class="pre">tf.map_fn</span></code> applies a function to each element of a tensor or a list of tensors.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Execute a body tensor while a condition tensor is true</span>
<span class="n">i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">condition</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">body</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">),)</span>
<span class="n">result_while_loop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">while_loop</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Execute a body tensor while a condition tensor is true:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result_while_loop</span><span class="p">)</span>

<span class="c1"># Apply a function to each element of a tensor or a list of tensors</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">function_to_apply</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">result_map_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">map_fn</span><span class="p">(</span><span class="n">function_to_apply</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Apply a function to each element of a tensor or a list of tensors:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result_map_fn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Execute a body tensor while a condition tensor is true:</span>
tf.Tensor(10, shape=(), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Apply a function to each element of a tensor or a list of tensors:</span>
tf.Tensor([1 4 9], shape=(3,), dtype=int32)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Switching:</strong> These operations execute a tensor or a list of tensors based on a selector. They can be useful for implementing multiple choices or cases.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.switch_case</span></code> executes one of a list of tensors based on an integer selector. <code class="docutils literal notranslate"><span class="pre">tf.case</span></code> executes one of a list of tensors based on a list of boolean predicates.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Execute one of a list of tensors based on an integer selector</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">branches</span> <span class="o">=</span> <span class="p">[</span><span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">2</span><span class="p">)]</span>
<span class="n">result_switch_case</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">switch_case</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">branches</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Execute one of a list of tensors based on an integer selector:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result_switch_case</span><span class="p">)</span>

<span class="c1"># Execute one of a list of tensors based on a list of boolean predicates</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">pred_fn_pairs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>
                 <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">2</span><span class="p">))]</span>
<span class="n">default</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">result_case</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">case</span><span class="p">(</span><span class="n">pred_fn_pairs</span><span class="p">,</span> <span class="n">default</span><span class="p">,</span> <span class="n">exclusive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Execute one of a list of tensors based on a list of boolean predicates:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result_case</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Execute one of a list of tensors based on an integer selector:</span>
tf.Tensor(2, shape=(), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Execute one of a list of tensors based on a list of boolean predicates:</span>
tf.Tensor(0, shape=(), dtype=int32)
</pre></div>
</div>
</div>
</div>
<p>These are some of the control flow operations available in TensorFlow, which can be used for different purposes and applications involving dynamic and complex logic and computation. For more information, please refer to the <a class="reference external" href="https://www.tensorflow.org/api_docs/cc/group/control-flow-ops">TensorFlow documentation</a>.</p>
</section>
<section id="reduction-operations">
<h2><span class="section-number">12.5.5. </span>Reduction Operations<a class="headerlink" href="#reduction-operations" title="Permalink to this heading">#</a></h2>
<p>Sure, I can expand on reduction operations. Reduction operations are a subset of TensorFlow operations that reduce tensors along specified dimensions, by applying functions such as sum, mean, max, min, etc. Reduction operations can be useful for various purposes and applications involving data aggregation and analysis.</p>
<p>Some of the common reduction operations are <span id="id7">[<a class="reference internal" href="../References.html#id54" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>:</p>
<ul class="simple">
<li><p><strong>Sum and Mean:</strong> These operations compute the sum or the mean of elements along a specified axis or across the entire tensor. They can be useful for calculating totals or averages of data.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.reduce_sum</span></code> computes the sum of elements along a specified axis or across the entire tensor. <code class="docutils literal notranslate"><span class="pre">tf.reduce_mean</span></code> computes the mean of elements along a specified axis or across the entire tensor.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Compute the sum of elements along a specified axis or across the entire tensor</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">sum_axis_0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">sum_total</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Compute the sum of elements along a specified axis or across the entire tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sum_axis_0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sum_total</span><span class="p">)</span>

<span class="c1"># Compute the mean of elements along a specified axis or across the entire tensor</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">mean_axis_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">mean_total</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Compute the mean of elements along a specified axis or across the entire tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mean_axis_1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mean_total</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Compute the sum of elements along a specified axis or across the entire tensor:</span>
tf.Tensor([5 7 9], shape=(3,), dtype=int32)
tf.Tensor(21, shape=(), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Compute the mean of elements along a specified axis or across the entire tensor:</span>
tf.Tensor([2. 5.], shape=(2,), dtype=float32)
tf.Tensor(3.5, shape=(), dtype=float32)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Max and Min:</strong> These operations compute the maximum or the minimum of elements along a specified axis or across the entire tensor. They can be useful for finding the largest or the smallest values of data.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.reduce_max</span></code> computes the maximum of elements along a specified axis or across the entire tensor. <code class="docutils literal notranslate"><span class="pre">tf.reduce_min</span></code> computes the minimum of elements along a specified axis or across the entire tensor.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Compute the maximum of elements along a specified axis or across the entire tensor</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">max_axis_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">max_total</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Compute the maximum of elements along a specified axis or across the entire tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">max_axis_1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">max_total</span><span class="p">)</span>

<span class="c1"># Compute the minimum of elements along a specified axis or across the entire tensor</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">min_axis_0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">min_total</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Compute the minimum of elements along a specified axis or across the entire tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">min_axis_0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">min_total</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Compute the maximum of elements along a specified axis or across the entire tensor:</span>
tf.Tensor([3 6], shape=(2,), dtype=int32)
tf.Tensor(6, shape=(), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Compute the minimum of elements along a specified axis or across the entire tensor:</span>
tf.Tensor([1 2 3], shape=(3,), dtype=int32)
tf.Tensor(1, shape=(), dtype=int32)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>All and Any:</strong> These operations compute the logical AND or the logical OR of elements along a specified axis or across the entire tensor. They can be useful for checking the truth value of data.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.reduce_all</span></code> computes the logical AND of elements along a specified axis or across the entire tensor. <code class="docutils literal notranslate"><span class="pre">tf.reduce_any</span></code> computes the logical OR of elements along a specified axis or across the entire tensor.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Compute the logical AND of elements along a specified axis or across the entire tensor</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]])</span>
<span class="n">logical_and_axis_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">logical_and_total</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Compute the logical AND of elements along a specified axis or across the entire tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">logical_and_axis_1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">logical_and_total</span><span class="p">)</span>

<span class="c1"># Compute the logical OR of elements along a specified axis or across the entire tensor</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]])</span>
<span class="n">logical_or_axis_0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_any</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">logical_or_total</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_any</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Compute the logical OR of elements along a specified axis or across the entire tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">logical_or_axis_0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">logical_or_total</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Compute the logical AND of elements along a specified axis or across the entire tensor:</span>
tf.Tensor([False False], shape=(2,), dtype=bool)
tf.Tensor(False, shape=(), dtype=bool)

<span class=" -Color -Color-Bold -Color-Bold-Red">Compute the logical OR of elements along a specified axis or across the entire tensor:</span>
tf.Tensor([ True False  True], shape=(3,), dtype=bool)
tf.Tensor(True, shape=(), dtype=bool)
</pre></div>
</div>
</div>
</div>
<p>These are some of the reduction operations available in TensorFlow, which can be used for different purposes and applications involving data aggregation and analysis. For more information, please refer to the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/Reduction">TensorFlow documentation</a>.</p>
</section>
<section id="sparse-operations">
<h2><span class="section-number">12.5.6. </span>Sparse Operations<a class="headerlink" href="#sparse-operations" title="Permalink to this heading">#</a></h2>
<section id="sparse-tensors">
<h3><span class="section-number">12.5.6.1. </span>Sparse Tensors<a class="headerlink" href="#sparse-tensors" title="Permalink to this heading">#</a></h3>
<p>In certain scenarios, your data might exhibit sparsity, such as in a wide embedding space. TensorFlow provides support for handling sparse data through the use of <code class="docutils literal notranslate"><span class="pre">tf.sparse.SparseTensor</span></code> and associated operations. These tools allow you to efficiently store and manipulate sparse data within your TensorFlow computations <span id="id8">[<a class="reference internal" href="../References.html#id54" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</p>
<figure class="align-center" id="id16">
<a class="reference internal image-reference" href="../_images/sparse.png"><img alt="../_images/sparse.png" src="../_images/sparse.png" style="width: 200px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 12.16 </span><span class="caption-text">A <code class="docutils literal notranslate"><span class="pre">tf.SparseTensor</span></code>, shape: [3, 4]. Image courtesy of TensorFlow documentation <span id="id9">[<a class="reference internal" href="../References.html#id54" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>.</span><a class="headerlink" href="#id16" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Create a sparse tensor storing values by index</span>
<span class="n">sparse_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span>
                                       <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                                       <span class="n">dense_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>

<span class="c1"># Print the sparse tensor</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;Sparse Tensor:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sparse_tensor</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Convert sparse tensor to dense</span>
<span class="n">dense_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">to_dense</span><span class="p">(</span><span class="n">sparse_tensor</span><span class="p">)</span>

<span class="c1"># Print the dense tensor</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;Dense Tensor:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dense_tensor</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Sparse Tensor:</span>
SparseTensor(indices=tf.Tensor(
[[0 0]
 [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) 

<span class=" -Color -Color-Bold -Color-Bold-Red">Dense Tensor:</span>
tf.Tensor(
[[1 0 0 0]
 [0 0 2 0]
 [0 0 0 0]], shape=(3, 4), dtype=int32)
</pre></div>
</div>
</div>
</div>
<p>In this code, we’re showcasing the creation of a sparse tensor using <code class="docutils literal notranslate"><span class="pre">tf.sparse.SparseTensor</span></code> and the subsequent conversion of that sparse tensor to a dense tensor using <code class="docutils literal notranslate"><span class="pre">tf.sparse.to_dense</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Create a higher-dimensional sparse tensor</span>
<span class="n">sparse_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span>
                                       <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                                       <span class="n">dense_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>

<span class="c1"># Print the sparse tensor</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;Sparse Tensor:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sparse_tensor</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Convert sparse tensor to dense</span>
<span class="n">dense_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">to_dense</span><span class="p">(</span><span class="n">sparse_tensor</span><span class="p">)</span>

<span class="c1"># Print the dense tensor</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;Dense Tensor:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dense_tensor</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Sparse Tensor:</span>
SparseTensor(indices=tf.Tensor(
[[0 0 0]
 [1 2 3]
 [2 1 2]], shape=(3, 3), dtype=int64), values=tf.Tensor([1 2 3], shape=(3,), dtype=int32), dense_shape=tf.Tensor([3 4 5], shape=(3,), dtype=int64)) 

<span class=" -Color -Color-Bold -Color-Bold-Red">Dense Tensor:</span>
tf.Tensor(
[[[1 0 0 0 0]
  [0 0 0 0 0]
  [0 0 0 0 0]
  [0 0 0 0 0]]

 [[0 0 0 0 0]
  [0 0 0 0 0]
  [0 0 0 2 0]
  [0 0 0 0 0]]

 [[0 0 0 0 0]
  [0 0 3 0 0]
  [0 0 0 0 0]
  [0 0 0 0 0]]], shape=(3, 4, 5), dtype=int32)
</pre></div>
</div>
</div>
</div>
<p>In this example, we’re creating a sparse tensor with a shape of [3, 4, 5].</p>
</section>
<section id="id10">
<h3><span class="section-number">12.5.6.2. </span>Sparse Operations<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h3>
<p>Sparse operations are a subset of TensorFlow operations that are designed for sparse tensors, which store tensors with many zeros efficiently by only keeping the non-zero values and their indices. Sparse operations can be useful for various purposes and applications involving sparse data and computation.</p>
<p>Some of the common sparse operations are <span id="id11">[<a class="reference internal" href="../References.html#id54" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>:</p>
<ul class="simple">
<li><p><strong>Creation and Conversion:</strong> These operations create or convert sparse tensors from or to other formats, such as dense tensors, coordinate lists, or index-value maps.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.sparse.from_dense</span></code> creates a sparse tensor from a dense tensor. <code class="docutils literal notranslate"><span class="pre">tf.sparse.to_dense</span></code> converts a sparse tensor to a dense tensor. <code class="docutils literal notranslate"><span class="pre">tf.sparse.from_value_index</span></code> creates a sparse tensor from a value-index map.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Create a sparse tensor from a dense tensor</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">sparse_tensor_from_dense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">from_dense</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Create a sparse tensor from a dense tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sparse_tensor_from_dense</span><span class="p">)</span>

<span class="c1"># Convert a sparse tensor to a dense tensor</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dense_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">dense_tensor_from_sparse</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">to_dense</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Convert a sparse tensor to a dense tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dense_tensor_from_sparse</span><span class="p">)</span>

<span class="c1"># Create a sparse tensor from a value-index map</span>
<span class="n">z_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">z_values</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">sparse_tensor_from_map</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="n">z_indices</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">z_values</span><span class="p">,</span> <span class="n">dense_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">])</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Create a sparse tensor from a value-index map:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sparse_tensor_from_map</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Create a sparse tensor from a dense tensor:</span>
SparseTensor(indices=tf.Tensor(
[[0 2]
 [1 0]
 [2 1]], shape=(3, 2), dtype=int64), values=tf.Tensor([1 2 3], shape=(3,), dtype=int32), dense_shape=tf.Tensor([3 3], shape=(2,), dtype=int64))

<span class=" -Color -Color-Bold -Color-Bold-Red">Convert a sparse tensor to a dense tensor:</span>
tf.Tensor(
[[0 0 1]
 [2 0 0]
 [0 3 0]], shape=(3, 3), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Create a sparse tensor from a value-index map:</span>
SparseTensor(indices=tf.Tensor(
[[0]
 [2]
 [4]], shape=(3, 1), dtype=int64), values=tf.Tensor([10 20 30], shape=(3,), dtype=int32), dense_shape=tf.Tensor([5], shape=(1,), dtype=int64))
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Reduction and Aggregation:</strong> These operations reduce or aggregate sparse tensors along specified dimensions, by applying functions such as sum, mean, max, min, etc. They can be useful for data analysis and compression.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.sparse.reduce_sum</span></code> computes the sum of elements along a specified axis or across the entire sparse tensor. <code class="docutils literal notranslate"><span class="pre">tf.sparse.reduce_max</span></code> computes the maximum of elements along a specified axis or across the entire sparse tensor.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Compute the sum of elements along a specified axis or across the entire sparse tensor</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dense_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">sum_axis_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sum_total</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Compute the sum of elements along a specified axis or across the entire sparse tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sum_axis_1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sum_total</span><span class="p">)</span>

<span class="c1"># Compute the maximum of elements along a specified axis or across the entire sparse tensor</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dense_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">max_axis_0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">max_total</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Compute the maximum of elements along a specified axis or across the entire sparse tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">max_axis_0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">max_total</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Compute the sum of elements along a specified axis or across the entire sparse tensor:</span>
tf.Tensor([1 2 3], shape=(3,), dtype=int32)
tf.Tensor(6, shape=(), dtype=int32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Compute the maximum of elements along a specified axis or across the entire sparse tensor:</span>
tf.Tensor([1 0 2 3], shape=(4,), dtype=int32)
tf.Tensor(3, shape=(), dtype=int32)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Manipulation and Transformation:</strong> These operations change the shape, size, order, and content of sparse tensors in various ways, such as reshaping, slicing, reordering, filling, and masking.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.sparse.reshape</span></code> changes the shape of a sparse tensor to a specified shape. <code class="docutils literal notranslate"><span class="pre">tf.sparse.slice</span></code> extracts a slice of a sparse tensor based on a starting position and a size. <code class="docutils literal notranslate"><span class="pre">tf.sparse.fill_empty_rows</span></code> fills the empty rows of a sparse tensor with a default value.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Change the shape of a sparse tensor to a specified shape</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dense_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">reshaped_sparse_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Change the shape of a sparse tensor to a specified shape:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">reshaped_sparse_tensor</span><span class="p">)</span>

<span class="c1"># Extract a slice of a sparse tensor based on a starting position and a size</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dense_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">sliced_sparse_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Extract a slice of a sparse tensor based on a starting position and a size:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sliced_sparse_tensor</span><span class="p">)</span>

<span class="c1"># Fill the empty rows of a sparse tensor with a default value</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dense_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">filled_sparse_tensor</span><span class="p">,</span> <span class="n">non_empty_rows</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">fill_empty_rows</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Fill the empty rows of a sparse tensor with a default value:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">filled_sparse_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">non_empty_rows</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Change the shape of a sparse tensor to a specified shape:</span>
SparseTensor(indices=tf.Tensor(
[[0 0]
 [1 0]
 [1 5]], shape=(3, 2), dtype=int64), values=tf.Tensor([1 2 3], shape=(3,), dtype=int32), dense_shape=tf.Tensor([2 6], shape=(2,), dtype=int64))

<span class=" -Color -Color-Bold -Color-Bold-Red">Extract a slice of a sparse tensor based on a starting position and a size:</span>
SparseTensor(indices=tf.Tensor([[1 1]], shape=(1, 2), dtype=int64), values=tf.Tensor([2], shape=(1,), dtype=int32), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64))

<span class=" -Color -Color-Bold -Color-Bold-Red">Fill the empty rows of a sparse tensor with a default value:</span>
SparseTensor(indices=tf.Tensor(
[[0 0]
 [1 2]
 [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1 2 3], shape=(3,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))
tf.Tensor([False False False], shape=(3,), dtype=bool)
</pre></div>
</div>
</div>
</div>
<p>These are some of the sparse operations available in TensorFlow, which can be used for different purposes and applications involving sparse data and computation. For more information, please refer to the <a class="reference external" href="https://www.tensorflow.org/guide/sparse_tensor">TensorFlow documentation</a>.</p>
</section>
</section>
<section id="neural-network-operations">
<h2><span class="section-number">12.5.7. </span>Neural Network Operations<a class="headerlink" href="#neural-network-operations" title="Permalink to this heading">#</a></h2>
<p>Neural network operations are a subset of TensorFlow operations that are specifically tailored for building and training neural networks, and include activation functions, loss functions, optimizers, and layers. Neural network operations can be useful for various purposes and applications involving machine learning and deep learning.</p>
<p>Some of the common neural network operations are <span id="id12">[<a class="reference internal" href="../References.html#id54" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>:</p>
<ul class="simple">
<li><p><strong>Activation Functions:</strong> These operations apply non-linear functions to tensors, such as sigmoid, softmax, relu, tanh, etc. They can be useful for introducing non-linearity and complexity to neural networks, as well as for normalizing or scaling outputs.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.nn.sigmoid</span></code> applies the sigmoid function to a tensor, which maps each element to a value between 0 and 1. <code class="docutils literal notranslate"><span class="pre">tf.nn.softmax</span></code> applies the softmax function to a tensor, which normalizes each element to a probability distribution across the last dimension.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Apply the sigmoid function to a tensor</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">sigmoid_result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Apply the sigmoid function to a tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sigmoid_result</span><span class="p">)</span>

<span class="c1"># Apply the softmax function to a tensor</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">softmax_result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Apply the softmax function to a tensor:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">softmax_result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Apply the sigmoid function to a tensor:</span>
tf.Tensor([0.26894143 0.5        0.7310586 ], shape=(3,), dtype=float32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Apply the softmax function to a tensor:</span>
tf.Tensor(
[[0.09003057 0.24472848 0.66524094]
 [0.09003057 0.24472848 0.66524094]], shape=(2, 3), dtype=float32)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Loss Functions:</strong> These operations compute the loss or error between the predicted outputs and the actual outputs of a neural network, such as mean squared error, cross entropy, hinge loss, etc. They can be useful for measuring the performance and accuracy of neural networks, as well as for guiding the optimization process.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.keras.losses.MeanSquaredError</span></code> computes the mean squared error between the predicted outputs and the actual outputs of a neural network. <code class="docutils literal notranslate"><span class="pre">tf.keras.losses.BinaryCrossentropy</span></code> computes the binary cross entropy between the predicted outputs and the actual outputs of a neural network.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Compute the mean squared error between the predicted outputs and the actual outputs of a neural network</span>
<span class="n">y_true_mse</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_pred_mse</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">()</span>
<span class="n">mse_result</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">y_true_mse</span><span class="p">,</span> <span class="n">y_pred_mse</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Compute the mean squared error between the predicted outputs and the actual outputs of a neural network:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mse_result</span><span class="p">)</span>

<span class="c1"># Compute the binary cross entropy between the predicted outputs and the actual outputs of a neural network</span>
<span class="n">y_true_bce</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_pred_bce</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">bce</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">()</span>
<span class="n">bce_result</span> <span class="o">=</span> <span class="n">bce</span><span class="p">(</span><span class="n">y_true_bce</span><span class="p">,</span> <span class="n">y_pred_bce</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Compute the binary cross entropy between the predicted outputs and the actual outputs of a neural network:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bce_result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Compute the mean squared error between the predicted outputs and the actual outputs of a neural network:</span>
tf.Tensor(1.0, shape=(), dtype=float32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Compute the binary cross entropy between the predicted outputs and the actual outputs of a neural network:</span>
tf.Tensor(0.1446214, shape=(), dtype=float32)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Optimizers:</strong> These operations update the parameters of a neural network based on the gradients of the loss function, using various optimization algorithms, such as gradient descent, Adam, RMSProp, etc. They can be useful for improving the performance and accuracy of neural networks, by minimizing the loss function.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.SGD</span></code> updates the parameters of a neural network using stochastic gradient descent. <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.Adam</span></code> updates the parameters of a neural network using Adam, which is an adaptive learning rate optimization algorithm.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Update the parameters of a neural network using stochastic gradient descent</span>
<span class="n">model_sgd</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)])</span>
<span class="n">sgd</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">x_sgd</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># Adjust input shape</span>
<span class="n">y_true_sgd</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">4.</span><span class="p">],</span> <span class="p">[</span><span class="mf">5.</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># Adjust target shape</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape_sgd</span><span class="p">:</span>
    <span class="n">predictions_sgd</span> <span class="o">=</span> <span class="n">model_sgd</span><span class="p">(</span><span class="n">x_sgd</span><span class="p">)</span>
    <span class="n">loss_sgd</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">predictions_sgd</span> <span class="o">-</span> <span class="n">y_true_sgd</span><span class="p">))</span>
<span class="n">grads_sgd</span> <span class="o">=</span> <span class="n">tape_sgd</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss_sgd</span><span class="p">,</span> <span class="n">model_sgd</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
<span class="n">sgd</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads_sgd</span><span class="p">,</span> <span class="n">model_sgd</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

<span class="c1"># Update the parameters of a neural network using Adam</span>
<span class="n">model_adam</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)])</span>
<span class="n">adam</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">x_adam</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># Adjust input shape</span>
<span class="n">y_true_adam</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">4.</span><span class="p">],</span> <span class="p">[</span><span class="mf">5.</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># Adjust target shape</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape_adam</span><span class="p">:</span>
    <span class="n">predictions_adam</span> <span class="o">=</span> <span class="n">model_adam</span><span class="p">(</span><span class="n">x_adam</span><span class="p">)</span>
    <span class="n">loss_adam</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">predictions_adam</span> <span class="o">-</span> <span class="n">y_true_adam</span><span class="p">))</span>
<span class="n">grads_adam</span> <span class="o">=</span> <span class="n">tape_adam</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss_adam</span><span class="p">,</span> <span class="n">model_adam</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
<span class="n">adam</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads_adam</span><span class="p">,</span> <span class="n">model_adam</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=int64, numpy=1&gt;
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Layers:</strong> These operations create and apply layers to tensors, which are the basic building blocks of neural networks. Layers can perform various functions, such as linear transformation, convolution, pooling, dropout, batch normalization, etc. They can be useful for defining the structure and behavior of neural networks, as well as for adding complexity and functionality to them.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Dense</span></code> creates and applies a densely connected layer to a tensor, which performs a linear transformation with a specified number of units and an optional activation function. <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Conv2D</span></code> creates and applies a convolutional layer to a tensor, which performs a convolution operation with a specified number of filters and an optional activation function.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Create and apply a densely connected layer to a tensor</span>
<span class="n">x_dense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># Adjust input type</span>
<span class="n">dense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
<span class="n">output_dense</span> <span class="o">=</span> <span class="n">dense</span><span class="p">(</span><span class="n">x_dense</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Densely connected layer output:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output_dense</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

<span class="c1"># Create and apply a convolutional layer to a tensor</span>
<span class="n">y_conv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[[[</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">]],</span> <span class="p">[[</span><span class="mf">4.</span><span class="p">],</span> <span class="p">[</span><span class="mf">5.</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.</span><span class="p">]],</span> <span class="p">[[</span><span class="mf">7.</span><span class="p">],</span> <span class="p">[</span><span class="mf">8.</span><span class="p">],</span> <span class="p">[</span><span class="mf">9.</span><span class="p">]]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># Adjust input type</span>
<span class="n">conv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
<span class="n">output_conv</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">y_conv</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Convolutional layer output:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output_conv</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Densely connected layer output:</span>
[[0. 0.]
 [0. 0.]]

<span class=" -Color -Color-Bold -Color-Bold-Red">Convolutional layer output:</span>
[[[[0.]
   [0.]]

  [[0.]
   [0.]]]]
</pre></div>
</div>
</div>
</div>
<p>These are some of the neural network operations available in TensorFlow, which can be used for different purposes and applications involving machine learning and deep learning. For more information, please refer to the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn">TensorFlow documentation</a>.</p>
</section>
<section id="variable-operations">
<h2><span class="section-number">12.5.8. </span>Variable Operations<a class="headerlink" href="#variable-operations" title="Permalink to this heading">#</a></h2>
<p>Variable operations are a subset of TensorFlow operations that deal with the creation, modification, and management of variables, which are mutable tensors that can store and update values. Variable operations can be useful for various purposes and applications involving parameter optimization and stateful computation.</p>
<p>Some of the common variable operations are <span id="id13">[<a class="reference internal" href="../References.html#id54" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>:</p>
<ul class="simple">
<li><p><strong>Creation and Initialization:</strong> These operations create and initialize variables with specified values, shapes, and data types. They can be useful for defining and allocating variables for neural networks or other models.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code> creates a variable with an initial value, shape, and data type. <code class="docutils literal notranslate"><span class="pre">tf.zeros</span></code> creates a variable filled with zeros of a specified shape and data type. <code class="docutils literal notranslate"><span class="pre">tf.random.normal</span></code> creates a variable with random values from a normal distribution of a specified shape and data type.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a variable with an initial value, shape, and data type</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;x:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Create a variable filled with zeros of a specified shape and data type</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;y:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Create a variable with random values from a normal distribution of a specified shape and data type</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;z:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">x:</span>
&lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=int32, numpy=1&gt;
<span class=" -Color -Color-Bold -Color-Bold-Red">y:</span>
tf.Tensor(
[[0. 0.]
 [0. 0.]], shape=(2, 2), dtype=float32)
<span class=" -Color -Color-Bold -Color-Bold-Red">z:</span>
tf.Tensor(
[[-0.24941136  1.8433316  -0.5462926 ]
 [-1.6385643   0.15836732 -0.8668773 ]
 [ 0.6604828   1.0676547  -0.20584674]], shape=(3, 3), dtype=float32)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Modification and Assignment:</strong> These operations modify and assign new values to variables, either directly or by applying functions or operations. They can be useful for updating and changing variables during training or inference.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.assign</span></code> assigns a new value to a variable. <code class="docutils literal notranslate"><span class="pre">tf.assign_add</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.assign_sub</span></code> assign the result of adding or subtracting a value to a variable, respectively. <code class="docutils literal notranslate"><span class="pre">tf.scatter_update</span></code> updates a variable by scattering a value into specified indices.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Assign a new value to a variable</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">x</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;x:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Assign the result of adding or subtracting a value to a variable</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">y</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;y (after adding):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">y</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;y (after subtracting):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Update a variable by scattering a value into specified indices</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">updates</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">sparse_delta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">IndexedSlices</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">)</span>
<span class="n">z</span><span class="o">.</span><span class="n">scatter_update</span><span class="p">(</span><span class="n">sparse_delta</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;z (after scattering):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">x:</span>
&lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=int32, numpy=2&gt;
<span class=" -Color -Color-Bold -Color-Bold-Red">y (after adding):</span>
&lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=int32, numpy=3&gt;
<span class=" -Color -Color-Bold -Color-Bold-Red">y (after subtracting):</span>
&lt;tf.Variable &#39;Variable:0&#39; shape=() dtype=int32, numpy=2&gt;
<span class=" -Color -Color-Bold -Color-Bold-Red">z (after scattering):</span>
&lt;tf.Variable &#39;Variable:0&#39; shape=(3,) dtype=int32, numpy=array([1, 4, 5])&gt;
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Optimization and Gradient Descent:</strong> These operations optimize the parameters of a neural network or other model based on the gradients of the loss function, using various optimization algorithms, such as gradient descent, Adam, RMSProp, etc. They can be useful for improving the performance and accuracy of models, by minimizing the loss function.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.train.Optimizer</span></code> is an abstract class that provides common methods and attributes for optimizers. <code class="docutils literal notranslate"><span class="pre">tf.train.GradientDescentOptimizer</span></code> is a subclass of <code class="docutils literal notranslate"><span class="pre">tf.train.Optimizer</span></code> that implements the gradient descent algorithm. <code class="docutils literal notranslate"><span class="pre">tf.train.AdamOptimizer</span></code> is a subclass of <code class="docutils literal notranslate"><span class="pre">tf.train.Optimizer</span></code> that implements the Adam algorithm, which is an adaptive learning rate optimization algorithm.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create an optimizer that implements the gradient descent algorithm</span>
<span class="n">optimizer_sgd</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># Create an optimizer that implements the Adam algorithm</span>
<span class="n">optimizer_adam</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># Update the parameters of a model based on the gradients of the loss function using SGD</span>
<span class="n">model_sgd</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)])</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape_sgd</span><span class="p">:</span>
    <span class="n">loss_sgd</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">model_sgd</span><span class="p">(</span><span class="n">x_sgd</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_true_sgd</span><span class="p">))</span>
<span class="n">grads_sgd</span> <span class="o">=</span> <span class="n">tape_sgd</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss_sgd</span><span class="p">,</span> <span class="n">model_sgd</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
<span class="n">optimizer_sgd</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads_sgd</span><span class="p">,</span> <span class="n">model_sgd</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

<span class="c1"># Update the parameters of a model based on the gradients of the loss function using Adam</span>
<span class="n">model_adam</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)])</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape_adam</span><span class="p">:</span>
    <span class="n">loss_adam</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">model_adam</span><span class="p">(</span><span class="n">x_adam</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_true_adam</span><span class="p">))</span>
<span class="n">grads_adam</span> <span class="o">=</span> <span class="n">tape_adam</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss_adam</span><span class="p">,</span> <span class="n">model_adam</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
<span class="n">optimizer_adam</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads_adam</span><span class="p">,</span> <span class="n">model_adam</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

<span class="c1"># Print model summary for verification</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;Model Summary (SGD):&quot;</span><span class="p">)</span>
<span class="n">model_sgd</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Model Summary (Adam):&quot;</span><span class="p">)</span>
<span class="n">model_adam</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Model Summary (SGD):</span>
Model: &quot;sequential_13&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_18 (Dense)            (3, 1)                    2         
                                                                 
=================================================================
Total params: 2 (8.00 Byte)
Trainable params: 2 (8.00 Byte)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

<span class=" -Color -Color-Bold -Color-Bold-Red">Model Summary (Adam):</span>
Model: &quot;sequential_14&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_19 (Dense)            (3, 1)                    2         
                                                                 
=================================================================
Total params: 2 (8.00 Byte)
Trainable params: 2 (8.00 Byte)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<p>These are some of the variable operations available in TensorFlow, which can be used for different purposes and applications involving parameter optimization and stateful computation. For more information, please refer to the <a class="reference external" href="https://www.tensorflow.org/guide/variable">TensorFlow documentation</a>.</p>
</section>
<section id="i-o-operations">
<h2><span class="section-number">12.5.9. </span>I/O Operations<a class="headerlink" href="#i-o-operations" title="Permalink to this heading">#</a></h2>
<p>I/O operations are a subset of TensorFlow operations that facilitate the reading and writing of data from various sources, such as files, queues, or networks. I/O operations can be useful for various purposes and applications involving data input and output.</p>
<p>Some of the common I/O operations are <span id="id14">[<a class="reference internal" href="../References.html#id54" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>:</p>
<ul class="simple">
<li><p><strong>Reading and Writing Files:</strong> These operations read and write data from or to files, such as text files, binary files, image files, audio files, etc. They can be useful for loading and saving data from or to local or remote storage.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.io.read_file</span></code> reads the entire contents of a file as a string tensor. <code class="docutils literal notranslate"><span class="pre">tf.io.decode_image</span></code> decodes an image file into a uint8 tensor. <code class="docutils literal notranslate"><span class="pre">tf.io.write_file</span></code> writes a string tensor to a file.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read the entire contents of a file as a string tensor</span>
<span class="n">filename_text</span> <span class="o">=</span> <span class="s2">&quot;test_files/test.txt&quot;</span>
<span class="n">content_text</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">filename_text</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;File Content (Text):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">content_text</span><span class="p">)</span>

<span class="c1"># Decode an image file into a uint8 tensor</span>
<span class="n">filename_image</span> <span class="o">=</span> <span class="s2">&quot;test_files/test.jpg&quot;</span>
<span class="n">image_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">filename_image</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">decode_image</span><span class="p">(</span><span class="n">image_data</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Image Tensor:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="c1"># Write a string tensor to a file</span>
<span class="n">filename_output</span> <span class="o">=</span> <span class="s2">&quot;test_files/output.txt&quot;</span>
<span class="n">content_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="s2">&quot;Hello Calgary&quot;</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">write_file</span><span class="p">(</span><span class="n">filename_output</span><span class="p">,</span> <span class="n">content_output</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">File &#39;output.txt&#39; has been written.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">File Content (Text):</span>
tf.Tensor(b&#39;ENGG 680 - Fall 2023&#39;, shape=(), dtype=string)

<span class=" -Color -Color-Bold -Color-Bold-Red">Image Tensor:</span>
tf.Tensor(
[[[255 255 255]
  [255 255 255]
  [255 255 255]
  ...
  [255 255 255]
  [255 255 255]
  [255 255 255]]

 [[255 255 255]
  [255 255 255]
  [255 255 255]
  ...
  [255 255 255]
  [255 255 255]
  [255 255 255]]

 [[255 255 255]
  [255 255 255]
  [255 255 255]
  ...
  [255 255 255]
  [255 255 255]
  [255 255 255]]

 ...

 [[255 255 255]
  [255 255 255]
  [255 255 255]
  ...
  [255 255 255]
  [255 255 255]
  [255 255 255]]

 [[255 255 255]
  [255 255 255]
  [255 255 255]
  ...
  [255 255 255]
  [255 255 255]
  [255 255 255]]

 [[255 255 255]
  [255 255 255]
  [255 255 255]
  ...
  [255 255 255]
  [255 255 255]
  [255 255 255]]], shape=(100, 100, 3), dtype=uint8)

<span class=" -Color -Color-Bold -Color-Bold-Red">File &#39;output.txt&#39; has been written.</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Reading and Writing DataSets:</strong> These operations read and write data from or to data sets, which are collections of elements that can be iterated over. Data sets can be created from various sources, such as tensors, files, generators, etc. They can be useful for processing and transforming data in batches or streams.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.from_tensor_slices</span></code> creates a data set from a tensor or a list of tensors. <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.map</span></code> applies a function to each element of a data set. <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.batch</span></code> combines consecutive elements of a data set into batches.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a data set from a tensor or a list of tensors</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;TensorSliceDataset:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="c1"># Apply a function to each element of a data set</span>
<span class="k">def</span> <span class="nf">add_one</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">dataset_mapped</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">add_one</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">MapDataset:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset_mapped</span><span class="p">)</span>

<span class="c1"># Combine consecutive elements of a data set into batches</span>
<span class="n">dataset_batched</span> <span class="o">=</span> <span class="n">dataset_mapped</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">BatchDataset:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset_batched</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">TensorSliceDataset:</span>
&lt;_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.int32, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))&gt;

<span class=" -Color -Color-Bold -Color-Bold-Red">MapDataset:</span>
&lt;_MapDataset element_spec=(TensorSpec(shape=(), dtype=tf.int32, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))&gt;

<span class=" -Color -Color-Bold -Color-Bold-Red">BatchDataset:</span>
&lt;_BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))&gt;
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Reading and Writing TFRecords:</strong> These operations read and write data from or to TFRecords, which are binary files that store data as a sequence of protocol buffers. TFRecords can be useful for storing and loading large or complex data efficiently and reliably.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.io.TFRecordWriter</span></code> creates a writer that writes data to a TFRecord file. <code class="docutils literal notranslate"><span class="pre">tf.train.Example</span></code> creates an example that stores data as a protocol buffer. <code class="docutils literal notranslate"><span class="pre">tf.data.TFRecordDataset</span></code> creates a data set that reads data from a TFRecord file.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a writer that writes data to a TFRecord file</span>
<span class="n">filename</span> <span class="o">=</span> <span class="s2">&quot;test_files/test.tfrecord&quot;</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">TFRecordWriter</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;TFRecordWriter created for file:&quot;</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

<span class="c1"># Create an example that stores data as a protocol buffer</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span><span class="n">int64_list</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Int64List</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span><span class="n">int64_list</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Int64List</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">]))</span>
<span class="n">example</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Example</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Features</span><span class="p">(</span><span class="n">feature</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">}))</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Example:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>

<span class="c1"># Write the example to the TFRecord file</span>
<span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
<span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Example written to TFRecord file:&quot;</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

<span class="c1"># Create a data set that reads data from a TFRecord file</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TFRecordDataset</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">TFRecordDataset created:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>est_files/test.tfrecordmTFRecordWriter created for file:

<span class=" -Color -Color-Bold -Color-Bold-Red">Example:</span>
features {
  feature {
    key: &quot;x&quot;
    value {
      int64_list {
        value: 1
      }
    }
  }
  feature {
    key: &quot;y&quot;
    value {
      int64_list {
        value: 4
      }
    }
  }
}

est_files/test.tfrecordm
Example written to TFRecord file:

<span class=" -Color -Color-Bold -Color-Bold-Red">TFRecordDataset created:</span>
&lt;TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)&gt;
</pre></div>
</div>
</div>
</div>
<p>These are some of the I/O operations available in TensorFlow, which can be used for different purposes and applications involving data input and output. For more information, please refer to the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/io">TensorFlow documentation</a>.</p>
</section>
<section id="image-and-signal-processing-operations">
<h2><span class="section-number">12.5.10. </span>Image and Signal Processing Operations<a class="headerlink" href="#image-and-signal-processing-operations" title="Permalink to this heading">#</a></h2>
<p>Image and signal processing operations are a subset of TensorFlow operations that are specific to image and signal processing tasks, and include functions for resizing, cropping, filtering, and transforming images and signals. Image and signal processing operations can be useful for various purposes and applications involving image and signal analysis and synthesis.</p>
<p>Some of the common image and signal processing operations are <span id="id15">[<a class="reference internal" href="../References.html#id54" title="TensorFlow Developers. Tensorflow documentation. https://www.tensorflow.org/guide, 2023. [Online; accessed 01-August-2023].">TensorFlow Developers, 2023</a>]</span>:</p>
<ul class="simple">
<li><p><strong>Resizing and Cropping:</strong> These operations change the size or the region of interest of images or signals, such as scaling, padding, centering, or cropping. They can be useful for adjusting the resolution or the aspect ratio of images or signals, or for extracting specific parts of them.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.image.resize</span></code>: Resizes an image or a batch of images to a specified size using a chosen method. <code class="docutils literal notranslate"><span class="pre">tf.image.crop_and_resize</span></code>: Crops and resizes a batch of images using bounding boxes. <code class="docutils literal notranslate"><span class="pre">tf.signal.dct</span></code>: Resamples a signal or a batch of signals to a specified number of samples using a discrete cosine transform (DCT) method.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Resize an image or a batch of images to a specified size using a specified method</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">resized_image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">method</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">ResizeMethod</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;Resized Image:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">resized_image</span><span class="p">)</span>

<span class="c1"># Crop and resize a batch of images using bounding boxes</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">boxes</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">cropped_resized_images</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">crop_and_resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">boxes</span><span class="o">=</span><span class="n">boxes</span><span class="p">,</span> <span class="n">box_indices</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">crop_size</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Cropped and Resized Images:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cropped_resized_images</span><span class="p">)</span>

<span class="c1"># Resample a signal or a batch of signals to a specified number of samples using a specified method</span>
<span class="n">signal</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">resampled_signal</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">signal</span><span class="o">.</span><span class="n">dct</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Resampled Signal:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">resampled_signal</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Resized Image:</span>
tf.Tensor(
[[[[2. ]
   [3.5]]

  [[6.5]
   [8. ]]]], shape=(1, 2, 2, 1), dtype=float32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Cropped and Resized Images:</span>
tf.Tensor(
[[[[1.]
   [3.]]

  [[7.]
   [9.]]]


 [[[5.]
   [6.]]

  [[8.]
   [9.]]]], shape=(2, 2, 2, 1), dtype=float32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Resampled Signal:</span>
tf.Tensor(
[[ 7.2000000e+01 -2.5769291e+01  9.5367432e-07 -2.6938186e+00
  -4.7683716e-07 -8.0361128e-01 -9.5367432e-07 -2.0280755e-01]], shape=(1, 8), dtype=float32)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Filtering and Convolution:</strong> These operations apply filters or convolution kernels to images or signals, such as smoothing, sharpening, edge detection, or feature extraction. They can be useful for enhancing, modifying, or analyzing images or signals, or for building convolutional neural networks.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.image.sobel_edges</span></code> applies the Sobel filter to an image or a batch of images and returns the gradients along the x and y directions. <code class="docutils literal notranslate"><span class="pre">tf.nn.conv2d</span></code> applies a 2-D convolution to an input tensor and a filter tensor and returns the output tensor. <code class="docutils literal notranslate"><span class="pre">tf.signal.fft</span></code> applies the fast Fourier transform to a signal or a batch of signals and returns the complex spectrum.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Apply the Sobel filter to an image or a batch of images and return the gradients along the x and y directions</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">sobel_gradients</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">sobel_edges</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;Sobel Filter Gradients:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sobel_gradients</span><span class="p">)</span>

<span class="c1"># Apply a 2-D convolution to an input tensor and a filter tensor and return the output tensor</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">]]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">filter_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[[[</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">]]],</span> <span class="p">[[[</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">]]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">convolution_result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">filter_tensor</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Convolution Result:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">convolution_result</span><span class="p">)</span>

<span class="c1"># Apply the fast Fourier transform to a signal or a batch of signals and return the complex spectrum</span>
<span class="n">signal</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">fft_result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">signal</span><span class="o">.</span><span class="n">fft</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">complex64</span><span class="p">))</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Fast Fourier Transform Result:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fft_result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Sobel Filter Gradients:</span>
tf.Tensor(
[[[[[ 0.  0.]]

   [[ 0.  8.]]

   [[ 0.  0.]]]


  [[[24.  0.]]

   [[24.  8.]]

   [[24.  0.]]]


  [[[ 0.  0.]]

   [[ 0.  8.]]

   [[ 0.  0.]]]]], shape=(1, 3, 3, 1, 2), dtype=float32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Convolution Result:</span>
tf.Tensor(
[[[[12.]
   [16.]]

  [[24.]
   [28.]]]], shape=(1, 2, 2, 1), dtype=float32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Fast Fourier Transform Result:</span>
tf.Tensor([[10.+0.j -2.+2.j -2.+0.j -2.-2.j]], shape=(1, 4), dtype=complex64)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Transformation and Augmentation:</strong> These operations transform or augment images or signals, such as rotating, flipping, cropping, scaling, translating, or adding noise. They can be useful for changing the perspective or the appearance of images or signals, or for increasing the diversity and size of data sets.</p>
<ul>
<li><p>Example: <code class="docutils literal notranslate"><span class="pre">tf.image.rot90</span></code> rotates an image or a batch of images by 90 degrees. <code class="docutils literal notranslate"><span class="pre">tf.image.random_flip_left_right</span></code> randomly flips an image or a batch of images horizontally. <code class="docutils literal notranslate"><span class="pre">tf.image.central_crop</span></code> crops the central region of an image or a batch of images to a specified fraction of the original size.</p></li>
<li><p>Code:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Rotate an image or a batch of images by 90 degrees</span>
<span class="n">rotated_image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;Rotated Image:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rotated_image</span><span class="p">)</span>

<span class="c1"># Randomly flip an image or a batch of images horizontally</span>
<span class="n">flipped_image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">random_flip_left_right</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Flipped Image:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">flipped_image</span><span class="p">)</span>

<span class="c1"># Crop the central region of an image or a batch of images to a specified fraction of the original size</span>
<span class="n">cropped_image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">central_crop</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">central_fraction</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Cropped Image:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cropped_image</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Rotated Image:</span>
tf.Tensor(
[[[[3.]
   [6.]
   [9.]]

  [[2.]
   [5.]
   [8.]]

  [[1.]
   [4.]
   [7.]]]], shape=(1, 3, 3, 1), dtype=float32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Flipped Image:</span>
tf.Tensor(
[[[[3.]
   [2.]
   [1.]]

  [[6.]
   [5.]
   [4.]]

  [[9.]
   [8.]
   [7.]]]], shape=(1, 3, 3, 1), dtype=float32)

<span class=" -Color -Color-Bold -Color-Bold-Red">Cropped Image:</span>
tf.Tensor(
[[[[1.]
   [2.]
   [3.]]

  [[4.]
   [5.]
   [6.]]

  [[7.]
   [8.]
   [9.]]]], shape=(1, 3, 3, 1), dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>These are some of the image and signal processing operations available in TensorFlow, which can be used for different purposes and applications involving image and signal analysis and synthesis. For more information, please refer to the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/image">TensorFlow documentation</a>.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_12"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="ENGG_680_C12S04.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">12.4. </span>Introduction to Variables</p>
      </div>
    </a>
    <a class="right-next"
       href="ENGG_680_C12S06.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">12.6. </span>Building a linear Regression Model</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#math-operations">12.5.1. Math Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#array-operations">12.5.2. Array Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#string-operations">12.5.3. String Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#control-flow-operations">12.5.4. Control Flow Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reduction-operations">12.5.5. Reduction Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sparse-operations">12.5.6. Sparse Operations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sparse-tensors">12.5.6.1. Sparse Tensors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">12.5.6.2. Sparse Operations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-network-operations">12.5.7. Neural Network Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variable-operations">12.5.8. Variable Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i-o-operations">12.5.9. I/O Operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-and-signal-processing-operations">12.5.10. Image and Signal Processing Operations</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hatef Dastour
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>