

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>12.13. Brief Overview of Additional Topics &#8212; Introduction to Digital Engineering</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_12/ENGG_680_C12S13';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="13. References" href="../References.html" />
    <link rel="prev" title="12.12. Enhancing Image Classification Precision Through TensorFlow and Data Augmentation Strategies" href="ENGG_680_C12S12.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../Introduction.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Introduction to Digital Engineering - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Introduction to Digital Engineering - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_01/ReadMe.html">1. Introduction to Python Programming</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S1.html">1.1. Variable names, Expressions and statements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S2.html">1.2. Fundamental Concepts and Operations in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S3.html">1.3. Functions</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_02/ReadMe.html">2. Control Flow: Conditionals, Recursion, and Iteration</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG_680_C02S1.html">2.1. Conditionals and recursion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG_680_C02S2.html">2.2. Iteration</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_03/ReadMe.html">3. Data Structures and File Handling in Python</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S1.html">3.1. Strings in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S2.html">3.2. Python Lists</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S3.html">3.3. Python Dictionaries: Key-Value Pairs in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S4.html">3.4. Python Tuples: Immutable Sequences in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S5.html">3.5. Python Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S6.html">3.6. Files in Python (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_04/ReadMe.html">4. Classes and Objects</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S1.html">4.1. Introduction to Classes and Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S2.html">4.2. Inheritance and Polymorphism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S3.html">4.3. Encapsulation and Abstraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S4.html">4.4. Copying Objects (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S5.html">4.5. Magic Methods (Dunder Methods) in Python (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S6.html">4.6. Examples of Classes (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_05/ReadMe.html">5. Introduction to NumPy</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S1.html">5.1. Basics of Numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S2.html">5.2. NumPy Function Reference and Usage Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S3.html">5.3. Advanced Numpy Concepts (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_06/ReadMe.html">6. Working with Data using Pandas</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S1.html">6.1. An Introduction to Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S2.html">6.2. DataFrame and Series Indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S3.html">6.3. Pandas Data Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S4.html">6.4. Handling Missing Data in Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S5.html">6.5. Combining Datasets using Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S6.html">6.6. Aggregation and Grouping in Pandas</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_07/ReadMe.html">7. Data Visualization using Python</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S1.html">7.1. Getting started with Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S2.html">7.2. Matplotlib Styles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S3.html">7.3. Matplotlib interfaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S4.html">7.4. Adjusting the Plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S5.html">7.5. Seaborn plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S6.html">7.6. Python Plotting Guide</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_08/ReadMe.html">8. An Introduction to Computer Vision</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S1.html">8.1. Getting Started with OpenCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S2.html">8.2. Geometric Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S3.html">8.3. Image Thresholding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S4.html">8.4. Image Filtering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S5.html">8.5. Drawing Functions (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_09/ReadMe.html">9. An Introduction to Machine Learning</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S1.html">9.1. Prologue: Statistical Metrics and Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S2.html">9.2. An Introduction to Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S3.html">9.3. Multiple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S4.html">9.4. Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S5.html">9.5. K-Nearest Neighbors (K-NN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S6.html">9.6. Resampling Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_09/ENGG_680_C09S7.html">9.7. Support Vector Machines</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_10/ReadMe.html">10. Tree-Based Methods</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S1.html">10.1. Fundamental Structure of Decision Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S2.html">10.2. Regression Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S3.html">10.3. Classification Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S4.html">10.4. Regression Trees and Linear Models (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S5.html">10.5. Enhancing Decision Trees with Bagging: An Introduction (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S6.html">10.6. Random Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S7.html">10.7. Gradient Boosting</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_11/ReadMe.html">11. Dimensionality Reduction and Feature Selection</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S1.html">11.1. Introduction to Dimensionality Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S2.html">11.2. Principal Components Analysis (PCA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S3.html">11.3. t-Distributed Stochastic Neighbor Embedding (t-SNE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S4.html">11.4. Linear and Quadratic Discriminant Analyses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S5.html">11.5. Recursive Feature Elimination (RFE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S6.html">11.6. Practical Considerations in Dimensionality Reduction</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="ReadMe.html">12. Introduction to Deep Learning</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S01.html">12.1. Understanding Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S02.html">12.2. Fundamentals of Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S03.html">12.3. TensorFlow Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S04.html">12.4. Introduction to Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S05.html">12.5. Tensors in Various Operations (Ops)</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S06.html">12.6. Building a linear Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S07.html">12.7. Building a Logistic Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S08.html">12.8. Multilayer Perceptron (MLP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S09.html">12.9. Deep Learning Architectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S10.html">12.10. Image classification with TensorFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S11.html">12.11. Image Augmentations with TensorFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C12S12.html">12.12. Enhancing Image Classification Precision Through TensorFlow and Data Augmentation Strategies</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">12.13. Brief Overview of Additional Topics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../References.html">13. References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Brief Overview of Additional Topics</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning">12.13.1. Transfer learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch">12.13.2. PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unsupervised-deep-learning-methods">12.13.3. Unsupervised Deep Learning Methods</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recent-advances-and-research-directions-in-deep-learning">12.13.4. Recent Advances and Research Directions in Deep Learning</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="brief-overview-of-additional-topics">
<h1><span class="section-number">12.13. </span>Brief Overview of Additional Topics<a class="headerlink" href="#brief-overview-of-additional-topics" title="Permalink to this heading">#</a></h1>
<p>We have addressed fundamental topics in deep learning, serving as a foundation for further exploration based on your requirements. Areas of potential interest include:</p>
<section id="transfer-learning">
<h2><span class="section-number">12.13.1. </span>Transfer learning<a class="headerlink" href="#transfer-learning" title="Permalink to this heading">#</a></h2>
<p>Transfer learning is based on the idea that a model that has learned some general features or patterns from a large and diverse dataset can be adapted to a new task that has less data or is more specific. For example, a model that has been trained on ImageNet, which is a dataset of millions of images from 1000 categories, can be fine-tuned for a specific image classification problem, such as identifying different types of flowers or animals. To do this, the model can either use the pre-trained weights as a fixed feature extractor, or update some or all of the weights with a smaller learning rate. Transfer learning can save time and computational resources, as it does not require training a model from scratch. It can also improve the performance of the model on the new task, as it can leverage the knowledge and experience gained from the previous task. Transfer learning is especially useful when the new task has a similar domain or structure as the previous task, or when the new task has limited or noisy data. Transfer learning is widely used in deep learning, especially for computer vision and natural language processing. You can read more about transfer learning in this article, which provides a comprehensive survey of transfer learning methods, applications, and challenges. You can also check out this article, which compares the performance of different transfer learning models for image classification <span id="id1">[<a class="reference internal" href="../References.html#id3" title="C.C. Aggarwal. Neural Networks and Deep Learning: A Textbook. Springer International Publishing, 2023. ISBN 9783031296420. URL: https://books.google.ca/books?id=0-rIEAAAQBAJ.">Aggarwal, 2023</a>, <a class="reference internal" href="../References.html#id40" title="Hatef Dastour and Quazi K. Hassan. A comparison of deep transfer learning methods for land use and land cover classification. Sustainability, 15(10):7854, 2023. doi:10.3390/su15107854.">Dastour and Hassan, 2023</a>, <a class="reference internal" href="../References.html#id221" title="R. Razavi-Far, B. Wang, M.E. Taylor, and Q. Yang. Federated and Transfer Learning. Adaptation, Learning, and Optimization. Springer International Publishing, 2022. ISBN 9783031117480. URL: https://books.google.ca/books?id=0M2REAAAQBAJ.">Razavi-Far <em>et al.</em>, 2022</a>, <a class="reference internal" href="../References.html#id220" title="J. Wang and Y. Chen. Introduction to Transfer Learning: Algorithms and Practice. Machine Learning: Foundations, Methodologies, and Applications. Springer Nature Singapore, 2023. ISBN 9789811975844. URL: https://books.google.ca/books?id=GOW2EAAAQBAJ.">Wang and Chen, 2023</a>]</span>.</p>
</section>
<section id="pytorch">
<h2><span class="section-number">12.13.2. </span>PyTorch<a class="headerlink" href="#pytorch" title="Permalink to this heading">#</a></h2>
<p>PyTorch is a popular and powerful framework for deep learning that allows you to build, train, and deploy neural networks with ease. PyTorch offers a dynamic and imperative programming style that is intuitive and flexible. PyTorch also supports GPU acceleration, distributed training, and various tools and libraries for computer vision, natural language processing, and more. PyTorch is a framework for deep learning that has four main components <span id="id2">[<a class="reference internal" href="../References.html#id224" title="Kathleen M Chen, Evan M Cofer, Jian Zhou, and Olga G Troyanskaya. Selene: a pytorch-based deep learning library for sequence data. Nature methods, 16(4):315–318, 2019. doi:10.1038/s41592-019-0360-8.">Chen <em>et al.</em>, 2019</a>, <a class="reference internal" href="../References.html#id223" title="P. Mishra. PyTorch Recipes: A Problem-Solution Approach. Apress, 2019. ISBN 9781484242582. URL: https://books.google.ca/books?id=X5OFDwAAQBAJ.">Mishra, 2019</a>, <a class="reference internal" href="../References.html#id222" title="PyTorch Developers. Pytorch documentation. https://pytorch.org/docs/stable/index.html, 2023. [Online; accessed 01-October-2023].">PyTorch Developers, 2023</a>]</span>:</p>
<ul class="simple">
<li><p><strong>Tensors</strong>: Tensors are multidimensional arrays that can store data of different types and shapes. Tensors are similar to NumPy arrays, but they can also be used on GPUs and other devices for faster computation. Tensors are the basic building blocks of PyTorch, and they support various operations, such as arithmetic, indexing, slicing, broadcasting, and linear algebra. Tensors can also be converted to and from NumPy arrays, which makes it easy to integrate PyTorch with other Python libraries. You can learn more about tensors in this tutorial.</p></li>
<li><p><strong>Autograd</strong>: Autograd is a module that provides automatic differentiation for all operations on tensors. Autograd can track the history of tensor operations and compute the gradients of any scalar output with respect to any tensor input. Autograd can handle complex computational graphs and dynamic control flows, which makes it easy to implement backpropagation and optimize neural networks. Autograd also allows you to define custom gradients for any tensor operation, which gives you more flexibility and control over your model. You can find out more about autograd in this tutorial.</p></li>
<li><p><strong>Modules</strong>: Modules are containers that can hold one or more tensors or other modules. Modules can define parameters, submodules, and forward functions that specify how to compute the output from the input. Modules can also register hooks and buffers that can modify the behavior of the module. Modules are the main way of creating and organizing neural network architectures in PyTorch, and they inherit from the <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> class. Modules can also be saved and loaded, which makes it easy to reuse and share your models. You can explore more about modules in this tutorial.</p></li>
<li><p><strong>Optimizers</strong>: Optimizers are classes that implement various optimization algorithms for updating the parameters of modules. Optimizers can take the gradients computed by autograd and apply different update rules, such as stochastic gradient descent, Adam, or RMSprop. Optimizers can also support features such as learning rate scheduling, momentum, weight decay, and gradient clipping. Optimizers can help you improve the performance and convergence of your model, as well as prevent overfitting and exploding gradients. You can read more about optimizers in this tutorial.</p></li>
</ul>
</section>
<section id="unsupervised-deep-learning-methods">
<h2><span class="section-number">12.13.3. </span>Unsupervised Deep Learning Methods<a class="headerlink" href="#unsupervised-deep-learning-methods" title="Permalink to this heading">#</a></h2>
<p>In extending our exploration of deep learning, it is imperative to delve into unsupervised learning methods, a domain that holds significant relevance in various applications. Unsupervised learning operates without labeled training data, allowing models to identify patterns and structures within the data on their own. This subsection introduces key unsupervised deep learning methods, offering a glimpse into their functionalities and applications.</p>
<ul class="simple">
<li><p><strong>Autoencoders</strong>: Autoencoders are a type of neural network architecture that is designed for unsupervised learning and data compression. They consist of two main components: an encoder and a decoder. The encoder takes the input data and compresses it into a lower-dimensional representation, while the decoder takes this compressed representation and reconstructs the original input data. The goal of an autoencoder is to learn an efficient representation of the input data that can be used for tasks such as feature learning, dimensionality reduction, and data denoising. Autoencoders are trained using backpropagation, which involves minimizing the difference between the input data and the reconstructed output. This is done by adjusting the weights of the neural network using gradient descent. The weights of the encoder and decoder are learned jointly, which allows the autoencoder to learn a compressed representation of the input data that is optimized for the reconstruction task. Autoencoders have many applications in deep learning, including image and video processing, natural language processing, and anomaly detection. They are also used in generative models such as variational autoencoders and generative adversarial networks (GANs) <span id="id3">[<a class="reference internal" href="../References.html#id235" title="J.O.P. Pinto, M.L.M. Kimpara, R.R. Reis, T. Seecharan, B.R. Upadhyaya, and J. Amadi-Echendu. 15th WCEAM Proceedings. Lecture Notes in Mechanical Engineering. Springer International Publishing, 2022. ISBN 9783030967949. URL: https://books.google.ca/books?id=fN5mEAAAQBAJ.">Pinto <em>et al.</em>, 2022</a>, <a class="reference internal" href="../References.html#id234" title="R.K. Sevakula and N.K. Verma. Improving Classifier Generalization: Real-Time Machine Learning based Applications. Studies in Computational Intelligence. Springer Nature Singapore, 2022. ISBN 9789811950735. URL: https://books.google.ca/books?id=0JCREAAAQBAJ.">Sevakula and Verma, 2022</a>]</span>.</p></li>
<li><p><strong>Clustering</strong>: Deep learning-based clustering is a popular technique that can learn clustering-friendly representations using deep neural networks. There are several deep unsupervised learning methods available which can map data-points to meaningful low dimensional representation vectors . Here are some popular deep learning-based clustering techniques <span id="id4">[<a class="reference internal" href="../References.html#id236" title="S. Chakraborty, S.H. Islam, and D. Samanta. Data Classification and Incremental Clustering in Data Mining and Machine Learning. EAI/Springer Innovations in Communication and Computing. Springer International Publishing, 2022. ISBN 9783030930882. URL: https://books.google.ca/books?id=xSFvEAAAQBAJ.">Chakraborty <em>et al.</em>, 2022</a>, <a class="reference internal" href="../References.html#id237" title="P.P. Joby, V.E. Balas, and R. Palanisamy. IoT Based Control Networks and Intelligent Systems: Proceedings of 3rd ICICNIS 2022. Lecture Notes in Networks and Systems. Springer Nature Singapore, 2022. ISBN 9789811958458. URL: https://books.google.ca/books?id=__WVEAAAQBAJ.">Joby <em>et al.</em>, 2022</a>]</span>:</p>
<ul>
<li><p><strong>Deep Adaptive Clustering</strong>: This method uses a deep autoencoder network to learn a low-dimensional representation of the input data and then applies a clustering algorithm to the learned representation <span id="id5">[<a class="reference internal" href="../References.html#id238" title="Usman Ahmed, Gautam Srivastava, Unil Yun, and Jerry Chun-Wei Lin. Eandc: an explainable attention network based deep adaptive clustering model for mental health treatment. Future Generation Computer Systems, 130:106–113, 2022. doi:10.1016/j.future.2021.12.008.">Ahmed <em>et al.</em>, 2022</a>]</span>.</p></li>
<li><p><strong>Clustering via Information Maximization</strong>: This method maximizes the mutual information between the input data and the learned representation to obtain a clustering solution <span id="id6">[<a class="reference internal" href="../References.html#id239" title="Zhizhong Huang, Jie Chen, Junping Zhang, and Hongming Shan. Learning representation for clustering via prototype scattering and positive sampling. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022. doi:10.1109/TPAMI.2022.3216454.">Huang <em>et al.</em>, 2022</a>]</span>.</p></li>
<li><p><strong>Information Maximization with Self-Augmented Training</strong>: This method uses a self-augmented training strategy to improve the quality of the learned representation and obtain better clustering results <span id="id7">[<a class="reference internal" href="../References.html#id240" title="Foivos Ntelemis, Yaochu Jin, and Spencer A Thomas. Information maximization clustering via multi-view self-labelling. Knowledge-Based Systems, 250:109042, 2022. doi:10.1016/j.knosys.2022.109042.">Ntelemis <em>et al.</em>, 2022</a>]</span>.</p></li>
</ul>
</li>
<li><p><strong>Generative Adversarial Networks (GANs)</strong>: GANs are a type of neural network architecture that consists of two networks: a generator and a discriminator. The generator creates new data samples that are similar to the training data, while the discriminator tries to distinguish between the generated data and the real data. GANs can be used for image generation, data augmentation, and style transfer <span id="id8">[<a class="reference internal" href="../References.html#id241" title="Yuzhen Lu, Dong Chen, Ebenezer Olaniyi, and Yanbo Huang. Generative adversarial networks (gans) for image augmentation in agriculture: a systematic review. Computers and Electronics in Agriculture, 200:107208, 2022. doi:10.1016/j.compag.2022.107208.">Lu <em>et al.</em>, 2022</a>]</span>.</p></li>
<li><p><strong>Self-Supervised Learning</strong>: Self-supervised learning leverages the inherent structures within the data to create supervised tasks without external labels. This paradigm has gained prominence in tasks like natural language processing and computer vision. Self-supervised learning aims to leverage inherent structures or relationships within the input data to create meaningful training signals. SSL tasks are designed so that solving it requires capturing essential features or relationships in the data. The input data is typically augmented or transformed in a way that creates pairs of related samples. One sample serves as the input, and the other is used to formulate the supervisory signal. This augmentation can involve introducing noise, cropping, rotation, or other transformations <span id="id9">[<a class="reference internal" href="../References.html#id242" title="Rayan Krishnan, Pranav Rajpurkar, and Eric J Topol. Self-supervised learning in medicine and healthcare. Nature Biomedical Engineering, 6(12):1346–1352, 2022. doi:10.1038/s41551-022-00914-1.">Krishnan <em>et al.</em>, 2022</a>]</span>.</p></li>
</ul>
<p>By familiarizing yourself with these unsupervised deep learning methods, you gain a more comprehensive understanding of the diverse capabilities within the deep learning landscape. These techniques not only expand your toolkit but also open avenues for addressing real-world challenges where labeled data might be limited or unavailable.</p>
</section>
<section id="recent-advances-and-research-directions-in-deep-learning">
<h2><span class="section-number">12.13.4. </span>Recent Advances and Research Directions in Deep Learning<a class="headerlink" href="#recent-advances-and-research-directions-in-deep-learning" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Multimodal Deep Learning</strong>: This is an area of deep learning that focuses on processing and analyzing data from multiple sources, such as text, images, and audio. Recent research in this area has focused on developing new architectures and techniques for multimodal learning <span id="id10">[<a class="reference internal" href="../References.html#id226" title="Jiquan Ngiam, Aditya Khosla, Mingyu Kim, Juhan Nam, Honglak Lee, and Andrew Y Ng. Multimodal deep learning. In Proceedings of the 28th international conference on machine learning (ICML-11), 689–696. 2011.">Ngiam <em>et al.</em>, 2011</a>, <a class="reference internal" href="../References.html#id227" title="Shangran Qiu, Matthew I Miller, Prajakta S Joshi, Joyce C Lee, Chonghua Xue, Yunruo Ni, Yuwei Wang, Ileana De Anda-Duran, Phillip H Hwang, Justin A Cramer, and others. Multimodal deep learning for alzheimer’s disease dementia assessment. Nature communications, 13(1):3404, 2022. doi:10.1038/s41467-022-31037-5.">Qiu <em>et al.</em>, 2022</a>]</span>.</p></li>
<li><p><strong>Interpretability in Deep Learning</strong>: Interpretability is an important aspect of deep learning, especially in applications where the decisions made by the model can have significant consequences. Recent research has focused on developing methods for making neural network decisions more transparent and understandable. Some of these methods include Layer-wise Relevance Propagation (LRP) and Integrated Gradients <span id="id11">[<a class="reference internal" href="../References.html#id228" title="Qiaoying Teng, Zhe Liu, Yuqing Song, Kai Han, and Yang Lu. A survey on the interpretability of deep learning in medical diagnosis. Multimedia Systems, 28(6):2335–2355, 2022. doi:10.1007/s00530-022-00960-4.">Teng <em>et al.</em>, 2022</a>]</span>.</p></li>
<li><p><strong>Incremental Learning</strong>: Incremental learning is a technique for training deep learning models on new data without forgetting what they have learned from previous data. Recent research in this area has focused on developing new algorithms and architectures for incremental learning <span id="id12">[<a class="reference internal" href="../References.html#id230" title="Songsong Tian, Lusi Li, Weijun Li, Hang Ran, Xin Ning, and Prayag Tiwari. A survey on few-shot class-incremental learning. Neural Networks, 169:307–324, 2024. doi:10.1016/j.neunet.2023.10.039.">Tian <em>et al.</em>, 2024</a>, <a class="reference internal" href="../References.html#id229" title="Gido M van de Ven, Tinne Tuytelaars, and Andreas S Tolias. Three types of incremental learning. Nature Machine Intelligence, 4(12):1185–1197, 2022. doi:10.1038/s42256-022-00568-3.">van de Ven <em>et al.</em>, 2022</a>]</span>.</p></li>
<li><p><strong>Generative Models</strong>: Generative models are a type of deep learning model that can generate new data that is similar to the training data. Recent research in this area has focused on developing new architectures and techniques for generative models, such as Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) <span id="id13">[<a class="reference internal" href="../References.html#id233" title="Masahiro Suzuki and Yutaka Matsuo. A survey of multimodal deep generative models. Advanced Robotics, 36(5-6):261–278, 2022. doi:10.1080/01691864.2022.2035253.">Suzuki and Matsuo, 2022</a>]</span>.</p></li>
<li><p><strong>Deep Reinforcement Learning</strong>: Deep reinforcement learning is a technique for training agents to perform tasks in an environment by rewarding them for good behavior. Recent research in this area has focused on developing new algorithms and architectures for deep reinforcement learning, such as Proximal Policy Optimization (PPO) and Soft Actor-Critic (SAC) <span id="id14">[<a class="reference internal" href="../References.html#id231" title="Pawel Ladosz, Lilian Weng, Minwoo Kim, and Hyondong Oh. Exploration in deep reinforcement learning: a survey. Information Fusion, 85:1–22, 2022. doi:10.1016/j.inffus.2022.03.003.">Ladosz <em>et al.</em>, 2022</a>, <a class="reference internal" href="../References.html#id232" title="S.E. Li. Reinforcement Learning for Sequential Decision and Optimal Control. Springer Nature, 2023. ISBN 9789811977862. URL: https://books.google.ca/books?id=BNYy0AEACAAJ.">Li, 2023</a>]</span>.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_12"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="ENGG_680_C12S12.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">12.12. </span>Enhancing Image Classification Precision Through TensorFlow and Data Augmentation Strategies</p>
      </div>
    </a>
    <a class="right-next"
       href="../References.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">13. </span>References</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning">12.13.1. Transfer learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch">12.13.2. PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unsupervised-deep-learning-methods">12.13.3. Unsupervised Deep Learning Methods</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recent-advances-and-research-directions-in-deep-learning">12.13.4. Recent Advances and Research Directions in Deep Learning</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hatef Dastour
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>