
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>9.6. Resampling Methods &#8212; Introduction to Digital Engineering</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css?v=564be945" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_09/ENGG_680_C09S6';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="9.7. Support Vector Machines" href="ENGG_680_C09S7.html" />
    <link rel="prev" title="9.5. K-Nearest Neighbors (K-NN)" href="ENGG_680_C09S5.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../Introduction.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Introduction to Digital Engineering - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Introduction to Digital Engineering - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_01/ReadMe.html">1. Introduction to Python Programming</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S1.html">1.1. Variable names, Expressions and statements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S2.html">1.2. Fundamental Concepts and Operations in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/ENGG_680_C01S3.html">1.3. Functions</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_02/ReadMe.html">2. Control Flow: Conditionals, Recursion, and Iteration</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG_680_C02S1.html">2.1. Conditionals and recursion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG_680_C02S2.html">2.2. Iteration</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_03/ReadMe.html">3. Data Structures and File Handling in Python</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S1.html">3.1. Strings in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S2.html">3.2. Python Lists</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S3.html">3.3. Python Dictionaries: Key-Value Pairs in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S4.html">3.4. Python Tuples: Immutable Sequences in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S5.html">3.5. Python Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG_680_C03S6.html">3.6. Files in Python (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_04/ReadMe.html">4. Classes and Objects</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S1.html">4.1. Introduction to Classes and Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S2.html">4.2. Inheritance and Polymorphism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S3.html">4.3. Encapsulation and Abstraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S4.html">4.4. Copying Objects (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S5.html">4.5. Magic Methods (Dunder Methods) in Python (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_04/ENGG_680_C04S6.html">4.6. Examples of Classes (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_05/ReadMe.html">5. Introduction to NumPy</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S1.html">5.1. Basics of Numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S2.html">5.2. NumPy Function Reference and Usage Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/ENGG_680_C05S3.html">5.3. Advanced Numpy Concepts (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_06/ReadMe.html">6. Working with Data using Pandas</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S1.html">6.1. An Introduction to Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S2.html">6.2. DataFrame and Series Indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S3.html">6.3. Pandas Data Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S4.html">6.4. Handling Missing Data in Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S5.html">6.5. Combining Datasets using Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/ENGG_680_C06S6.html">6.6. Aggregation and Grouping in Pandas</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_07/ReadMe.html">7. Data Visualization using Python</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S1.html">7.1. Getting started with Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S2.html">7.2. Matplotlib Styles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S3.html">7.3. Matplotlib interfaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S4.html">7.4. Adjusting the Plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S5.html">7.5. Seaborn plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/ENGG_680_C07S6.html">7.6. Python Plotting Guide</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_08/ReadMe.html">8. An Introduction to Computer Vision</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S1.html">8.1. Getting Started with OpenCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S2.html">8.2. Geometric Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S3.html">8.3. Image Thresholding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S4.html">8.4. Image Filtering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_08/ENGG_680_C08S5.html">8.5. Drawing Functions (Optional Section)</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="ReadMe.html">9. An Introduction to Machine Learning</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C09S1.html">9.1. Prologue: Statistical Metrics and Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C09S2.html">9.2. An Introduction to Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C09S3.html">9.3. Multiple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C09S4.html">9.4. Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C09S5.html">9.5. K-Nearest Neighbors (K-NN)</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">9.6. Resampling Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG_680_C09S7.html">9.7. Support Vector Machines</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_10/ReadMe.html">10. Tree-Based Methods</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S1.html">10.1. Fundamental Structure of Decision Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S2.html">10.2. Regression Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S3.html">10.3. Classification Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S4.html">10.4. Regression Trees and Linear Models (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S5.html">10.5. Enhancing Decision Trees with Bagging: An Introduction (Optional Section)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S6.html">10.6. Random Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_10/ENGG_680_C10S7.html">10.7. Gradient Boosting</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_11/ReadMe.html">11. Dimensionality Reduction and Feature Selection</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S1.html">11.1. Introduction to Dimensionality Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S2.html">11.2. Principal Components Analysis (PCA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S3.html">11.3. t-Distributed Stochastic Neighbor Embedding (t-SNE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S4.html">11.4. Linear and Quadratic Discriminant Analyses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S5.html">11.5. Recursive Feature Elimination (RFE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_11/ENGG_680_C11S6.html">11.6. Practical Considerations in Dimensionality Reduction</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_12/ReadMe.html">12. Introduction to Deep Learning</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S01.html">12.1. Understanding Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S02.html">12.2. Fundamentals of Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S03.html">12.3. TensorFlow Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S04.html">12.4. Introduction to Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S05.html">12.5. Tensors in Various Operations (Ops)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S06.html">12.6. Building a linear Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S07.html">12.7. Building a Logistic Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S08.html">12.8. Multilayer Perceptron (MLP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S09.html">12.9. Deep Learning Architectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S10.html">12.10. Image classification with TensorFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S11.html">12.11. Image Augmentations with TensorFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S12.html">12.12. Enhancing Image Classification Precision Through TensorFlow and Data Augmentation Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_12/ENGG_680_C12S13.html">12.13. Brief Overview of Additional Topics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../References.html">13. References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Resampling Methods</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation-cv">9.6.1. Cross-Validation (CV)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#leave-one-out-cross-validation-loocv">9.6.1.1. Leave-One-Out Cross-Validation (LOOCV)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bootstrap-method">9.6.2. Bootstrap Method</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="resampling-methods">
<h1><span class="section-number">9.6. </span>Resampling Methods<a class="headerlink" href="#resampling-methods" title="Link to this heading">#</a></h1>
<p>Resampling methods involve the iterative extraction of sample data from a training set, followed by refitting a model of interest on each sample. This iterative process yields additional information about the fitted model. For instance, it allows us to assess the variability of a linear regression fit and compare the results. Two widely used resampling methods are <span id="id1">[<a class="reference internal" href="../References.html#id98" title="Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani, and Jonathan Taylor. An Introduction to Statistical Learning: with Applications in R. Springer Texts in Statistics. Springer Cham, 2023. ISBN 9783031391897. URL: https://link.springer.com/book/10.1007/978-3-031-38747-0.">James <em>et al.</em>, 2023</a>]</span>:</p>
<section id="cross-validation-cv">
<h2><span class="section-number">9.6.1. </span>Cross-Validation (CV)<a class="headerlink" href="#cross-validation-cv" title="Link to this heading">#</a></h2>
<p>Cross-Validation is a powerful resampling technique used to assess the performance of predictive models. Particularly valuable when dealing with limited data, it allows you to estimate how well your model will perform on unseen data points, providing a glimpse into its generalization capabilities <span id="id2">[<a class="reference internal" href="../References.html#id98" title="Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani, and Jonathan Taylor. An Introduction to Statistical Learning: with Applications in R. Springer Texts in Statistics. Springer Cham, 2023. ISBN 9783031391897. URL: https://link.springer.com/book/10.1007/978-3-031-38747-0.">James <em>et al.</em>, 2023</a>]</span>.</p>
<p>In the context of k-fold Cross-Validation, a commonly used approach, the dataset is divided into k subsets or “folds.” The steps for performing k-fold Cross-Validation are as follows <span id="id3">[<a class="reference internal" href="../References.html#id98" title="Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani, and Jonathan Taylor. An Introduction to Statistical Learning: with Applications in R. Springer Texts in Statistics. Springer Cham, 2023. ISBN 9783031391897. URL: https://link.springer.com/book/10.1007/978-3-031-38747-0.">James <em>et al.</em>, 2023</a>, <a class="reference internal" href="../References.html#id170" title="Payam Refaeilzadeh, Lei Tang, and Huan Liu. Cross-Validation, pages 532–538. Springer US, Boston, MA, 2009. doi:10.1007/978-0-387-39940-9_565.">Refaeilzadeh <em>et al.</em>, 2009</a>]</span>:</p>
<ol class="arabic simple">
<li><p><strong>Partitioning Data:</strong></p>
<ul class="simple">
<li><p>Divide the dataset into k equally sized subsets, referred to as <span class="math notranslate nohighlight">\(D_1, D_2, \ldots, D_k\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Iterative Training and Testing:</strong></p>
<ul class="simple">
<li><p>For each fold <span class="math notranslate nohighlight">\(D_i\)</span>, treat it as the test set while combining the remaining folds <span class="math notranslate nohighlight">\(D_1 \cup \ldots \cup D_{i-1} \cup D_{i+1} \cup \ldots \cup D_k\)</span> to form the training set.</p></li>
<li><p>Train your model on the training set and evaluate its performance on the test set.</p></li>
<li><p>Repeat this process for each fold, resulting in k iterations.</p></li>
</ul>
</li>
<li><p><strong>Performance Metrics:</strong></p>
<ul class="simple">
<li><p>For each iteration, compute a performance metric (e.g., accuracy, mean squared error) based on your model’s predictions on the test set.</p></li>
</ul>
</li>
<li><p><strong>Overall Performance Estimate:</strong></p>
<ul class="simple">
<li><p>Calculate the average of the performance metrics obtained from the k iterations. This average provides an overall estimate of your model’s performance.</p></li>
</ul>
</li>
</ol>
<p>Mathematically, let’s consider a performance metric denoted as <span class="math notranslate nohighlight">\(P\)</span>, exemplified by accuracy, and a model <span class="math notranslate nohighlight">\(M\)</span> designed to map input features <span class="math notranslate nohighlight">\(X\)</span> to predictions <span class="math notranslate nohighlight">\(\hat{y}\)</span>. In the context of k-fold Cross-Validation, the following steps are undertaken for each fold <span class="math notranslate nohighlight">\(D_i\)</span>:</p>
<ol class="arabic">
<li><p><strong>Training:</strong> The model <span class="math notranslate nohighlight">\(M\)</span> is trained on the training set, excluding the current fold <span class="math notranslate nohighlight">\(D_i\)</span>. This process results in a trained model, represented as <span class="math notranslate nohighlight">\(M_i\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-822d945f-7739-4939-8b98-e0d8d277766d">
<span class="eqno">(9.100)<a class="headerlink" href="#equation-822d945f-7739-4939-8b98-e0d8d277766d" title="Permalink to this equation">#</a></span>\[\begin{equation} M_i = M.fit(X_{\text{train}_i}, y_{\text{train}_i}) \end{equation}\]</div>
<p>where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(M_i\)</span>: This represents the model obtained after training on a specific fold <span class="math notranslate nohighlight">\(D_i\)</span>. It is a distinct instance of the original model <span class="math notranslate nohighlight">\(M\)</span> and is specific to the training set <span class="math notranslate nohighlight">\(X_{\text{train}_i}, y_{\text{train}_i}\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(M\)</span>: The original model that maps input features to predictions.</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{fit}\)</span>: This method is typically used in machine learning libraries to train a model. It adjusts the parameters of the model based on the provided training data.</p></li>
<li><p><span class="math notranslate nohighlight">\(X_{\text{train}_i}\)</span>: The input features of the training set for fold <span class="math notranslate nohighlight">\(D_i\)</span>. It is a subset of the entire dataset, excluding the instances in fold <span class="math notranslate nohighlight">\(D_i\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(y_{\text{train}_i}\)</span>: The corresponding labels of the training set for fold <span class="math notranslate nohighlight">\(D_i\)</span>. Like <span class="math notranslate nohighlight">\(X_{\text{train}_i}\)</span>, it is a subset of the entire set of labels, excluding those in fold <span class="math notranslate nohighlight">\(D_i\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Evaluation:</strong> The trained model <span class="math notranslate nohighlight">\(M_i\)</span> is evaluated on the fold <span class="math notranslate nohighlight">\(D_i\)</span>, which serves as the test set. This evaluation produces a performance metric for the current iteration, denoted as <span class="math notranslate nohighlight">\(P_i\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-af04da76-2862-4adc-a89f-65fd1e590367">
<span class="eqno">(9.101)<a class="headerlink" href="#equation-af04da76-2862-4adc-a89f-65fd1e590367" title="Permalink to this equation">#</a></span>\[\begin{equation} P_i = P(M_i.predict(X_{\text{test}_i}), y_{\text{test}_i}) \end{equation}\]</div>
<p>where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P_i\)</span>: This represents the performance metric (e.g., accuracy, mean squared error) obtained for the current fold <span class="math notranslate nohighlight">\(D_i\)</span>. It is the result of evaluating the model <span class="math notranslate nohighlight">\(M_i\)</span> on the test set.</p></li>
<li><p><span class="math notranslate nohighlight">\(P\)</span>: The performance metric function, which quantifies how well the model’s predictions align with the actual values.</p></li>
<li><p><span class="math notranslate nohighlight">\(M_i\)</span>: The model trained on the specific training set for the current fold <span class="math notranslate nohighlight">\(D_i\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{predict}\)</span>: This method is commonly used in machine learning libraries to generate predictions based on a trained model.</p></li>
<li><p><span class="math notranslate nohighlight">\(X_{\text{test}_i}\)</span>: The input features of the test set for fold <span class="math notranslate nohighlight">\(D_i\)</span>. It represents the instances that were set aside for testing in the current iteration.</p></li>
<li><p><span class="math notranslate nohighlight">\(y_{\text{test}_i}\)</span>: The corresponding actual labels of the test set for fold <span class="math notranslate nohighlight">\(D_i\)</span>. These are the true values against which the model’s predictions are compared.</p></li>
</ul>
</li>
</ol>
<p>These steps are iteratively applied for each fold, resulting in k performance metrics <span class="math notranslate nohighlight">\(P_1, P_2, ..., P_k\)</span>. The average performance estimate <span class="math notranslate nohighlight">\(\bar{P}\)</span> is then computed by taking the mean of these metrics:</p>
<div class="amsmath math notranslate nohighlight" id="equation-fc62a064-59b8-4215-adb8-fde1ae5dbeb8">
<span class="eqno">(9.102)<a class="headerlink" href="#equation-fc62a064-59b8-4215-adb8-fde1ae5dbeb8" title="Permalink to this equation">#</a></span>\[\begin{equation} \bar{P} = \frac{1}{k} \sum_{i=1}^{k} P_i \end{equation}\]</div>
<p>This average provides an aggregated measure of the model’s performance across all folds, offering a comprehensive evaluation of its generalization capabilities. Importantly, Cross-Validation transcends the limitations of training error, delivering a robust performance estimate crucial for informed model assessment and selection in predictive modeling contexts <span id="id4">[<a class="reference internal" href="../References.html#id98" title="Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani, and Jonathan Taylor. An Introduction to Statistical Learning: with Applications in R. Springer Texts in Statistics. Springer Cham, 2023. ISBN 9783031391897. URL: https://link.springer.com/book/10.1007/978-3-031-38747-0.">James <em>et al.</em>, 2023</a>, <a class="reference internal" href="../References.html#id170" title="Payam Refaeilzadeh, Lei Tang, and Huan Liu. Cross-Validation, pages 532–538. Springer US, Boston, MA, 2009. doi:10.1007/978-0-387-39940-9_565.">Refaeilzadeh <em>et al.</em>, 2009</a>]</span>.</p>
<p><font color='Blue'><b>Example</b></font>: Consider a dataset <span class="math notranslate nohighlight">\(S\)</span> containing 6 samples, denoted as {<span class="math notranslate nohighlight">\(x_1\)</span>, <span class="math notranslate nohighlight">\(x_2\)</span>, <span class="math notranslate nohighlight">\(x_3\)</span>, <span class="math notranslate nohighlight">\(x_4\)</span>, <span class="math notranslate nohighlight">\(x_5\)</span>, <span class="math notranslate nohighlight">\(x_6\)</span>}, and the objective is to perform a 3-fold cross-validation.</p>
<p>To begin, the dataset <span class="math notranslate nohighlight">\(S\)</span> is divided into 3 subsets in a randomized manner, resulting in:</p>
<ul class="simple">
<li><p>Subset 1: <span class="math notranslate nohighlight">\(S_1 = \{x_1, x_2\}\)</span></p></li>
<li><p>Subset 2: <span class="math notranslate nohighlight">\(S_2 = \{x_3, x_4\}\)</span></p></li>
<li><p>Subset 3: <span class="math notranslate nohighlight">\(S_3 = \{x_5, x_6\}\)</span></p></li>
</ul>
<p>In the subsequent steps, the machine-learning model is trained and evaluated 3 times. During each iteration, two of the subsets are combined to form the training set, while the remaining subset serves as the test set. The process unfolds as follows:</p>
<p><strong>Iteration 1:</strong></p>
<ul class="simple">
<li><p><font color='Green'><b>Training Set:</b></font> <span class="math notranslate nohighlight">\(S_1 = \{x_1, x_2\}\)</span>, <span class="math notranslate nohighlight">\(S_2 = \{x_3, x_4\}\)</span></p></li>
<li><p><font color='Blue'><b>Test Set:</b></font> <span class="math notranslate nohighlight">\(S_3 = \{x_5, x_6\}\)</span></p></li>
</ul>
<p><strong>Iteration 2:</strong></p>
<ul class="simple">
<li><p><font color='Green'><b>Training Set:</b></font> <span class="math notranslate nohighlight">\(S_2 = \{x_3, x_4\}\)</span>, <span class="math notranslate nohighlight">\(S_3 = \{x_5, x_6\}\)</span></p></li>
<li><p><font color='Blue'><b>Test Set:</b></font> <span class="math notranslate nohighlight">\(S_1 = \{x_1, x_2\}\)</span></p></li>
</ul>
<p><strong>Iteration 3:</strong></p>
<ul class="simple">
<li><p><font color='Green'><b>Training Set:</b></font> <span class="math notranslate nohighlight">\(S_1 = \{x_1, x_2\}\)</span>, <span class="math notranslate nohighlight">\(S_3 = \{x_5, x_6\}\)</span></p></li>
<li><p><font color='Blue'><b>Test Set:</b></font> <span class="math notranslate nohighlight">\(S_2 = \{x_3, x_4\}\)</span></p></li>
</ul>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/CV.png"><img alt="../_images/CV.png" src="../_images/CV.png" style="width: 450px;" /></a>
</figure>
<p>We also can do this in python:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="c1"># Define the dataset as a one-dimensional array</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">,</span> <span class="s1">&#39;x3&#39;</span><span class="p">,</span> <span class="s1">&#39;x4&#39;</span><span class="p">,</span> <span class="s1">&#39;x5&#39;</span><span class="p">,</span> <span class="s1">&#39;x6&#39;</span><span class="p">])</span>

<span class="c1"># Reshape the dataset into a two-dimensional array with one column</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Create the KFold object with 3 splits</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">print_bold</span><span class="p">(</span><span class="n">txt</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[1;31m&quot;</span> <span class="o">+</span> <span class="n">txt</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[0m&quot;</span><span class="p">)</span>

<span class="c1"># Loop over the train and test indices returned by the KFold object</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Print the train and test sets</span>
    <span class="n">print_bold</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t\033</span><span class="s2">[1;42mTrain set</span><span class="se">\033</span><span class="s2">[0m:{&quot;</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()),</span> <span class="s1">&#39;}&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t\033</span><span class="s2">[1;44mTest set</span><span class="se">\033</span><span class="s2">[0m:{&quot;</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()),</span> <span class="s1">&#39;}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Fold 1:</span>
	<span class=" -Color -Color-Bold -Color-Bold-BGGreen">Train set</span>:{ x3, x4, x5, x6 }
	<span class=" -Color -Color-Bold -Color-Bold-BGBlue">Test set</span>:{ x1, x2 }

<span class=" -Color -Color-Bold -Color-Bold-Red">Fold 2:</span>
	<span class=" -Color -Color-Bold -Color-Bold-BGGreen">Train set</span>:{ x1, x2, x5, x6 }
	<span class=" -Color -Color-Bold -Color-Bold-BGBlue">Test set</span>:{ x3, x4 }

<span class=" -Color -Color-Bold -Color-Bold-Red">Fold 3:</span>
	<span class=" -Color -Color-Bold -Color-Bold-BGGreen">Train set</span>:{ x1, x2, x3, x4 }
	<span class=" -Color -Color-Bold -Color-Bold-BGBlue">Test set</span>:{ x5, x6 }
</pre></div>
</div>
</div>
</div>
<p><font color='Blue'><b>Example</b></font>: Returning to the Iris dataset, we employ a cross-validation strategy with a 5-fold partitioning scheme. In this approach, the dataset is divided into five subsets of roughly equal size, and the model is trained and evaluated five times. Each time, a different subset is held out as the test set, while the remaining four subsets are combined to form the training set. This process ensures that every data point is used for both training and testing, leading to a more robust evaluation of the model’s performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>

<span class="c1"># Load the Iris dataset</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>

<span class="c1"># Create a KNN Classifier</span>
<span class="n">KKN</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># Using 3 nearest neighbors</span>

<span class="k">def</span> <span class="nf">print_bold</span><span class="p">(</span><span class="n">txt</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[1;35m&quot;</span> <span class="o">+</span> <span class="n">txt</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[0m&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_Line</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">80</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="s1">&#39;_&#39;</span><span class="p">)</span>
    
<span class="c1"># Initialize KFold cross-validator</span>
<span class="n">n_splits</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Lists to store train and test scores for each fold</span>
<span class="n">train_acc_scores</span><span class="p">,</span> <span class="n">test_acc_scores</span><span class="p">,</span> <span class="n">train_f1_scores</span><span class="p">,</span> <span class="n">test_f1_scores</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>


<span class="c1"># Perform Cross-Validation</span>
<span class="k">for</span> <span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
    <span class="n">KKN</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="c1"># train</span>
    <span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">KKN</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">train_acc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">))</span>
    <span class="n">train_f1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">,</span> <span class="n">average</span> <span class="o">=</span> <span class="s1">&#39;weighted&#39;</span><span class="p">))</span>
    <span class="c1"># test</span>
    <span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">KKN</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">test_acc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">))</span>
    <span class="n">test_f1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">,</span> <span class="n">average</span> <span class="o">=</span> <span class="s1">&#39;weighted&#39;</span><span class="p">))</span>

<span class="n">_Line</span><span class="p">()</span>
<span class="c1">#  Print the Train and Test Scores for each fold</span>
<span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_splits</span><span class="p">):</span>
    <span class="n">print_bold</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Fold </span><span class="si">{</span><span class="n">fold</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Train Accuracy Score = </span><span class="si">{</span><span class="n">train_acc_scores</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Test Accuracy Score = </span><span class="si">{</span><span class="n">test_acc_scores</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Train F1 Score (weighted) = </span><span class="si">{</span><span class="n">train_f1_scores</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Test F1 Score (weighted)= </span><span class="si">{</span><span class="n">test_f1_scores</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">_Line</span><span class="p">()</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Accuracy Score:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Mean Train Accuracy Score: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_acc_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_acc_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Mean Test Accuracy Score: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_acc_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_acc_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;F1 Score:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Mean F1 Accuracy Score (weighted): </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_f1_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_f1_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Mean F1 Accuracy Score (weighted): </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_f1_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_f1_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">_Line</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>________________________________________________________________________________
<span class=" -Color -Color-Bold -Color-Bold-Magenta">Fold 1:</span>
	Train Accuracy Score = 0.9500, Test Accuracy Score = 1.0000
	Train F1 Score (weighted) = 0.9500, Test F1 Score (weighted)= 1.0000
<span class=" -Color -Color-Bold -Color-Bold-Magenta">Fold 2:</span>
	Train Accuracy Score = 0.9667, Test Accuracy Score = 0.9667
	Train F1 Score (weighted) = 0.9667, Test F1 Score (weighted)= 0.9662
<span class=" -Color -Color-Bold -Color-Bold-Magenta">Fold 3:</span>
	Train Accuracy Score = 0.9583, Test Accuracy Score = 0.9667
	Train F1 Score (weighted) = 0.9583, Test F1 Score (weighted)= 0.9668
<span class=" -Color -Color-Bold -Color-Bold-Magenta">Fold 4:</span>
	Train Accuracy Score = 0.9833, Test Accuracy Score = 0.9333
	Train F1 Score (weighted) = 0.9833, Test F1 Score (weighted)= 0.9322
<span class=" -Color -Color-Bold -Color-Bold-Magenta">Fold 5:</span>
	Train Accuracy Score = 0.9583, Test Accuracy Score = 0.9667
	Train F1 Score (weighted) = 0.9583, Test F1 Score (weighted)= 0.9667
________________________________________________________________________________
<span class=" -Color -Color-Bold -Color-Bold-Magenta">Accuracy Score:</span>
	Mean Train Accuracy Score: 0.9633 ± 0.0113
	Mean Test Accuracy Score: 0.9667 ± 0.0211
<span class=" -Color -Color-Bold -Color-Bold-Magenta">F1 Score:</span>
	Mean F1 Accuracy Score (weighted): 0.9633 ± 0.0113
	Mean F1 Accuracy Score (weighted): 0.9664 ± 0.0214
________________________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="warning admonition">
<p class="admonition-title">Note</p>
<ol class="arabic">
<li><p><code class="docutils literal notranslate"><span class="pre">metrics.accuracy_score</span></code> is a function commonly used in the context of classification tasks within the field of machine learning. It is part of the scikit-learn library in Python. This function is utilized to quantify the accuracy of a classification model by comparing the predicted labels against the true labels of a dataset.</p>
<p>The accuracy score is calculated by dividing the number of correctly classified instances by the total number of instances. Mathematically, it can be expressed as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-57961326-1e1a-48cf-be85-7e0677f1725e">
<span class="eqno">(9.103)<a class="headerlink" href="#equation-57961326-1e1a-48cf-be85-7e0677f1725e" title="Permalink to this equation">#</a></span>\[\begin{equation} \text{Accuracy} = \frac{\text{Number of Correctly Classified Instances}}{\text{Total Number of Instances}} \end{equation}\]</div>
<p>In Python, using the <code class="docutils literal notranslate"><span class="pre">metrics.accuracy_score</span></code> function involves providing the true labels and the predicted labels as arguments. The function then returns a numerical value representing the accuracy of the classification model.</p>
<p>It is important to note that while accuracy is a straightforward metric, it may not be sufficient in scenarios with imbalanced class distributions. In such cases, additional metrics like precision, recall, and F1-score might be more informative for evaluating the performance of a classification model <span id="id5">[<a class="reference internal" href="../References.html#id53" title="scikit-learn Developers. Scikit-learn user guide. https://scikit-learn.org/stable/user_guide.html, 2023. [Online; accessed 01-August-2023].">scikit-learn Developers, 2023</a>]</span>.</p>
</li>
<li><p>The F1 Score, specifically in its weighted form, is a metric commonly employed in the evaluation of classification models. It provides a balance between precision and recall, offering a single numerical value that summarizes the model’s performance across multiple classes in a weighted manner.</p>
<p>The weighted F1 Score is calculated by considering both precision (<span class="math notranslate nohighlight">\(P\)</span>) and recall (<span class="math notranslate nohighlight">\(R\)</span>) for each class and then computing the harmonic mean of these values. The weighted aspect accounts for the imbalance in class sizes. Mathematically, it is defined as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-28e608c4-9144-4dd0-8045-02cbd7f8d9bd">
<span class="eqno">(9.104)<a class="headerlink" href="#equation-28e608c4-9144-4dd0-8045-02cbd7f8d9bd" title="Permalink to this equation">#</a></span>\[\begin{equation} F1_{\text{weighted}} = \frac{\sum_{i=1}^{C} w_i \cdot F1_i}{\sum_{i=1}^{C} w_i} \end{equation}\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( C \)</span> is the number of classes.</p></li>
<li><p><span class="math notranslate nohighlight">\( F1_i \)</span> is the F1 Score for class <span class="math notranslate nohighlight">\( i \)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\( w_i \)</span> is the weight assigned to class <span class="math notranslate nohighlight">\( i \)</span>, typically proportional to the number of instances in that class.</p></li>
</ul>
<p>In Python, scikit-learn’s <code class="docutils literal notranslate"><span class="pre">metrics.f1_score</span></code> function can be utilized to compute the F1 Score. When employing the ‘weighted’ parameter, it calculates the average F1 Score, considering the number of instances in each class as weights.</p>
<p>This weighted F1 Score is particularly useful when dealing with imbalanced datasets, where certain classes may have significantly fewer instances than others. It provides a more nuanced evaluation of the model’s ability to perform well across all classes, accounting for the influence of class size on the overall metric <span id="id6">[<a class="reference internal" href="../References.html#id53" title="scikit-learn Developers. Scikit-learn user guide. https://scikit-learn.org/stable/user_guide.html, 2023. [Online; accessed 01-August-2023].">scikit-learn Developers, 2023</a>]</span>.</p>
<p><font color='Blue'><b>Example:</b></font> Let’s consider a scenario where we have a classification model dealing with a dataset that includes three classes: A, B, and C. The dataset is imbalanced, meaning that the number of instances in each class is different. We want to compute the weighted F1 Score for this model.</p>
<p>Here’s a hypothetical example with class counts and F1 Scores for each class:</p>
<ul class="simple">
<li><p>Class A: True Positives (TP) = 150, False Positives (FP) = 20, False Negatives (FN) = 10</p></li>
<li><p>Class B: TP = 80, FP = 5, FN = 30</p></li>
<li><p>Class C: TP = 40, FP = 10, FN = 5</p></li>
</ul>
<p>Class weights (<span class="math notranslate nohighlight">\(w_i\)</span>) can be determined based on the number of instances in each class. For simplicity, let’s assume the weights are proportional to the number of instances in each class:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(w_{\text{A}} = 300\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(w_{\text{B}} = 115\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(w_{\text{C}} = 55\)</span></p></li>
</ul>
<p>Now, we can compute the F1 Score for each class using the formula:</p>
<div class="amsmath math notranslate nohighlight" id="equation-84ebf6ea-6e30-4d5f-bab9-2a61718493fd">
<span class="eqno">(9.105)<a class="headerlink" href="#equation-84ebf6ea-6e30-4d5f-bab9-2a61718493fd" title="Permalink to this equation">#</a></span>\[\begin{equation} F1_i = \frac{2 \cdot \text{TP}_i}{2 \cdot \text{TP}_i + \text{FP}_i + \text{FN}_i} \end{equation}\]</div>
<p>After calculating <span class="math notranslate nohighlight">\(F1_i\)</span> for each class, we can then compute the weighted F1 Score using the formula mentioned earlier:</p>
<div class="amsmath math notranslate nohighlight" id="equation-23428815-2aba-4974-9413-f766b5766e05">
<span class="eqno">(9.106)<a class="headerlink" href="#equation-23428815-2aba-4974-9413-f766b5766e05" title="Permalink to this equation">#</a></span>\[\begin{equation} F1_{\text{weighted}} = \frac{w_{\text{A}} \cdot F1_{\text{A}} + w_{\text{B}} \cdot F1_{\text{B}} + w_{\text{C}} \cdot F1_{\text{C}}}{w_{\text{A}} + w_{\text{B}} + w_{\text{C}}} \end{equation}\]</div>
<p>This weighted F1 Score provides a comprehensive evaluation of the model’s performance, giving more importance to classes with a larger number of instances.</p>
</li>
</ol>
</div>
<p>On the other hand, observe that,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Create a Pandas DataFrame</span>
<span class="n">iris_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">iris_df</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>

<span class="c1"># Use groupby to count observations by species</span>
<span class="n">species_counts</span> <span class="o">=</span> <span class="n">iris_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;species&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="o">.</span><span class="n">to_frame</span><span class="p">(</span><span class="s1">&#39;Count&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of Observations by Species:&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">species_counts</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of Observations by Species:
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>species</th>
      <th>setosa</th>
      <th>versicolor</th>
      <th>virginica</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Count</th>
      <td>50</td>
      <td>50</td>
      <td>50</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now, let’s invistigate the previous splitss</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">print_bold</span><span class="p">(</span><span class="n">txt</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[1;34m&quot;</span> <span class="o">+</span> <span class="n">txt</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[0m&quot;</span><span class="p">)</span>
    
<span class="c1"># Perform Cross-Validation</span>
<span class="k">for</span> <span class="n">C</span><span class="p">,</span> <span class="p">(</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
    <span class="n">print_bold</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Fold </span><span class="si">{</span><span class="n">C</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">:&#39;</span><span class="p">)</span>

    <span class="c1"># Extract target names for train and test sets</span>
    <span class="n">train_targets</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">][</span><span class="n">train_idx</span><span class="p">]</span>
    <span class="n">test_targets</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">][</span><span class="n">test_idx</span><span class="p">]</span>

    <span class="c1"># Create DataFrames for train and test sets</span>
    <span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">train_targets</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">to_frame</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">df_train</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Set&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Train&#39;</span><span class="p">])</span>

    <span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">test_targets</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">to_frame</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">df_test</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Set&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Test&#39;</span><span class="p">])</span>

    <span class="c1"># Concatenate DataFrames</span>
    <span class="n">df_concat</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span><span class="p">])</span>

    <span class="c1"># Define styles for the data rows</span>
    <span class="n">styles</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;selector&#39;</span><span class="p">:</span> <span class="s1">&#39;tbody tr:nth-child(1)&#39;</span><span class="p">,</span> <span class="s1">&#39;props&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="s1">&#39;background-color&#39;</span><span class="p">,</span> <span class="s1">&#39;#f0fff0&#39;</span><span class="p">)]},</span>
              <span class="p">{</span><span class="s1">&#39;selector&#39;</span><span class="p">:</span> <span class="s1">&#39;tbody tr:nth-child(2)&#39;</span><span class="p">,</span> <span class="s1">&#39;props&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="s1">&#39;background-color&#39;</span><span class="p">,</span> <span class="s1">&#39;#cfe2f3&#39;</span><span class="p">)]}]</span>

    <span class="c1"># Apply styles to the DataFrame and display it</span>
    <span class="n">display</span><span class="p">(</span><span class="n">df_concat</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">set_table_styles</span><span class="p">(</span><span class="n">styles</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Blue">Fold 1:</span>
</pre></div>
</div>
<div class="output text_html"><style type="text/css">
#T_7a18b tbody tr:nth-child(1) {
  background-color: #f0fff0;
}
#T_7a18b tbody tr:nth-child(2) {
  background-color: #cfe2f3;
}
</style>
<table id="T_7a18b">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_7a18b_level0_col0" class="col_heading level0 col0" >Set</th>
      <th id="T_7a18b_level0_col1" class="col_heading level0 col1" >versicolor</th>
      <th id="T_7a18b_level0_col2" class="col_heading level0 col2" >setosa</th>
      <th id="T_7a18b_level0_col3" class="col_heading level0 col3" >virginica</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_7a18b_level0_row0" class="row_heading level0 row0" ></th>
      <td id="T_7a18b_row0_col0" class="data row0 col0" >Train</td>
      <td id="T_7a18b_row0_col1" class="data row0 col1" >41</td>
      <td id="T_7a18b_row0_col2" class="data row0 col2" >40</td>
      <td id="T_7a18b_row0_col3" class="data row0 col3" >39</td>
    </tr>
    <tr>
      <th id="T_7a18b_level0_row1" class="row_heading level0 row1" ></th>
      <td id="T_7a18b_row1_col0" class="data row1 col0" >Test</td>
      <td id="T_7a18b_row1_col1" class="data row1 col1" >9</td>
      <td id="T_7a18b_row1_col2" class="data row1 col2" >10</td>
      <td id="T_7a18b_row1_col3" class="data row1 col3" >11</td>
    </tr>
  </tbody>
</table>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Blue">Fold 2:</span>
</pre></div>
</div>
<div class="output text_html"><style type="text/css">
#T_7803f tbody tr:nth-child(1) {
  background-color: #f0fff0;
}
#T_7803f tbody tr:nth-child(2) {
  background-color: #cfe2f3;
}
</style>
<table id="T_7803f">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_7803f_level0_col0" class="col_heading level0 col0" >Set</th>
      <th id="T_7803f_level0_col1" class="col_heading level0 col1" >virginica</th>
      <th id="T_7803f_level0_col2" class="col_heading level0 col2" >versicolor</th>
      <th id="T_7803f_level0_col3" class="col_heading level0 col3" >setosa</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_7803f_level0_row0" class="row_heading level0 row0" ></th>
      <td id="T_7803f_row0_col0" class="data row0 col0" >Train</td>
      <td id="T_7803f_row0_col1" class="data row0 col1" >43</td>
      <td id="T_7803f_row0_col2" class="data row0 col2" >40</td>
      <td id="T_7803f_row0_col3" class="data row0 col3" >37</td>
    </tr>
    <tr>
      <th id="T_7803f_level0_row1" class="row_heading level0 row1" ></th>
      <td id="T_7803f_row1_col0" class="data row1 col0" >Test</td>
      <td id="T_7803f_row1_col1" class="data row1 col1" >7</td>
      <td id="T_7803f_row1_col2" class="data row1 col2" >10</td>
      <td id="T_7803f_row1_col3" class="data row1 col3" >13</td>
    </tr>
  </tbody>
</table>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Blue">Fold 3:</span>
</pre></div>
</div>
<div class="output text_html"><style type="text/css">
#T_1964b tbody tr:nth-child(1) {
  background-color: #f0fff0;
}
#T_1964b tbody tr:nth-child(2) {
  background-color: #cfe2f3;
}
</style>
<table id="T_1964b">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_1964b_level0_col0" class="col_heading level0 col0" >Set</th>
      <th id="T_1964b_level0_col1" class="col_heading level0 col1" >virginica</th>
      <th id="T_1964b_level0_col2" class="col_heading level0 col2" >versicolor</th>
      <th id="T_1964b_level0_col3" class="col_heading level0 col3" >setosa</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_1964b_level0_row0" class="row_heading level0 row0" ></th>
      <td id="T_1964b_row0_col0" class="data row0 col0" >Train</td>
      <td id="T_1964b_row0_col1" class="data row0 col1" >42</td>
      <td id="T_1964b_row0_col2" class="data row0 col2" >40</td>
      <td id="T_1964b_row0_col3" class="data row0 col3" >38</td>
    </tr>
    <tr>
      <th id="T_1964b_level0_row1" class="row_heading level0 row1" ></th>
      <td id="T_1964b_row1_col0" class="data row1 col0" >Test</td>
      <td id="T_1964b_row1_col1" class="data row1 col1" >8</td>
      <td id="T_1964b_row1_col2" class="data row1 col2" >10</td>
      <td id="T_1964b_row1_col3" class="data row1 col3" >12</td>
    </tr>
  </tbody>
</table>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Blue">Fold 4:</span>
</pre></div>
</div>
<div class="output text_html"><style type="text/css">
#T_a18ff tbody tr:nth-child(1) {
  background-color: #f0fff0;
}
#T_a18ff tbody tr:nth-child(2) {
  background-color: #cfe2f3;
}
</style>
<table id="T_a18ff">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_a18ff_level0_col0" class="col_heading level0 col0" >Set</th>
      <th id="T_a18ff_level0_col1" class="col_heading level0 col1" >setosa</th>
      <th id="T_a18ff_level0_col2" class="col_heading level0 col2" >versicolor</th>
      <th id="T_a18ff_level0_col3" class="col_heading level0 col3" >virginica</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_a18ff_level0_row0" class="row_heading level0 row0" ></th>
      <td id="T_a18ff_row0_col0" class="data row0 col0" >Train</td>
      <td id="T_a18ff_row0_col1" class="data row0 col1" >42</td>
      <td id="T_a18ff_row0_col2" class="data row0 col2" >40</td>
      <td id="T_a18ff_row0_col3" class="data row0 col3" >38</td>
    </tr>
    <tr>
      <th id="T_a18ff_level0_row1" class="row_heading level0 row1" ></th>
      <td id="T_a18ff_row1_col0" class="data row1 col0" >Test</td>
      <td id="T_a18ff_row1_col1" class="data row1 col1" >8</td>
      <td id="T_a18ff_row1_col2" class="data row1 col2" >10</td>
      <td id="T_a18ff_row1_col3" class="data row1 col3" >12</td>
    </tr>
  </tbody>
</table>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Blue">Fold 5:</span>
</pre></div>
</div>
<div class="output text_html"><style type="text/css">
#T_bf0b7 tbody tr:nth-child(1) {
  background-color: #f0fff0;
}
#T_bf0b7 tbody tr:nth-child(2) {
  background-color: #cfe2f3;
}
</style>
<table id="T_bf0b7">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_bf0b7_level0_col0" class="col_heading level0 col0" >Set</th>
      <th id="T_bf0b7_level0_col1" class="col_heading level0 col1" >setosa</th>
      <th id="T_bf0b7_level0_col2" class="col_heading level0 col2" >versicolor</th>
      <th id="T_bf0b7_level0_col3" class="col_heading level0 col3" >virginica</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_bf0b7_level0_row0" class="row_heading level0 row0" ></th>
      <td id="T_bf0b7_row0_col0" class="data row0 col0" >Train</td>
      <td id="T_bf0b7_row0_col1" class="data row0 col1" >43</td>
      <td id="T_bf0b7_row0_col2" class="data row0 col2" >39</td>
      <td id="T_bf0b7_row0_col3" class="data row0 col3" >38</td>
    </tr>
    <tr>
      <th id="T_bf0b7_level0_row1" class="row_heading level0 row1" ></th>
      <td id="T_bf0b7_row1_col0" class="data row1 col0" >Test</td>
      <td id="T_bf0b7_row1_col1" class="data row1 col1" >7</td>
      <td id="T_bf0b7_row1_col2" class="data row1 col2" >11</td>
      <td id="T_bf0b7_row1_col3" class="data row1 col3" >12</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="warning admonition">
<p class="admonition-title">Remark</p>
<p>StratifiedKFold is an important cross-validation technique, especially when dealing with imbalanced datasets or classification problems where the distribution of classes is not uniform. It helps ensure that each fold maintains a similar class distribution as the original dataset, providing a more representative sampling and reducing potential bias in model evaluation <span id="id7">[<a class="reference internal" href="../References.html#id160" title="F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: machine learning in Python. Journal of Machine Learning Research, 12:2825–2830, 2011.">Pedregosa <em>et al.</em>, 2011</a>, <a class="reference internal" href="../References.html#id53" title="scikit-learn Developers. Scikit-learn user guide. https://scikit-learn.org/stable/user_guide.html, 2023. [Online; accessed 01-August-2023].">scikit-learn Developers, 2023</a>]</span>.</p>
<p>Here’s why StratifiedKFold is important:</p>
<ol class="arabic simple">
<li><p><strong>Imbalanced Datasets</strong>: In classification tasks, imbalanced datasets have significantly different proportions of different classes. If you use a simple random sampling method for cross-validation, there’s a risk that some folds may not contain instances of rare classes, leading to poor performance evaluation. StratifiedKFold addresses this by ensuring that each fold retains the same class distribution as the original dataset.</p></li>
<li><p><strong>Better Generalization</strong>: When you split a dataset into train and test sets, you want both sets to be representative of the overall dataset. If the class distribution in the test set is significantly different from the training set, the model’s performance on the test set might not accurately reflect its real-world performance.</p></li>
<li><p><strong>Reduced Variability</strong>: Using a stratified approach reduces the variance in evaluation metrics, as each fold closely resembles the overall class distribution. This makes the evaluation more stable and reliable.</p></li>
<li><p><strong>Preserving Relationships</strong>: If there are any relationships between features and classes, stratified sampling helps ensure that these relationships are maintained in each fold, allowing the model to learn from consistent patterns.</p></li>
<li><p><strong>Comparative Analysis</strong>: When comparing different models or algorithms, using the same cross-validation technique across all evaluations helps ensure fair comparisons.</p></li>
</ol>
<p>StratifiedKFold is essential for obtaining reliable and unbiased performance estimates, especially in scenarios where class imbalances exist. It’s a valuable tool to prevent the evaluation process from being skewed by the data’s inherent class distribution.</p>
</div>
<p>When working with a small dataset like the Iris dataset, which has only 150 samples, the choice of cross-validation strategy becomes even more crucial. Using StratifiedKFold for splitting a small dataset into train and test sets offers several benefits:</p>
<ol class="arabic simple">
<li><p><strong>Preserving Data Distribution</strong>: The Iris dataset contains three classes (species) with 50 samples each. If you use simple random splitting without stratification, there’s a chance that one or more classes might be underrepresented or absent in either the train or test set. StratifiedKFold ensures that each fold maintains the original class distribution, which is particularly important when working with a limited number of samples.</p></li>
<li><p><strong>More Reliable Performance Estimates</strong>: In small datasets, individual data points can have a larger impact on model training and evaluation. By using stratification, you’re making sure that each fold accurately represents the underlying data distribution. This leads to more reliable performance estimates and reduces the risk of overfitting or underestimation.</p></li>
<li><p><strong>Preventing Overfitting</strong>: Small datasets are prone to overfitting, especially if you’re using a complex model. Using stratified cross-validation helps in mitigating this risk by providing consistent evaluation across folds and ensuring that each fold has a representative distribution of classes.</p></li>
<li><p><strong>Robustness to Variability</strong>: Small datasets often have more variability in terms of data distribution and noise. StratifiedKFold provides a way to handle this variability by maintaining class balance, leading to a more stable evaluation process.</p></li>
<li><p><strong>Comparable Results</strong>: StratifiedKFold ensures that performance metrics are calculated over similar data distributions for each fold. This makes your results more comparable and interpretable.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Iris dataset</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>

<span class="c1"># Create a KNN Classifier</span>
<span class="n">KKN</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># Using 3 nearest neighbors</span>

<span class="k">def</span> <span class="nf">print_bold</span><span class="p">(</span><span class="n">txt</span><span class="p">):</span>
    <span class="n">_left</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[1;43m&quot;</span>
    <span class="n">_right</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[0m&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">_left</span> <span class="o">+</span> <span class="n">txt</span> <span class="o">+</span> <span class="n">_right</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_Line</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">80</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="s1">&#39;_&#39;</span><span class="p">)</span>
    
<span class="c1"># Initialize StratifiedKFold cross-validator</span>
<span class="n">n_splits</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Lists to store train and test scores for each fold</span>
<span class="n">train_acc_scores</span><span class="p">,</span> <span class="n">test_acc_scores</span><span class="p">,</span> <span class="n">train_f1_scores</span><span class="p">,</span> <span class="n">test_f1_scores</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>


<span class="c1"># Perform Cross-Validation</span>
<span class="k">for</span> <span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="ow">in</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
    <span class="n">KKN</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="c1"># train</span>
    <span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">KKN</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">train_acc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">))</span>
    <span class="n">train_f1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">,</span> <span class="n">average</span> <span class="o">=</span> <span class="s1">&#39;weighted&#39;</span><span class="p">))</span>
    <span class="c1"># test</span>
    <span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">KKN</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">test_acc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">))</span>
    <span class="n">test_f1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">,</span> <span class="n">average</span> <span class="o">=</span> <span class="s1">&#39;weighted&#39;</span><span class="p">))</span>

<span class="n">_Line</span><span class="p">()</span>
<span class="c1">#  Print the Train and Test Scores for each fold</span>
<span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_splits</span><span class="p">):</span>
    <span class="n">print_bold</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Fold </span><span class="si">{</span><span class="n">fold</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Train Accuracy Score = </span><span class="si">{</span><span class="n">train_acc_scores</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Test Accuracy Score = </span><span class="si">{</span><span class="n">test_acc_scores</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Train F1 Score (weighted) = </span><span class="si">{</span><span class="n">train_f1_scores</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Test F1 Score (weighted)= </span><span class="si">{</span><span class="n">test_f1_scores</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">_Line</span><span class="p">()</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Accuracy Score:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Mean Train Accuracy Score: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_acc_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_acc_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Mean Test Accuracy Score: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_acc_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_acc_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;F1 Score:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Mean F1 Accuracy Score (weighted): </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_f1_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_f1_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Mean F1 Accuracy Score (weighted): </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_f1_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_f1_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">_Line</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>________________________________________________________________________________
<span class=" -Color -Color-Bold -Color-Bold-BGYellow">Fold 1:</span>
	Train Accuracy Score = 0.9500, Test Accuracy Score = 1.0000
	Train F1 Score (weighted) = 0.9500, Test F1 Score (weighted)= 1.0000
<span class=" -Color -Color-Bold -Color-Bold-BGYellow">Fold 2:</span>
	Train Accuracy Score = 0.9583, Test Accuracy Score = 0.9667
	Train F1 Score (weighted) = 0.9583, Test F1 Score (weighted)= 0.9666
<span class=" -Color -Color-Bold -Color-Bold-BGYellow">Fold 3:</span>
	Train Accuracy Score = 0.9917, Test Accuracy Score = 0.8667
	Train F1 Score (weighted) = 0.9917, Test F1 Score (weighted)= 0.8653
<span class=" -Color -Color-Bold -Color-Bold-BGYellow">Fold 4:</span>
	Train Accuracy Score = 0.9500, Test Accuracy Score = 1.0000
	Train F1 Score (weighted) = 0.9500, Test F1 Score (weighted)= 1.0000
<span class=" -Color -Color-Bold -Color-Bold-BGYellow">Fold 5:</span>
	Train Accuracy Score = 0.9583, Test Accuracy Score = 0.9333
	Train F1 Score (weighted) = 0.9583, Test F1 Score (weighted)= 0.9333
________________________________________________________________________________
<span class=" -Color -Color-Bold -Color-Bold-BGYellow">Accuracy Score:</span>
	Mean Train Accuracy Score: 0.9617 ± 0.0155
	Mean Test Accuracy Score: 0.9533 ± 0.0499
<span class=" -Color -Color-Bold -Color-Bold-BGYellow">F1 Score:</span>
	Mean F1 Accuracy Score (weighted): 0.9617 ± 0.0155
	Mean F1 Accuracy Score (weighted): 0.9530 ± 0.0504
________________________________________________________________________________
</pre></div>
</div>
</div>
</div>
<p>Observe that now:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">print_bold</span><span class="p">(</span><span class="n">txt</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[1;31m&quot;</span> <span class="o">+</span> <span class="n">txt</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[0m&quot;</span><span class="p">)</span>
    
<span class="c1"># Perform Cross-Validation</span>
<span class="k">for</span> <span class="n">C</span><span class="p">,</span> <span class="p">(</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)):</span>
    <span class="n">print_bold</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Fold </span><span class="si">{</span><span class="n">C</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">:&#39;</span><span class="p">)</span>

    <span class="c1"># Extract target names for train and test sets</span>
    <span class="n">train_targets</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">][</span><span class="n">train_idx</span><span class="p">]</span>
    <span class="n">test_targets</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">][</span><span class="n">test_idx</span><span class="p">]</span>

    <span class="c1"># Create DataFrames for train and test sets</span>
    <span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">train_targets</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">to_frame</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">df_train</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Set&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Train&#39;</span><span class="p">])</span>

    <span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">test_targets</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">to_frame</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">df_test</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Set&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Test&#39;</span><span class="p">])</span>

    <span class="c1"># Concatenate DataFrames</span>
    <span class="n">df_concat</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span><span class="p">])</span>

    <span class="c1"># Define styles for the data rows</span>
    <span class="n">styles</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;selector&#39;</span><span class="p">:</span> <span class="s1">&#39;tbody tr:nth-child(1)&#39;</span><span class="p">,</span> <span class="s1">&#39;props&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="s1">&#39;background-color&#39;</span><span class="p">,</span> <span class="s1">&#39;#f0fff0&#39;</span><span class="p">)]},</span>
              <span class="p">{</span><span class="s1">&#39;selector&#39;</span><span class="p">:</span> <span class="s1">&#39;tbody tr:nth-child(2)&#39;</span><span class="p">,</span> <span class="s1">&#39;props&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="s1">&#39;background-color&#39;</span><span class="p">,</span> <span class="s1">&#39;#cfe2f3&#39;</span><span class="p">)]}]</span>

    <span class="c1"># Apply styles to the DataFrame and display it</span>
    <span class="n">display</span><span class="p">(</span><span class="n">df_concat</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">set_table_styles</span><span class="p">(</span><span class="n">styles</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Fold 1:</span>
</pre></div>
</div>
<div class="output text_html"><style type="text/css">
#T_033c0 tbody tr:nth-child(1) {
  background-color: #f0fff0;
}
#T_033c0 tbody tr:nth-child(2) {
  background-color: #cfe2f3;
}
</style>
<table id="T_033c0">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_033c0_level0_col0" class="col_heading level0 col0" >Set</th>
      <th id="T_033c0_level0_col1" class="col_heading level0 col1" >setosa</th>
      <th id="T_033c0_level0_col2" class="col_heading level0 col2" >versicolor</th>
      <th id="T_033c0_level0_col3" class="col_heading level0 col3" >virginica</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_033c0_level0_row0" class="row_heading level0 row0" ></th>
      <td id="T_033c0_row0_col0" class="data row0 col0" >Train</td>
      <td id="T_033c0_row0_col1" class="data row0 col1" >40</td>
      <td id="T_033c0_row0_col2" class="data row0 col2" >40</td>
      <td id="T_033c0_row0_col3" class="data row0 col3" >40</td>
    </tr>
    <tr>
      <th id="T_033c0_level0_row1" class="row_heading level0 row1" ></th>
      <td id="T_033c0_row1_col0" class="data row1 col0" >Test</td>
      <td id="T_033c0_row1_col1" class="data row1 col1" >10</td>
      <td id="T_033c0_row1_col2" class="data row1 col2" >10</td>
      <td id="T_033c0_row1_col3" class="data row1 col3" >10</td>
    </tr>
  </tbody>
</table>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Fold 2:</span>
</pre></div>
</div>
<div class="output text_html"><style type="text/css">
#T_5cf56 tbody tr:nth-child(1) {
  background-color: #f0fff0;
}
#T_5cf56 tbody tr:nth-child(2) {
  background-color: #cfe2f3;
}
</style>
<table id="T_5cf56">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_5cf56_level0_col0" class="col_heading level0 col0" >Set</th>
      <th id="T_5cf56_level0_col1" class="col_heading level0 col1" >setosa</th>
      <th id="T_5cf56_level0_col2" class="col_heading level0 col2" >versicolor</th>
      <th id="T_5cf56_level0_col3" class="col_heading level0 col3" >virginica</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_5cf56_level0_row0" class="row_heading level0 row0" ></th>
      <td id="T_5cf56_row0_col0" class="data row0 col0" >Train</td>
      <td id="T_5cf56_row0_col1" class="data row0 col1" >40</td>
      <td id="T_5cf56_row0_col2" class="data row0 col2" >40</td>
      <td id="T_5cf56_row0_col3" class="data row0 col3" >40</td>
    </tr>
    <tr>
      <th id="T_5cf56_level0_row1" class="row_heading level0 row1" ></th>
      <td id="T_5cf56_row1_col0" class="data row1 col0" >Test</td>
      <td id="T_5cf56_row1_col1" class="data row1 col1" >10</td>
      <td id="T_5cf56_row1_col2" class="data row1 col2" >10</td>
      <td id="T_5cf56_row1_col3" class="data row1 col3" >10</td>
    </tr>
  </tbody>
</table>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Fold 3:</span>
</pre></div>
</div>
<div class="output text_html"><style type="text/css">
#T_ea6fd tbody tr:nth-child(1) {
  background-color: #f0fff0;
}
#T_ea6fd tbody tr:nth-child(2) {
  background-color: #cfe2f3;
}
</style>
<table id="T_ea6fd">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_ea6fd_level0_col0" class="col_heading level0 col0" >Set</th>
      <th id="T_ea6fd_level0_col1" class="col_heading level0 col1" >setosa</th>
      <th id="T_ea6fd_level0_col2" class="col_heading level0 col2" >versicolor</th>
      <th id="T_ea6fd_level0_col3" class="col_heading level0 col3" >virginica</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_ea6fd_level0_row0" class="row_heading level0 row0" ></th>
      <td id="T_ea6fd_row0_col0" class="data row0 col0" >Train</td>
      <td id="T_ea6fd_row0_col1" class="data row0 col1" >40</td>
      <td id="T_ea6fd_row0_col2" class="data row0 col2" >40</td>
      <td id="T_ea6fd_row0_col3" class="data row0 col3" >40</td>
    </tr>
    <tr>
      <th id="T_ea6fd_level0_row1" class="row_heading level0 row1" ></th>
      <td id="T_ea6fd_row1_col0" class="data row1 col0" >Test</td>
      <td id="T_ea6fd_row1_col1" class="data row1 col1" >10</td>
      <td id="T_ea6fd_row1_col2" class="data row1 col2" >10</td>
      <td id="T_ea6fd_row1_col3" class="data row1 col3" >10</td>
    </tr>
  </tbody>
</table>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Fold 4:</span>
</pre></div>
</div>
<div class="output text_html"><style type="text/css">
#T_28481 tbody tr:nth-child(1) {
  background-color: #f0fff0;
}
#T_28481 tbody tr:nth-child(2) {
  background-color: #cfe2f3;
}
</style>
<table id="T_28481">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_28481_level0_col0" class="col_heading level0 col0" >Set</th>
      <th id="T_28481_level0_col1" class="col_heading level0 col1" >setosa</th>
      <th id="T_28481_level0_col2" class="col_heading level0 col2" >versicolor</th>
      <th id="T_28481_level0_col3" class="col_heading level0 col3" >virginica</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_28481_level0_row0" class="row_heading level0 row0" ></th>
      <td id="T_28481_row0_col0" class="data row0 col0" >Train</td>
      <td id="T_28481_row0_col1" class="data row0 col1" >40</td>
      <td id="T_28481_row0_col2" class="data row0 col2" >40</td>
      <td id="T_28481_row0_col3" class="data row0 col3" >40</td>
    </tr>
    <tr>
      <th id="T_28481_level0_row1" class="row_heading level0 row1" ></th>
      <td id="T_28481_row1_col0" class="data row1 col0" >Test</td>
      <td id="T_28481_row1_col1" class="data row1 col1" >10</td>
      <td id="T_28481_row1_col2" class="data row1 col2" >10</td>
      <td id="T_28481_row1_col3" class="data row1 col3" >10</td>
    </tr>
  </tbody>
</table>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Fold 5:</span>
</pre></div>
</div>
<div class="output text_html"><style type="text/css">
#T_ee578 tbody tr:nth-child(1) {
  background-color: #f0fff0;
}
#T_ee578 tbody tr:nth-child(2) {
  background-color: #cfe2f3;
}
</style>
<table id="T_ee578">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_ee578_level0_col0" class="col_heading level0 col0" >Set</th>
      <th id="T_ee578_level0_col1" class="col_heading level0 col1" >setosa</th>
      <th id="T_ee578_level0_col2" class="col_heading level0 col2" >versicolor</th>
      <th id="T_ee578_level0_col3" class="col_heading level0 col3" >virginica</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_ee578_level0_row0" class="row_heading level0 row0" ></th>
      <td id="T_ee578_row0_col0" class="data row0 col0" >Train</td>
      <td id="T_ee578_row0_col1" class="data row0 col1" >40</td>
      <td id="T_ee578_row0_col2" class="data row0 col2" >40</td>
      <td id="T_ee578_row0_col3" class="data row0 col3" >40</td>
    </tr>
    <tr>
      <th id="T_ee578_level0_row1" class="row_heading level0 row1" ></th>
      <td id="T_ee578_row1_col0" class="data row1 col0" >Test</td>
      <td id="T_ee578_row1_col1" class="data row1 col1" >10</td>
      <td id="T_ee578_row1_col2" class="data row1 col2" >10</td>
      <td id="T_ee578_row1_col3" class="data row1 col3" >10</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<section id="leave-one-out-cross-validation-loocv">
<h3><span class="section-number">9.6.1.1. </span>Leave-One-Out Cross-Validation (LOOCV)<a class="headerlink" href="#leave-one-out-cross-validation-loocv" title="Link to this heading">#</a></h3>
<p>Leave-One-Out Cross-Validation is a special case of k-fold Cross-Validation where (k) is set to the number of samples in the dataset. In other words, for each iteration of LOOCV, only one sample is used as the test set, and the rest of the samples form the training set. LOOCV is particularly useful when dealing with a small dataset since it maximizes the use of available data for testing purposes.</p>
<p>Here’s how LOOCV works:</p>
<ol class="arabic simple">
<li><p><strong>Iteration:</strong></p>
<ul class="simple">
<li><p>For each data point in the dataset, designate it as the test instance, and use the remaining (n-1) instances as the training set.</p></li>
</ul>
</li>
<li><p><strong>Model Training and Testing:</strong></p>
<ul class="simple">
<li><p>Train your model on the (n-1) training instances.</p></li>
<li><p>Evaluate the model’s performance on the single test instance.</p></li>
<li><p>Calculate the performance metric (e.g., accuracy, mean squared error) for this iteration.</p></li>
</ul>
</li>
<li><p><strong>Repeat for All Data Points:</strong></p>
<ul class="simple">
<li><p>Repeat steps 1 and 2 for all (n) data points in the dataset.</p></li>
</ul>
</li>
<li><p><strong>Overall Performance Estimate:</strong></p>
<ul class="simple">
<li><p>Calculate the average performance metric across all (n) iterations. This provides an overall estimate of the model’s performance.</p></li>
</ul>
</li>
</ol>
<p><strong>Advantages of LOOCV:</strong></p>
<ul class="simple">
<li><p>Utilizes the entire dataset for testing, ensuring maximum information is used.</p></li>
<li><p>Provides a nearly unbiased estimate of the model’s performance, as each instance serves as both training and test data.</p></li>
<li><p>Particularly useful for small datasets where other forms of cross-validation may result in too few instances for testing.</p></li>
</ul>
<p><strong>Disadvantages of LOOCV:</strong></p>
<ul class="simple">
<li><p>Can be computationally expensive for large datasets, as it requires fitting the model (n) times.</p></li>
<li><p>May lead to high variance estimates due to the potential similarity between training and test instances in each iteration.</p></li>
</ul>
<p>LOOCV provides a reliable estimate of a model’s performance, especially when dealing with limited data. While it can be more computationally intensive, its comprehensiveness and minimal bias make it a valuable tool for model assessment.</p>
<p>Example: In leave-one-out (LOO) cross-validation, we iteratively train our machine-learning model n times, where n represents the size of our dataset. During each iteration, a single sample is set aside as the test set, while the remaining samples are used for training the model.</p>
<p>LOO can be thought of as an extreme case of k-fold cross-validation, where the value of <strong>k</strong> becomes equal to <strong>n</strong>. If we apply the LOO approach to the previous example, we’ll create 6 distinct test subsets:</p>
<ul class="simple">
<li><p>Subset 1: <span class="math notranslate nohighlight">\(S_1 = \{x_1\}\)</span></p></li>
<li><p>Subset 2: <span class="math notranslate nohighlight">\(S_2 = \{x_2\}\)</span></p></li>
<li><p>Subset 3: <span class="math notranslate nohighlight">\(S_3 = \{x_3\}\)</span></p></li>
<li><p>Subset 4: <span class="math notranslate nohighlight">\(S_4 = \{x_4\}\)</span></p></li>
<li><p>Subset 5: <span class="math notranslate nohighlight">\(S_5 = \{x_5\}\)</span></p></li>
<li><p>Subset 6: <span class="math notranslate nohighlight">\(S_6 = \{x_6\}\)</span></p></li>
</ul>
<p>For each of these subsets, we perform an iteration. During iteration <strong>i = 1, 2, …, 6</strong>, we use the dataset <strong><span class="math notranslate nohighlight">\(S\)</span></strong> without the samples from <strong><span class="math notranslate nohighlight">\(S_i\)</span></strong> (denoted as <strong><span class="math notranslate nohighlight">\(S \setminus S_i\)</span></strong>) as the training data. Then, we evaluate the model’s performance on <strong><span class="math notranslate nohighlight">\(S_i\)</span></strong>, which serves as the test set:</p>
<p><strong>Iteration 1:</strong></p>
<ul class="simple">
<li><p><font color='Green'><b>Training Set:</b></font> <span class="math notranslate nohighlight">\(S \setminus S_1\)</span></p></li>
<li><p><font color='Blue'><b>Test Set:</b></font> <span class="math notranslate nohighlight">\(S_1 = \{x_1\}\)</span></p></li>
</ul>
<p><strong>Iteration 2:</strong></p>
<ul class="simple">
<li><p><font color='Green'><b>Training Set:</b></font> <span class="math notranslate nohighlight">\(S \setminus S_2\)</span></p></li>
<li><p><font color='Blue'><b>Test Set:</b></font> <span class="math notranslate nohighlight">\(S_2 = \{x_2\}\)</span></p></li>
</ul>
<p><strong>Iteration 3:</strong></p>
<ul class="simple">
<li><p><font color='Green'><b>Training Set:</b></font> <span class="math notranslate nohighlight">\(S \setminus S_3\)</span></p></li>
<li><p><font color='Blue'><b>Test Set:</b></font> <span class="math notranslate nohighlight">\(S_3 = \{x_3\}\)</span></p></li>
</ul>
<p><strong>Iteration 4:</strong></p>
<ul class="simple">
<li><p><font color='Green'><b>Training Set:</b></font> <span class="math notranslate nohighlight">\(S \setminus S_4\)</span></p></li>
<li><p><font color='Blue'><b>Test Set:</b></font> <span class="math notranslate nohighlight">\(S_4 = \{x_4\}\)</span></p></li>
</ul>
<p><strong>Iteration 5:</strong></p>
<ul class="simple">
<li><p><font color='Green'><b>Training Set:</b></font> <span class="math notranslate nohighlight">\(S \setminus S_5\)</span></p></li>
<li><p><font color='Blue'><b>Test Set:</b></font> <span class="math notranslate nohighlight">\(S_5 = \{x_5\}\)</span></p></li>
</ul>
<p><strong>Iteration 6:</strong></p>
<ul class="simple">
<li><p><font color='Green'><b>Training Set:</b></font> <span class="math notranslate nohighlight">\(S \setminus S_6\)</span></p></li>
<li><p><font color='Blue'><b>Test Set:</b></font> <span class="math notranslate nohighlight">\(S_6 = \{x_6\}\)</span></p></li>
</ul>
<p>In each iteration, the model learns from all but one data point and then gets evaluated on the held-out sample. This process provides a detailed assessment of the model’s performance for every individual sample in the dataset.</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/LeaveOneOut.png"><img alt="../_images/LeaveOneOut.png" src="../_images/LeaveOneOut.png" style="width: 450px;" /></a>
</figure>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeaveOneOut</span>

<span class="c1"># Define the dataset as a one-dimensional array</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">,</span> <span class="s1">&#39;x3&#39;</span><span class="p">,</span> <span class="s1">&#39;x4&#39;</span><span class="p">,</span> <span class="s1">&#39;x5&#39;</span><span class="p">,</span> <span class="s1">&#39;x6&#39;</span><span class="p">])</span>

<span class="c1"># Reshape the dataset into a two-dimensional array with one column</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Create the KFold object with 3 splits</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">print_bold</span><span class="p">(</span><span class="n">txt</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[1;31m&quot;</span> <span class="o">+</span> <span class="n">txt</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[0m&quot;</span><span class="p">)</span>

<span class="n">loo</span> <span class="o">=</span> <span class="n">LeaveOneOut</span><span class="p">()</span>
    
<span class="c1"># Loop over the train and test indices returned by the KFold object</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">loo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Print the train and test sets</span>
    <span class="n">print_bold</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t\033</span><span class="s2">[1;42mTrain set</span><span class="se">\033</span><span class="s2">[0m:{&quot;</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()),</span> <span class="s1">&#39;}&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t\033</span><span class="s2">[1;44mTest set</span><span class="se">\033</span><span class="s2">[0m:{&quot;</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()),</span> <span class="s1">&#39;}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-Red">Fold 1:</span>
	<span class=" -Color -Color-Bold -Color-Bold-BGGreen">Train set</span>:{ x2, x3, x4, x5, x6 }
	<span class=" -Color -Color-Bold -Color-Bold-BGBlue">Test set</span>:{ x1 }

<span class=" -Color -Color-Bold -Color-Bold-Red">Fold 2:</span>
	<span class=" -Color -Color-Bold -Color-Bold-BGGreen">Train set</span>:{ x1, x3, x4, x5, x6 }
	<span class=" -Color -Color-Bold -Color-Bold-BGBlue">Test set</span>:{ x2 }

<span class=" -Color -Color-Bold -Color-Bold-Red">Fold 3:</span>
	<span class=" -Color -Color-Bold -Color-Bold-BGGreen">Train set</span>:{ x1, x2, x4, x5, x6 }
	<span class=" -Color -Color-Bold -Color-Bold-BGBlue">Test set</span>:{ x3 }

<span class=" -Color -Color-Bold -Color-Bold-Red">Fold 4:</span>
	<span class=" -Color -Color-Bold -Color-Bold-BGGreen">Train set</span>:{ x1, x2, x3, x5, x6 }
	<span class=" -Color -Color-Bold -Color-Bold-BGBlue">Test set</span>:{ x4 }

<span class=" -Color -Color-Bold -Color-Bold-Red">Fold 5:</span>
	<span class=" -Color -Color-Bold -Color-Bold-BGGreen">Train set</span>:{ x1, x2, x3, x4, x6 }
	<span class=" -Color -Color-Bold -Color-Bold-BGBlue">Test set</span>:{ x5 }

<span class=" -Color -Color-Bold -Color-Bold-Red">Fold 6:</span>
	<span class=" -Color -Color-Bold -Color-Bold-BGGreen">Train set</span>:{ x1, x2, x3, x4, x5 }
	<span class=" -Color -Color-Bold -Color-Bold-BGBlue">Test set</span>:{ x6 }
</pre></div>
</div>
</div>
</div>
<p><font color='Blue'><b>Example:</b></font></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeaveOneOut</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Iris dataset</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>

<span class="k">def</span> <span class="nf">_Line</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">50</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="s1">&#39;_&#39;</span><span class="p">)</span>
    
<span class="c1"># Create a KNN Classifier</span>
<span class="n">KKN</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># Using 3 nearest neighbors</span>

<span class="k">def</span> <span class="nf">print_bold</span><span class="p">(</span><span class="n">txt</span><span class="p">):</span>
    <span class="n">_left</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[1;43m&quot;</span>
    <span class="n">_right</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[0m&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">_left</span> <span class="o">+</span> <span class="n">txt</span> <span class="o">+</span> <span class="n">_right</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_Line</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">80</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="s1">&#39;_&#39;</span><span class="p">)</span>
    
<span class="c1"># Initialize Leave-One-Out cross-validator</span>
<span class="n">loo</span> <span class="o">=</span> <span class="n">LeaveOneOut</span><span class="p">()</span>

<span class="c1"># Lists to store train and test scores for each iteration</span>
<span class="n">train_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Lists to store train and test scores for each fold</span>
<span class="n">train_acc_scores</span><span class="p">,</span> <span class="n">test_acc_scores</span><span class="p">,</span> <span class="n">train_f1_scores</span><span class="p">,</span> <span class="n">test_f1_scores</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="c1"># Perform Leave-One-Out Cross-Validation</span>
<span class="k">for</span> <span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="ow">in</span> <span class="n">loo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
    <span class="n">KKN</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="c1"># train</span>
    <span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">KKN</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">train_acc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">))</span>
    <span class="n">train_f1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">,</span> <span class="n">average</span> <span class="o">=</span> <span class="s1">&#39;weighted&#39;</span><span class="p">))</span>
    <span class="c1"># test</span>
    <span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">KKN</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">test_acc_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">))</span>
    <span class="n">test_f1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">,</span> <span class="n">average</span> <span class="o">=</span> <span class="s1">&#39;weighted&#39;</span><span class="p">))</span>

<span class="c1"># _Line()</span>
<span class="c1"># #  Print the Train and Test Scores for each fold</span>
<span class="c1"># for fold in range(len(train_acc_scores)):</span>
<span class="c1">#     print_bold(f&#39;Fold {fold + 1}:&#39;)</span>
<span class="c1">#     print(f&quot;\tTrain Accuracy Score = {train_acc_scores[fold]:.4f}, Test Accuracy Score = {test_acc_scores[fold]:.4f}&quot;)</span>
<span class="c1">#     print(f&quot;\tTrain F1 Score (weighted) = {train_f1_scores[fold]:.4f}, Test F1 Score (weighted)= {test_f1_scores[fold]:.4f}&quot;)</span>

<span class="n">_Line</span><span class="p">()</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;Accuracy Score:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Mean Train Accuracy Score: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_acc_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_acc_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Mean Test Accuracy Score: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_acc_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_acc_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">print_bold</span><span class="p">(</span><span class="s1">&#39;F1 Score:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Mean F1 Accuracy Score (weighted): </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_f1_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_f1_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Mean F1 Accuracy Score (weighted): </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_f1_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_f1_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">_Line</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>________________________________________________________________________________
<span class=" -Color -Color-Bold -Color-Bold-BGYellow">Accuracy Score:</span>
	Mean Train Accuracy Score: 0.9601 ± 0.0019
	Mean Test Accuracy Score: 0.9600 ± 0.1960
<span class=" -Color -Color-Bold -Color-Bold-BGYellow">F1 Score:</span>
	Mean F1 Accuracy Score (weighted): 0.9601 ± 0.0019
	Mean F1 Accuracy Score (weighted): 0.9600 ± 0.1960
________________________________________________________________________________
</pre></div>
</div>
</div>
</div>
<p>Note that:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Perform Cross-Validation</span>
<span class="n">C</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">test_idx</span> <span class="ow">in</span> <span class="n">loo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">print_bold</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Fold </span><span class="si">{</span><span class="n">C</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">][</span><span class="n">test_idx</span><span class="p">])</span>
    <span class="n">C</span><span class="o">+=</span><span class="mi">1</span>
    <span class="c1"># Only the first 5 folds</span>
    <span class="k">if</span> <span class="n">C</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
        <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold -Color-Bold-BGYellow">Fold 1:</span>
[&#39;setosa&#39;]
<span class=" -Color -Color-Bold -Color-Bold-BGYellow">Fold 2:</span>
[&#39;setosa&#39;]
<span class=" -Color -Color-Bold -Color-Bold-BGYellow">Fold 3:</span>
[&#39;setosa&#39;]
<span class=" -Color -Color-Bold -Color-Bold-BGYellow">Fold 4:</span>
[&#39;setosa&#39;]
<span class=" -Color -Color-Bold -Color-Bold-BGYellow">Fold 5:</span>
[&#39;setosa&#39;]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="bootstrap-method">
<h2><span class="section-number">9.6.2. </span>Bootstrap Method<a class="headerlink" href="#bootstrap-method" title="Link to this heading">#</a></h2>
<p>The Bootstrap method is a powerful resampling technique designed to estimate the sampling distribution of a given statistic, such as the mean, median, or standard deviation. It offers a robust way to assess the variability and uncertainty associated with a statistic, without relying on specific assumptions about the underlying data distribution <span id="id8">[<a class="reference internal" href="../References.html#id98" title="Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani, and Jonathan Taylor. An Introduction to Statistical Learning: with Applications in R. Springer Texts in Statistics. Springer Cham, 2023. ISBN 9783031391897. URL: https://link.springer.com/book/10.1007/978-3-031-38747-0.">James <em>et al.</em>, 2023</a>]</span>:.</p>
<p>Here’s a detailed breakdown of the Bootstrap method:</p>
<ol class="arabic simple">
<li><p><strong>Bootstrap Sample Generation:</strong></p>
<ul class="simple">
<li><p>For each iteration <span class="math notranslate nohighlight">\(b = 1, 2, \ldots, B\)</span>, create a new bootstrap sample <span class="math notranslate nohighlight">\(x_1^*, x_2^*, \ldots, x_n^*\)</span> by randomly selecting <span class="math notranslate nohighlight">\(n\)</span> observations with replacement from the original dataset <span class="math notranslate nohighlight">\(x_1, x_2, \ldots, x_n\)</span>. This allows for duplicates within the sample.</p></li>
</ul>
</li>
<li><p><strong>Statistic Calculation:</strong></p>
<ul class="simple">
<li><p>Calculate the statistic of interest <span class="math notranslate nohighlight">\(T^*\)</span> based on the bootstrap sample: <span class="math notranslate nohighlight">\(T^* = g(x_1^*, x_2^*, \ldots, x_n^*)\)</span>. Here, <span class="math notranslate nohighlight">\(g\)</span> is a function that computes the desired statistic. For instance, if estimating the mean, <span class="math notranslate nohighlight">\(T^* = \dfrac{1}{n} \sum_{i=1}^{n} x_i^*\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Repeat and Collect Statistics:</strong></p>
<ul class="simple">
<li><p>Repeat steps 1 and 2 for a significant number of iterations <span class="math notranslate nohighlight">\(B\)</span>, resulting in a collection of bootstrap statistics: <span class="math notranslate nohighlight">\(T_1^*, T_2^*, \ldots, T_B^*\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Estimating Variability:</strong></p>
<ul class="simple">
<li><p>The distribution of the calculated bootstrap statistics <span class="math notranslate nohighlight">\(T_1^*, T_2^*, \ldots, T_B^*\)</span> approximates the sampling distribution of the original statistic <span class="math notranslate nohighlight">\(T\)</span>.</p></li>
<li><p>From this distribution, you can calculate various measures of variability, such as confidence intervals, standard errors, or percentiles.</p></li>
</ul>
</li>
</ol>
<p>Bootstraping, in the context of statistics and data analysis, refers to a resampling technique that helps us make inferences about a population based on a sample of data. It’s particularly useful when we want to understand the variability of a statistic (such as the mean or standard deviation) and estimate its properties, like confidence intervals, when the underlying population distribution might be unknown or complex.</p>
<p>Here’s a simple explanation of bootstrapping:</p>
<ol class="arabic simple">
<li><p><strong>The Problem:</strong> Imagine you have a small dataset, and you want to understand something about a specific statistic (like the mean) of the entire population from which the data was drawn. However, drawing conclusions directly from your limited sample might not accurately reflect the true characteristics of the population.</p></li>
<li><p><strong>Resampling:</strong> Bootstrapping addresses this by simulating the process of drawing samples from your original data. To do this, you randomly select data points from your original dataset with replacement, creating a new “bootstrap sample” of the same size as your original data. Because you’re sampling with replacement, some data points will appear multiple times in the bootstrap sample, while others might not appear at all.</p></li>
<li><p><strong>Calculating Statistic:</strong> For each bootstrap sample, you calculate the desired statistic (e.g., mean) based on the data points in that sample.</p></li>
<li><p><strong>Repeated Process:</strong> You repeat the resampling process (step 2 and 3) a large number of times (often thousands of times). Each time, you’re essentially creating a simulated dataset by drawing samples from your original data with replacement.</p></li>
<li><p><strong>Inference:</strong> By analyzing the distribution of the calculated statistic across all these bootstrap samples, you can make inferences about the population. For instance, you can estimate the variability of the statistic (by looking at its standard deviation), calculate confidence intervals, or even visualize the distribution itself.</p></li>
<li><p><strong>Advantages:</strong> Bootstrapping is powerful because it doesn’t rely on assumptions about the shape or parameters of the population distribution. It works well for small sample sizes and can provide valuable insights even when traditional statistical methods might not be applicable.</p></li>
</ol>
<p>Bootstrapping is a resampling technique that helps us understand the characteristics of a population by repeatedly creating simulated datasets from our original data and calculating statistics of interest on these simulated datasets. It’s a versatile and useful tool in situations where traditional statistical methods might not be suitable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;../mystyle.mplstyle&#39;</span><span class="p">)</span>

<span class="c1"># Load the Iris dataset from Seaborn</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;iris&quot;</span><span class="p">)</span>

<span class="c1"># Choose a specific iris species (let&#39;s say &quot;setosa&quot;)</span>
<span class="n">species_data</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="n">iris</span><span class="p">[</span><span class="s2">&quot;species&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;setosa&quot;</span><span class="p">]</span>
<span class="n">petal_length_data</span> <span class="o">=</span> <span class="n">species_data</span><span class="p">[</span><span class="s2">&quot;petal_length&quot;</span><span class="p">]</span>

<span class="c1"># Number of bootstrap samples</span>
<span class="n">num_bootstraps</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Initialize an array to store bootstrap sample means</span>
<span class="n">bootstrap_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_bootstraps</span><span class="p">)</span>

<span class="c1"># Perform bootstrapping</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_bootstraps</span><span class="p">):</span>
    <span class="n">bootstrap_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">petal_length_data</span><span class="p">,</span>
                                        <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">petal_length_data</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">bootstrap_means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">bootstrap_sample</span><span class="p">)</span>

<span class="c1"># Calculate the 95% confidence interval for the mean</span>
<span class="n">confidence_interval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">bootstrap_means</span><span class="p">,</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">97.5</span><span class="p">])</span>

<span class="c1"># Create a new figure and axis</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Plot the histogram of bootstrap sample means</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">bootstrap_means</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">petal_length_data</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Original Mean&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">bootstrap_means</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Bootstrap Mean&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">confidence_interval</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;95% CI Lower&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">confidence_interval</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;95% CI Upper&#39;</span><span class="p">)</span>

<span class="c1"># Set various plot settings in one call</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Mean Petal Length&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Frequency&quot;</span><span class="p">,</span>
       <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Bootstrapped Mean Petal Length Distribution&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original Mean: </span><span class="si">%.5f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">petal_length_data</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Bootstrap Mean </span><span class="si">%.5f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">bootstrap_means</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;95% Confidence Interval:&quot;</span><span class="p">,</span> <span class="n">confidence_interval</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original Mean: 1.46200
Bootstrap Mean 1.46189
95% Confidence Interval: [1.414   1.50805]
</pre></div>
</div>
<img alt="../_images/5162de11df516f6d4596ec3c077741639f0c8d092647a1d5474bd2222125f813.png" src="../_images/5162de11df516f6d4596ec3c077741639f0c8d092647a1d5474bd2222125f813.png" />
</div>
</div>
<p>Let’s break down the code step by step:</p>
<ol class="arabic">
<li><p><strong>Import Libraries:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">numpy</span></code> is imported as <code class="docutils literal notranslate"><span class="pre">np</span></code> for numerical operations.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">seaborn</span></code> is imported as <code class="docutils literal notranslate"><span class="pre">sns</span></code> for data visualization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot</span></code> is imported as <code class="docutils literal notranslate"><span class="pre">plt</span></code> for creating plots.</p></li>
</ul>
</li>
<li><p><strong>Load the Dataset:</strong></p>
<ul class="simple">
<li><p>The Iris dataset is loaded using <code class="docutils literal notranslate"><span class="pre">sns.load_dataset(&quot;iris&quot;)</span></code>.</p></li>
</ul>
</li>
<li><p><strong>Data Preparation:</strong></p>
<ul class="simple">
<li><p>A specific species (“setosa”) from the dataset is chosen.</p></li>
<li><p>The “petal_length” data for the chosen species is extracted.</p></li>
</ul>
</li>
<li><p><strong>Number of Bootstrap Samples:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">num_bootstraps</span></code> is set to 1000, indicating the number of bootstrap samples to generate.</p></li>
</ul>
</li>
<li><p><strong>Initialize Arrays:</strong></p>
<ul class="simple">
<li><p>An array named <code class="docutils literal notranslate"><span class="pre">bootstrap_means</span></code> is initialized to store the means of each bootstrap sample.</p></li>
</ul>
</li>
<li><p><strong>Perform Bootstrapping:</strong></p>
<ul class="simple">
<li><p>A loop runs <code class="docutils literal notranslate"><span class="pre">num_bootstraps</span></code> times.</p></li>
<li><p>For each iteration, a bootstrap sample is created by randomly selecting data points from <code class="docutils literal notranslate"><span class="pre">petal_length_data</span></code> with replacement.</p></li>
<li><p>The mean of the bootstrap sample is calculated and stored in the <code class="docutils literal notranslate"><span class="pre">bootstrap_means</span></code> array.</p></li>
</ul>
</li>
<li><p><strong>Calculate Confidence Interval:</strong>
The code snippet <code class="docutils literal notranslate"><span class="pre">np.percentile(bootstrap_means,</span> <span class="pre">[2.5,</span> <span class="pre">97.5])</span></code> calculates the percentiles of the <code class="docutils literal notranslate"><span class="pre">bootstrap_means</span></code> array. In particular, it calculates the 2.5th and 97.5th percentiles of the distribution, which correspond to the lower and upper bounds of a 95% confidence interval.</p>
<p>In the context of bootstrapping and statistical inference, the calculated confidence interval provides an estimate of the range in which the true population parameter (in this case, the mean) is likely to fall. Here’s how it works:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">bootstrap_means</span></code>: This is an array that contains the means of various bootstrap samples. Each value in this array represents the mean of a specific bootstrap sample.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">np.percentile(bootstrap_means,</span> <span class="pre">[2.5,</span> <span class="pre">97.5])</span></code>: This function call calculates the specified percentiles from the <code class="docutils literal notranslate"><span class="pre">bootstrap_means</span></code> array. Percentiles are values that divide a dataset into corresponding percentages. In this case, the code calculates the 2.5th and 97.5th percentiles.</p>
<ul class="simple">
<li><p>The 2.5th percentile represents the value below which 2.5% of the data falls. It gives the lower bound of the confidence interval.</p></li>
<li><p>The 97.5th percentile represents the value below which 97.5% of the data falls. It gives the upper bound of the confidence interval.</p></li>
</ul>
</li>
<li><p>The calculated percentiles provide the lower and upper bounds of a confidence interval. Specifically, the range between the 2.5th percentile and the 97.5th percentile is a 95% confidence interval for the parameter being estimated (in this case, the mean of the population).</p></li>
</ol>
</li>
<li><p><strong>Create Plot:</strong></p>
<ul class="simple">
<li><p>A new figure and axis are created using <code class="docutils literal notranslate"><span class="pre">plt.subplots()</span></code>.</p></li>
<li><p>The histogram of bootstrapped means is plotted using <code class="docutils literal notranslate"><span class="pre">sns.histplot()</span></code>, with a kernel density estimate (KDE) overlaid.</p></li>
<li><p>Dashed vertical lines are added to indicate the original mean, bootstrap mean, and lower and upper bounds of the confidence interval.</p></li>
</ul>
</li>
<li><p><strong>Set Plot Settings:</strong></p>
<ul class="simple">
<li><p>Various plot settings such as labels, title, and legends are set using the <code class="docutils literal notranslate"><span class="pre">ax.set()</span></code> function.</p></li>
</ul>
</li>
<li><p><strong>Display the Plot:</strong></p>
<ul class="simple">
<li><p>The plot is displayed using <code class="docutils literal notranslate"><span class="pre">plt.show()</span></code>.</p></li>
</ul>
</li>
<li><p><strong>Print Results:</strong></p>
<ul class="simple">
<li><p>The original mean of “petal_length_data”, bootstrap mean, and the calculated confidence interval are printed using <code class="docutils literal notranslate"><span class="pre">print()</span></code> statements.</p></li>
</ul>
</li>
</ol>
<p>The code essentially demonstrates how bootstrapping can be used to estimate the mean of a dataset, and how the distribution of bootstrapped means provides insights into the variability of the estimate. The confidence interval helps us understand the range within which the true population mean is likely to fall.</p>
<div class="warning admonition">
<p class="admonition-title">Note</p>
<p>Let’s focus on this part:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">bootstrap_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">petal_length_data</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">petal_length_data</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">numpy.random.choice</span></code> function was used to generate a bootstrap sample from the <code class="docutils literal notranslate"><span class="pre">petal_length_data</span> <span class="pre">array</span></code>. A bootstrap sample is a random sample of the <strong>same size</strong> as the original data, but <strong>with replacement</strong>. This means that some elements of the original data may appear more than once or not at all in the bootstrap sample. The purpose of bootstrapping is to estimate the uncertainty or variability of a statistic, such as the mean, by resampling the data many times and computing the statistic for each sample. In this case, the code is trying to estimate the 95% confidence interval for the mean of the petal length of the setosa species. For more information about the numpy.random.choice function, you can refer to the <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html">NumPy Manual</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">generate_bootstrap_sample</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">6</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates a bootstrapped sample from an array of consecutive integers.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - size (int): The size of the bootstrap sample.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - numpy.ndarray: The generated bootstrapped sample.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;str&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">num_bootstraps</span> <span class="o">=</span> <span class="mi">10</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Obtaining </span><span class="si">{</span><span class="n">num_bootstraps</span><span class="si">}</span><span class="s1"> bootstrapped samples:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_bootstraps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">bootstrap_sample</span> <span class="o">=</span> <span class="n">generate_bootstrap_sample</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Sample </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t\t</span><span class="s1">[</span><span class="si">{</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">bootstrap_sample</span><span class="p">)</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">)</span>
    
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Obtaining</span> <span class="mi">10</span> <span class="n">bootstrapped</span> <span class="n">samples</span><span class="p">:</span>

<span class="n">Sample</span> <span class="mi">1</span><span class="p">:</span>
		<span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">Sample</span> <span class="mi">2</span><span class="p">:</span>
		<span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">Sample</span> <span class="mi">3</span><span class="p">:</span>
		<span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">Sample</span> <span class="mi">4</span><span class="p">:</span>
		<span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">Sample</span> <span class="mi">5</span><span class="p">:</span>
		<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">Sample</span> <span class="mi">6</span><span class="p">:</span>
		<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="n">Sample</span> <span class="mi">7</span><span class="p">:</span>
		<span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">Sample</span> <span class="mi">8</span><span class="p">:</span>
		<span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">Sample</span> <span class="mi">9</span><span class="p">:</span>
		<span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">Sample</span> <span class="mi">10</span><span class="p">:</span>
		<span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p><font color='Blue'><b>Example - Estimating the Mean Monthly Temperature of Calgary in January Using Bootstrapping:</b></font> In this exercise, we will learn how to use the bootstrapping technique to estimate the uncertainty of a statistic, such as the mean, by resampling the data many times and computing the statistic for each sample. We will use the data of the mean monthly temperature of <code class="docutils literal notranslate"><span class="pre">CALGARY</span> <span class="pre">INT'L</span> <span class="pre">CS</span></code> in January, obtained from the <a class="reference external" href="https://climate.weather.gc.ca/">Government of Canada</a>, as an example. We will use Python to perform the bootstrapping, plot the histogram of the bootstrap sample means, and calculate the 95% confidence interval for the mean. We will also compare the original mean and the bootstrap mean, and see how they are close to each other. This exercise will help us understand how to use bootstrapping to measure the variability of a statistic and how it can be useful in data analysis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">Link</span> <span class="o">=</span> <span class="s1">&#39;https://climate.weather.gc.ca/climate_data/bulk_data_e.html?format=csv&amp;stationID=27211&amp;Year=2022&amp;Month=1&amp;Day=1&amp;time=&amp;timeframe=2&amp;submit=Download+Data&#39;</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">Link</span><span class="p">,</span> <span class="n">usecols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Date/Time&#39;</span><span class="p">,</span> <span class="s1">&#39;Year&#39;</span><span class="p">,</span> <span class="s1">&#39;Month&#39;</span> <span class="p">,</span> <span class="s1">&#39;Mean Temp (°C)&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date/Time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date/Time&#39;</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Date/Time&#39;</span><span class="p">:</span><span class="s1">&#39;Date&#39;</span><span class="p">})</span>
<span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Year</th>
      <th>Month</th>
      <th>Mean Temp (°C)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2022-01-01</td>
      <td>2022</td>
      <td>1</td>
      <td>-13.4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2022-01-02</td>
      <td>2022</td>
      <td>1</td>
      <td>-7.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2022-01-03</td>
      <td>2022</td>
      <td>1</td>
      <td>-20.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2022-01-04</td>
      <td>2022</td>
      <td>1</td>
      <td>-27.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2022-01-05</td>
      <td>2022</td>
      <td>1</td>
      <td>-27.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>360</th>
      <td>2022-12-27</td>
      <td>2022</td>
      <td>12</td>
      <td>1.4</td>
    </tr>
    <tr>
      <th>361</th>
      <td>2022-12-28</td>
      <td>2022</td>
      <td>12</td>
      <td>-4.9</td>
    </tr>
    <tr>
      <th>362</th>
      <td>2022-12-29</td>
      <td>2022</td>
      <td>12</td>
      <td>-8.2</td>
    </tr>
    <tr>
      <th>363</th>
      <td>2022-12-30</td>
      <td>2022</td>
      <td>12</td>
      <td>-2.7</td>
    </tr>
    <tr>
      <th>364</th>
      <td>2022-12-31</td>
      <td>2022</td>
      <td>12</td>
      <td>-6.3</td>
    </tr>
  </tbody>
</table>
<p>364 rows × 4 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">calendar</span>

<span class="k">def</span> <span class="nf">print_bold</span><span class="p">(</span><span class="n">txt</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[1;46m&quot;</span> <span class="o">+</span> <span class="n">txt</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[0m&quot;</span><span class="p">)</span>

<span class="n">year</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">Year</span><span class="o">.</span><span class="n">unique</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">9.5</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    
    <span class="n">mean_temp_data</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">Month</span> <span class="o">==</span> <span class="n">m</span><span class="p">,</span> <span class="s1">&#39;Mean Temp (°C)&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

    <span class="c1"># Number of bootstrap samples</span>
    <span class="n">num_bootstraps</span> <span class="o">=</span> <span class="mi">1000</span>

    <span class="c1"># Initialize an array to store bootstrap sample means</span>
    <span class="n">bootstrap_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_bootstraps</span><span class="p">)</span>

    <span class="c1"># Perform bootstrapping</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_bootstraps</span><span class="p">):</span>
        <span class="n">bootstrap_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">mean_temp_data</span><span class="p">,</span>
                                            <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">mean_temp_data</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">bootstrap_means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">bootstrap_sample</span><span class="p">)</span>

    <span class="c1"># Calculate the 95% confidence interval for the mean</span>
    <span class="n">confidence_interval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">bootstrap_means</span><span class="p">,</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">97.5</span><span class="p">])</span>

    <span class="c1"># Plot the histogram of bootstrap sample means</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">bootstrap_means</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;LightCyan&#39;</span><span class="p">,</span> <span class="n">stat</span> <span class="o">=</span> <span class="s1">&#39;probability&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_temp_data</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">lw</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Original Mean&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">bootstrap_means</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">lw</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Bootstrap Mean&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">confidence_interval</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">lw</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;95% CI Lower&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">confidence_interval</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">lw</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;95% CI Upper&#39;</span><span class="p">)</span>

    <span class="c1"># Set various plot settings in one call</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span> <span class="o">=</span> <span class="s2">&quot;Mean Monthly Temp (°C)&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Probability&quot;</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">calendar</span><span class="o">.</span><span class="n">month_name</span><span class="p">[</span><span class="n">m</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">print_bold</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="si">{</span><span class="n">calendar</span><span class="o">.</span><span class="n">month_name</span><span class="p">[</span><span class="n">m</span><span class="p">]</span><span class="si">}</span><span class="s1">:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Original Mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_temp_data</span><span class="p">)</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">Bootstrap Mean </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">bootstrap_means</span><span class="p">)</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">95% Confidence Interval: [</span><span class="si">{</span><span class="n">confidence_interval</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">confidence_interval</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Bootstrapped Mean Monthly Temperature (°C) Distribution&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">weight</span> <span class="o">=</span> <span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
<span class=" -Color -Color-Bold -Color-Bold-BGCyan">January:</span>
	Original Mean: -5.67419
	Bootstrap Mean -5.72667
	95% Confidence Interval: [-9.44548, -2.27081]

<span class=" -Color -Color-Bold -Color-Bold-BGCyan">February:</span>
	Original Mean: -4.77143
	Bootstrap Mean -4.82502
	95% Confidence Interval: [-8.23768, -1.37661]

<span class=" -Color -Color-Bold -Color-Bold-BGCyan">March:</span>
	Original Mean: 0.08710
	Bootstrap Mean 0.08042
	95% Confidence Interval: [-2.05161, 2.10984]

<span class=" -Color -Color-Bold -Color-Bold-BGCyan">April:</span>
	Original Mean: 1.74333
	Bootstrap Mean 1.71917
	95% Confidence Interval: [-0.40675, 3.68675]

<span class=" -Color -Color-Bold -Color-Bold-BGCyan">May:</span>
	Original Mean: 9.30968
	Bootstrap Mean 9.29412
	95% Confidence Interval: [8.19669, 10.35500]

<span class=" -Color -Color-Bold -Color-Bold-BGCyan">June:</span>
	Original Mean: 13.73333
	Bootstrap Mean 13.72767
	95% Confidence Interval: [12.98292, 14.40333]

<span class=" -Color -Color-Bold -Color-Bold-BGCyan">July:</span>
	Original Mean: 18.01935
	Bootstrap Mean 18.00699
	95% Confidence Interval: [16.99960, 18.94540]

<span class=" -Color -Color-Bold -Color-Bold-BGCyan">August:</span>
	Original Mean: 19.18387
	Bootstrap Mean 19.18258
	95% Confidence Interval: [18.26750, 20.04847]

<span class=" -Color -Color-Bold -Color-Bold-BGCyan">September:</span>
	Original Mean: 14.43333
	Bootstrap Mean 14.45491
	95% Confidence Interval: [12.97300, 15.84058]

<span class=" -Color -Color-Bold -Color-Bold-BGCyan">October:</span>
	Original Mean: 8.59355
	Bootstrap Mean 8.56779
	95% Confidence Interval: [6.84758, 10.19710]

<span class=" -Color -Color-Bold -Color-Bold-BGCyan">November:</span>
	Original Mean: -6.44483
	Bootstrap Mean -6.43098
	95% Confidence Interval: [-9.05172, -3.89621]

<span class=" -Color -Color-Bold -Color-Bold-BGCyan">December:</span>
	Original Mean: -12.24839
	Bootstrap Mean -12.23658
	95% Confidence Interval: [-15.52919, -9.03161]
</pre></div>
</div>
<img alt="../_images/f4d91d945908a61b6919efb143d1cd489ba213149fbda876d028586917cb8908.png" src="../_images/f4d91d945908a61b6919efb143d1cd489ba213149fbda876d028586917cb8908.png" />
</div>
</div>
<p>The results show the mean monthly temperature of Calgary in each month, calculated from the original data and from the bootstrap samples. The bootstrap samples are obtained by randomly drawing observations from the original data with replacement, and repeating this process many times. The bootstrap mean is the average of the bootstrap sample means, and the 95% confidence interval is the range of values that contains 95% of the bootstrap sample means. The confidence interval gives us an estimate of how much the mean monthly temperature can vary due to sampling error.</p>
<p>The updated results also show that the original mean and the bootstrap mean are very close to each other in each month, which means that the original data is representative of the population and the bootstrap technique is reliable. The confidence intervals are also relatively narrow, which means that the uncertainty of the mean monthly temperature is low. However, the confidence intervals also show that the mean monthly temperature can be quite different from the original mean in some months, especially in the winter months. For example, in December, the original mean is -12.24839, but the 95% confidence interval is [-15.52919, -9.03161], which means that the mean monthly temperature can be as low as -15.52919 or as high as -9.03161 with 95% probability.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_09"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="ENGG_680_C09S5.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">9.5. </span>K-Nearest Neighbors (K-NN)</p>
      </div>
    </a>
    <a class="right-next"
       href="ENGG_680_C09S7.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">9.7. </span>Support Vector Machines</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation-cv">9.6.1. Cross-Validation (CV)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#leave-one-out-cross-validation-loocv">9.6.1.1. Leave-One-Out Cross-Validation (LOOCV)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bootstrap-method">9.6.2. Bootstrap Method</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hatef Dastour
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>