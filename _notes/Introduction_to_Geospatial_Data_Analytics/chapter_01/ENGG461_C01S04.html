
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>1.4. Spatial Resolution &#8212; Introduction to Geospatial Data Analytics</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css?v=564be945" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_01/ENGG461_C01S04';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1.5. Spectral Resolution" href="ENGG461_C01S05.html" />
    <link rel="prev" title="1.3. Radiometric Resolution" href="ENGG461_C01S03.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../Preface.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Introduction to Geospatial Data Analytics - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Introduction to Geospatial Data Analytics - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="ENGG461_C01.html">1. An Overview to Remote Sensing</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ENGG461_C01S01.html">1.1. The Integration of GIS, RS, and GPS</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG461_C01S02.html">1.2. What is Remote Sensing?</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG461_C01S03.html">1.3. Radiometric Resolution</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">1.4. Spatial Resolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG461_C01S05.html">1.5. Spectral Resolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG461_C01S06.html">1.6. Temporal Resolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="ENGG461_C01S07.html">1.7. Understanding Remote Sensing Images</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_02/ENGG461_C02.html">2. Fundamentals of Geospatial Data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG461_C02S01.html">2.1. Introduction to GIS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG461_C02S02.html">2.2. Basic Definitions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG461_C02S03.html">2.3. Understanding Coordinate Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG461_C02S04.html">2.4. Map Projections</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG461_C02S05.html">2.5. Cylindrical Projections</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG461_C02S06.html">2.6. Conic Projections</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/ENGG461_C02S07.html">2.7. Azimuthal Projections</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_03/ENGG461_C03.html">3. Framework for Spatial Data Science</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/ENGG461_C03S02.html">3.1. Understanding Geospatial Data</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../References.html">4. References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Spatial Resolution</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#field-of-view-fov-and-instantaneous-field-of-view-ifov">1.4.1. Field of View (FOV) and Instantaneous Field of View (IFOV)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#field-of-view-fov">1.4.1.1. Field of View (FOV)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#instantaneous-field-of-view-ifov">1.4.1.2. Instantaneous Field of View (IFOV)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#importance-of-spatial-resolution-in-remote-sensing">1.4.2. Importance of Spatial Resolution in Remote Sensing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-spatial-resolution-should-we-use">1.4.3. What Spatial Resolution Should We Use?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#swaths-the-breadth-of-earth-observation">1.4.4. Swaths: The Breadth of Earth Observation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#importance-of-swath-width">1.4.5. Importance of Swath Width</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="important admonition">
<p class="admonition-title">Remark</p>
<p>Please be aware that these lecture notes are accessible online in an ‘<strong>early access</strong>’ format. They are actively being developed, and certain sections will be further enriched to provide a comprehensive understanding of the subject matter.</p>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="spatial-resolution">
<span id="id1"></span><h1><span class="section-number">1.4. </span>Spatial Resolution<a class="headerlink" href="#spatial-resolution" title="Link to this heading">#</a></h1>
<p>Spatial resolution refers to the size of one pixel on the ground. A higher spatial resolution indicates more detail and a smaller area covered by each pixel <span id="id2">[<a class="reference internal" href="../References.html#id24" title="NASA Earth Science Data Systems. What is Remote Sensing? August 2019. Publisher: Earth Science Data Systems, NASA. URL: https://www.earthdata.nasa.gov/learn/backgrounders/remote-sensing (visited on 2024-06-21).">Earth Science Data Systems, 2019</a>]</span>.</p>
<p>Consider a patchwork quilt covering the ground, where each square of the quilt represents a pixel in an image. The <strong>spatial resolution</strong> is the size of these squares. Smaller squares (pixels) mean that the quilt (image) can show finer patterns and details. For instance, a high spatial resolution of <strong>30 centimeters</strong> per pixel allows us to distinguish between objects like cars and trees, while a lower resolution might only show larger features like buildings or fields.</p>
<p><a class="reference internal" href="#fieldview-fig"><span class="std std-numref">Fig. 1.11</span></a> illustrates the concept of spatial resolution in remote sensing <span id="id3">[<a class="reference internal" href="../References.html#id25" title="Natural Resources Canada. Remote Sensing Tutorials. September 2007. Last Modified: 2019-08-06 Publisher: Natural Resources Canada. URL: https://natural-resources.canada.ca/maps-tools-and-publications/satellite-imagery-elevation-data-and-air-photos/tutorial-fundamentals-remote-sensing/9309 (visited on 2024-01-21).">Natural Resources Canada, 2007</a>]</span>:</p>
<ul class="simple">
<li><p><strong>A - Instantaneous Field of View (IFOV)</strong>: This is the angular cone of visibility of the sensor, defining the area of the Earth’s surface visible from the sensor at any given moment. A smaller IFOV results in finer spatial resolution.</p></li>
<li><p><strong>B - Area on the Earth’s Surface (Spatial Resolution)</strong>: This shaded area represents the part of the Earth’s surface that falls within the IFOV, indicating the ground area the sensor can capture in an image at one time.</p></li>
<li><p><strong>C - Distance Between the Ground and Sensor</strong>: This is the altitude of the sensor above the Earth’s surface. The size of the resolution cell, which determines the maximum spatial resolution, is calculated by multiplying the IFOV by this distance.</p></li>
</ul>
<figure class="align-center" id="fieldview-fig">
<a class="reference internal image-reference" href="../_images/fieldview.png"><img alt="../_images/fieldview.png" src="../_images/fieldview.png" style="width: 300px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1.11 </span><span class="caption-text">The spatial resolution of the sensor is illustrated by the smallest detectable feature on the ground, represented by point A within the sensor’s field of view.
Image Credit: <span id="id4">[<a class="reference internal" href="../References.html#id25" title="Natural Resources Canada. Remote Sensing Tutorials. September 2007. Last Modified: 2019-08-06 Publisher: Natural Resources Canada. URL: https://natural-resources.canada.ca/maps-tools-and-publications/satellite-imagery-elevation-data-and-air-photos/tutorial-fundamentals-remote-sensing/9309 (visited on 2024-01-21).">Natural Resources Canada, 2007</a>]</span>. <a class="reference external" href="https://natural-resources.canada.ca/sites/nrcan/files/earthsciences/images/resource/tutor/fundam/images/fieldview.gif">Link to the image</a>.</span><a class="headerlink" href="#fieldview-fig" title="Link to this image">#</a></p>
</figcaption>
</figure>
<section id="field-of-view-fov-and-instantaneous-field-of-view-ifov">
<h2><span class="section-number">1.4.1. </span>Field of View (FOV) and Instantaneous Field of View (IFOV)<a class="headerlink" href="#field-of-view-fov-and-instantaneous-field-of-view-ifov" title="Link to this heading">#</a></h2>
<section id="field-of-view-fov">
<h3><span class="section-number">1.4.1.1. </span>Field of View (FOV)<a class="headerlink" href="#field-of-view-fov" title="Link to this heading">#</a></h3>
<p>The Field of View (FOV) is the angle of vision that the entire focal plane array (FPA) matrix covers from the objective’s second node <span id="id5">[<a class="reference internal" href="../References.html#id57" title="T. Pencheva, D. Pulov, B. Gyoch, and M. Nenkov. Design of CCD Optical System for Thermal IR Spectral Region. In 2006 29th International Spring Seminar on Electronics Technology, 173–178. 2006. ISSN: 2161-2064. doi:10.1109/ISSE.2006.365380.">Pencheva <em>et al.</em>, 2006</a>]</span>.</p>
<div class="math notranslate nohighlight" id="equation-eq-fov">
<span class="eqno">(1.2)<a class="headerlink" href="#equation-eq-fov" title="Link to this equation">#</a></span>\[FOV = \dfrac{a}{f} = \dfrac{A}{s}\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(a\)</span> = dimension of the FPA matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> = focal length of the objective</p></li>
<li><p><span class="math notranslate nohighlight">\(A\)</span> = dimension of the object</p></li>
<li><p><span class="math notranslate nohighlight">\(s\)</span> = distance to the object plane</p></li>
</ul>
<div class="warning admonition">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p><strong>Objective</strong>: The lens or optical system that focuses light onto the FPA detector.</p></li>
<li><p><strong>Object</strong>: The target or scene being observed or imaged.</p></li>
<li><p><strong>FPA Detector</strong>: The focal plane array, a sensor matrix that captures the image formed by the objective.</p></li>
</ul>
</div>
</section>
<section id="instantaneous-field-of-view-ifov">
<h3><span class="section-number">1.4.1.2. </span>Instantaneous Field of View (IFOV)<a class="headerlink" href="#instantaneous-field-of-view-ifov" title="Link to this heading">#</a></h3>
<p>The Instantaneous Field of View (IFOV) is the angle of vision of a single pixel of the photo-receiving matrix from the objective’s second node <span id="id6">[<a class="reference internal" href="../References.html#id57" title="T. Pencheva, D. Pulov, B. Gyoch, and M. Nenkov. Design of CCD Optical System for Thermal IR Spectral Region. In 2006 29th International Spring Seminar on Electronics Technology, 173–178. 2006. ISSN: 2161-2064. doi:10.1109/ISSE.2006.365380.">Pencheva <em>et al.</em>, 2006</a>]</span>.</p>
<div class="math notranslate nohighlight" id="equation-eq-ifov">
<span class="eqno">(1.3)<a class="headerlink" href="#equation-eq-ifov" title="Link to this equation">#</a></span>\[IFOV = \dfrac{\delta a}{f} = \dfrac{\delta A}{s}\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\delta a\)</span> = dimension of one pixel of the FPA matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\delta A\)</span> = projection size of one pixel on the object plane</p></li>
</ul>
<p>These equations help determine the resolution and field of vision for infrared optical systems.</p>
<p>Moreover, <a class="reference internal" href="#field-of-view-fig"><span class="std std-numref">Fig. 1.12</span></a> illustrates the <strong>Field of View (FOV) and Instantaneous Field of View (IFOV)</strong> for an optical system:</p>
<ul class="simple">
<li><p><strong>Field of View (FOV)</strong>: This is the angle of vision of the entire focal plane array (FPA) matrix from the objective’s second node <span id="id7">[<a class="reference internal" href="../References.html#id57" title="T. Pencheva, D. Pulov, B. Gyoch, and M. Nenkov. Design of CCD Optical System for Thermal IR Spectral Region. In 2006 29th International Spring Seminar on Electronics Technology, 173–178. 2006. ISSN: 2161-2064. doi:10.1109/ISSE.2006.365380.">Pencheva <em>et al.</em>, 2006</a>]</span>. It is calculated as <span class="math notranslate nohighlight">\(FOV = a / f = A / s\)</span>, where <span class="math notranslate nohighlight">\(a\)</span> is the dimension of the FPA, <span class="math notranslate nohighlight">\(f\)</span> is the focal length, <span class="math notranslate nohighlight">\(A\)</span> is the image dimension, and <span class="math notranslate nohighlight">\(s\)</span> is the distance to the object plane.</p></li>
<li><p><strong>Instantaneous Field of View (IFOV)</strong>: This is the angle of vision of a single pixel of the photo-receiving matrix from the objective’s second node <span id="id8">[<a class="reference internal" href="../References.html#id57" title="T. Pencheva, D. Pulov, B. Gyoch, and M. Nenkov. Design of CCD Optical System for Thermal IR Spectral Region. In 2006 29th International Spring Seminar on Electronics Technology, 173–178. 2006. ISSN: 2161-2064. doi:10.1109/ISSE.2006.365380.">Pencheva <em>et al.</em>, 2006</a>]</span>. It is calculated as <span class="math notranslate nohighlight">\(IFOV = \delta a / f = \delta A / s\)</span>, where <span class="math notranslate nohighlight">\(\delta a\)</span> is the dimension of one pixel.</p></li>
</ul>
<p>These parameters help determine the resolution and quality of the infrared imaging system.</p>
<figure class="align-center" id="field-of-view-fig">
<a class="reference internal image-reference" href="../_images/field_of_view.jpg"><img alt="../_images/field_of_view.jpg" src="../_images/field_of_view.jpg" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1.12 </span><span class="caption-text">The spatial resolution of the sensor is illustrated by the smallest detectable feature on the ground, represented by point A within the sensor’s field of view.
Image reproduced based on the idea presented in <span id="id9">[<a class="reference internal" href="../References.html#id57" title="T. Pencheva, D. Pulov, B. Gyoch, and M. Nenkov. Design of CCD Optical System for Thermal IR Spectral Region. In 2006 29th International Spring Seminar on Electronics Technology, 173–178. 2006. ISSN: 2161-2064. doi:10.1109/ISSE.2006.365380.">Pencheva <em>et al.</em>, 2006</a>]</span>.</span><a class="headerlink" href="#field-of-view-fig" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="proof example admonition" id="example1.4.0">
<p class="admonition-title"><span class="caption-number">Example 1.2 </span></p>
<section class="example-content" id="proof-content">
<p>Given Parameters</p>
<ul class="simple">
<li><p>Dimension of the FPA matrix (<span class="math notranslate nohighlight">\(a\)</span>): 20 mm</p></li>
<li><p>Focal length of the objective (<span class="math notranslate nohighlight">\(f\)</span>): 50 mm</p></li>
<li><p>Distance to the object plane (<span class="math notranslate nohighlight">\(s\)</span>): 1000 mm</p></li>
<li><p>Dimension of one pixel of the FPA matrix (<span class="math notranslate nohighlight">\(\delta a\)</span>): 0.02 mm</p></li>
</ul>
<p><strong>Field of View (FOV):</strong>
Using the formula <a class="reference internal" href="#equation-eq-fov">(1.2)</a>, and substituting the given values:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
FOV = \dfrac{20 \, \text{mm}}{50 \, \text{mm}} = 0.4
\end{equation*}\]</div>
<p>This means the FOV is 0.4 radians.</p>
<p><strong>Instantaneous Field of View (IFOV):</strong>
Using the formula <a class="reference internal" href="#equation-eq-ifov">(1.3)</a>, and substituting the given values:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
IFOV = \dfrac{0.02 \, \text{mm}}{50 \, \text{mm}} = 0.0004
\end{equation*}\]</div>
<p>This means the IFOV is 0.0004 radians.</p>
<p><strong>Interpretation:</strong></p>
<ul class="simple">
<li><p>The FOV of the entire FPA matrix is 0.4 radians, which indicates the angle of vision covered by the entire sensor array.</p></li>
<li><p>The IFOV of a single pixel is 0.0004 radians, which indicates the angle of vision covered by a single pixel in the sensor array.</p></li>
</ul>
</section>
</div></section>
</section>
<section id="importance-of-spatial-resolution-in-remote-sensing">
<h2><span class="section-number">1.4.2. </span>Importance of Spatial Resolution in Remote Sensing<a class="headerlink" href="#importance-of-spatial-resolution-in-remote-sensing" title="Link to this heading">#</a></h2>
<p>Spatial resolution measures the smallest feature a sensor can detect. The IFOV and the sensor’s altitude work together to define the resolution cell, the smallest area on the ground that can be resolved. If a feature is larger than the resolution cell, it can be detected; if it is smaller, it may not be distinguishable unless it has a dominant reflectance that allows for sub-pixel detection. This concept is crucial for understanding the capabilities and limitations of different remote sensing technologies.</p>
<p>Spatial resolution is critical in satellite imagery, determining how much detail is visible. For example, the Moderate Resolution Imaging Spectroradiometer (<a class="reference external" href="https://modis.gsfc.nasa.gov/">MODIS</a>) instruments on the Terra and Aqua satellites have bands with different resolutions:</p>
<ul class="simple">
<li><p><strong>1 km Resolution Bands</strong>: These bands are suited for observing large-scale environmental changes. Each pixel represents a 1 km² area on the ground, offering a broader view but with less detail.</p></li>
<li><p><strong>250 m and 500 m Resolution Bands</strong>: These higher-resolution bands capture smaller areas of 250 m² and 500 m² per pixel, respectively. They are ideal for detailed monitoring and mapping of smaller regions.</p></li>
</ul>
<p>The difference in detail is evident when comparing images with varying resolutions:</p>
<ul class="simple">
<li><p>A <strong>30 m/pixel</strong> resolution image shows fine details with little to no pixelation.</p></li>
<li><p>At <strong>100 m/pixel</strong>, the image is less detailed, and objects become harder to distinguish.</p></li>
<li><p>At <strong>300 m/pixel</strong>, the image is quite pixelated, suitable only for identifying large features.</p></li>
</ul>
<div class="proof example admonition" id="example1.4.1">
<p class="admonition-title"><span class="caption-number">Example 1.3 </span></p>
<section class="example-content" id="proof-content">
<p><a class="reference internal" href="#fig-landsat432-calgary"><span class="std std-numref">Fig. 1.13</span></a> provides a visual comparison of the city of Calgary using satellite imagery from the USGS Landsat 8 Level 2, Collection 2, Tier 1 dataset. Each panel represents the city at a different spatial resolution, demonstrating how the level of detail changes with varying pixel sizes. The panels show the city at four different resolutions:</p>
<ul class="simple">
<li><p><strong>30 m/pixel</strong>: The highest resolution, where individual features such as roads, buildings, and vegetation patches are more discernible.</p></li>
<li><p><strong>100 m/pixel</strong>: A moderate resolution where some details are still visible, but finer features start to blur.</p></li>
<li><p><strong>300 m/pixel</strong>: Lower resolution, where urban features become less distinct.</p></li>
</ul>
<!-- - **1000 m/pixel**: The lowest resolution, where features are highly generalized and less detailed. -->
<figure class="align-center" id="fig-landsat432-calgary">
<img alt="../_images/Landsat432_Calgary.jpg" src="../_images/Landsat432_Calgary.jpg" />
<figcaption>
<p><span class="caption-number">Fig. 1.13 </span><span class="caption-text">Panels showing the city of Calgary using the Red, Green, and Blue bands from USGS <a class="reference external" href="https://www.usgs.gov/landsat-missions/landsat-collection-2-level-2-science-products">Landsat</a> 8 Level 2, Collection 2, Tier 1. The images are displayed at different spatial resolutions: 30 m/pixel, 100 m/pixel, and 300 m/pixel. Image processed by H. Dastour using Google Earth Engine. Note: JPG format for web display and the image processed by H. Dastour using Google Earth Engine.</span><a class="headerlink" href="#fig-landsat432-calgary" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>This figure effectively illustrates the impact of spatial resolution on satellite imagery and highlights the importance of selecting appropriate resolutions for different applications. Higher resolutions provide more detailed information, which is crucial for applications like urban planning, environmental monitoring, and geographical analysis.</p>
</section>
</div></section>
<section id="what-spatial-resolution-should-we-use">
<h2><span class="section-number">1.4.3. </span>What Spatial Resolution Should We Use?<a class="headerlink" href="#what-spatial-resolution-should-we-use" title="Link to this heading">#</a></h2>
<p><a class="reference internal" href="#fig-spatial-resolution-basics"><span class="std std-numref">Fig. 1.14</span></a> provides a visual guide to understanding spatial resolution in the context of Earth observation. It explains that spatial resolution is the area represented by a single pixel in an image, with examples ranging from coarse to fine resolutions <span id="id10">[<a class="reference internal" href="../References.html#id24" title="NASA Earth Science Data Systems. What is Remote Sensing? August 2019. Publisher: Earth Science Data Systems, NASA. URL: https://www.earthdata.nasa.gov/learn/backgrounders/remote-sensing (visited on 2024-06-21).">Earth Science Data Systems, 2019</a>]</span>:</p>
<ul class="simple">
<li><p><strong>Lowest/Coarse (110 km / 1 degree)</strong>: Suitable for global observations, this resolution provides a broad overview of Earth’s features but lacks detail.</p></li>
<li><p><strong>Continental (30 km / 0.25 degrees)</strong>: This resolution is appropriate for studying large-scale phenomena across continents.</p></li>
<li><p><strong>National (10 km / 0.09 degrees)</strong>: With more detail, this resolution is good for country-wide research, capturing features like large cities or natural parks.</p></li>
<li><p><strong>Regional (1 km)</strong>: This fine resolution allows for detailed studies of smaller areas, such as neighborhoods or specific ecosystems.</p></li>
</ul>
<p>The infographic emphasizes the importance of choosing the right spatial resolution for different scales of research, from global to regional studies.</p>
<figure class="align-center" id="fig-spatial-resolution-basics">
<img alt="../_images/Spatial-Resolution-Basics.jpeg" src="../_images/Spatial-Resolution-Basics.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 1.14 </span><span class="caption-text">A range of spatial resolutions available for common NASA sensor products, tailored for diverse research needs from local to global extents. <a class="reference external" href="https://www.earthdata.nasa.gov/s3fs-public/styles/large_full_968px_/public/2023-04/Spatial-Resolution-Basics.jpeg">Link to Image</a>.</span><a class="headerlink" href="#fig-spatial-resolution-basics" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="swaths-the-breadth-of-earth-observation">
<h2><span class="section-number">1.4.4. </span>Swaths: The Breadth of Earth Observation<a class="headerlink" href="#swaths-the-breadth-of-earth-observation" title="Link to this heading">#</a></h2>
<p>In remote sensing, “swath” refers to the segment of the Earth’s surface captured by a sensor aboard a satellite or aircraft in a single flyover. It’s comparable to the panoramic view from an airplane window—the swath is the visible strip of land below, representing the sensor’s field of vision during one orbit around the Earth <span id="id11">[<a class="reference internal" href="../References.html#id25" title="Natural Resources Canada. Remote Sensing Tutorials. September 2007. Last Modified: 2019-08-06 Publisher: Natural Resources Canada. URL: https://natural-resources.canada.ca/maps-tools-and-publications/satellite-imagery-elevation-data-and-air-photos/tutorial-fundamentals-remote-sensing/9309 (visited on 2024-01-21).">Natural Resources Canada, 2007</a>]</span>.</p>
<!-- ```{figure} ../rs_figs/swath.png
---
width: 300px
align: center
---
A satellite orbiting the Earth, the swath would be the area on the Earth’s surface that the satellite is able to image during a single pass. Image Credit: {cite}`canada_remote_2007`. [Link to Image](https://natural-resources.canada.ca/sites/nrcan/files/earthsciences/images/resource/tutor/fundam/images/swath.gif)
``` -->
<figure class="align-center" id="id12">
<a class="reference internal image-reference" href="../_images/bandwidth.jpg"><img alt="../_images/bandwidth.jpg" src="../_images/bandwidth.jpg" style="width: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1.15 </span><span class="caption-text">A satellite orbiting the Earth, the swath would be the area on the Earth’s surface that the satellite is able to image during a single pass.</span><a class="headerlink" href="#id12" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The swath’s width is determined by two key factors:</p>
<ul class="simple">
<li><p><strong>Sensor’s Field of View (FOV)</strong>: The angular range within which the sensor can observe and collect data.</p></li>
<li><p><strong>Satellite’s Altitude</strong>: The height at which the satellite orbits the Earth.</p></li>
</ul>
<div class="proof example admonition" id="example1.4.2">
<p class="admonition-title"><span class="caption-number">Example 1.4 </span> (High vs. Low Swath Width)</p>
<section class="example-content" id="proof-content">
<ul class="simple">
<li><p><strong>Wide FOV and Low Earth Orbit (LEO)</strong>: A sensor with a wide FOV on an LEO satellite will have a larger swath, covering more ground with each pass.</p></li>
<li><p><strong>Narrow FOV and High Earth Orbit (HEO)</strong>: A sensor with a narrow FOV on a HEO satellite will have a smaller swath, covering less ground with each pass.</p></li>
</ul>
<p>The closer a satellite is to the Earth’s surface, the narrower the area it can image. Conversely, satellites at higher altitudes can cover wider areas.</p>
</section>
</div><p><a class="reference internal" href="#sw-fig"><span class="std std-numref">Fig. 1.16</span></a> illustrates the calculation of swath width <span class="math notranslate nohighlight">\(W\)</span> for a satellite sensor’s field of view using the following formula:</p>
<div class="math notranslate nohighlight" id="equation-sw-formula-eq">
<span class="eqno">(1.4)<a class="headerlink" href="#equation-sw-formula-eq" title="Link to this equation">#</a></span>\[ W = 2H \tan(\theta) \]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(H\)</span> is the altitude of the satellite above the Earth’s surface.</p></li>
<li><p><span class="math notranslate nohighlight">\(\theta\)</span> is the half-angle of the sensor’s field of view.</p></li>
</ul>
<figure class="align-center" id="sw-fig">
<a class="reference internal image-reference" href="../_images/sw_fig.jpg"><img alt="../_images/sw_fig.jpg" src="../_images/sw_fig.jpg" style="width: 300px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1.16 </span><span class="caption-text">Geometric illustration showing how swath width (<span class="math notranslate nohighlight">\(W\)</span>) is calculated from satellite altitude (<span class="math notranslate nohighlight">\(H\)</span>) and sensor half-angle field of view (<span class="math notranslate nohighlight">\(\theta\)</span>).</span><a class="headerlink" href="#sw-fig" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Explanation:</strong></p>
<ol class="arabic simple">
<li><p><strong>Altitude (<span class="math notranslate nohighlight">\(H\)</span>)</strong>: This is the height of the satellite above the Earth’s surface. For example, if a satellite is at an altitude of 500 km, <span class="math notranslate nohighlight">\(H = 500 \)</span> km.</p></li>
<li><p><strong>Field of View Angle (<span class="math notranslate nohighlight">\(2\theta\)</span>)</strong>: The total viewing angle of the sensor. For instance, if the sensor has a full field of view angle of 136 degrees, the half-angle <span class="math notranslate nohighlight">\(\theta\)</span> would be 68 degrees.</p></li>
</ol>
<div class="proof example admonition" id="example1.4.3">
<p class="admonition-title"><span class="caption-number">Example 1.5 </span></p>
<section class="example-content" id="proof-content">
<p>Suppose a satellite is at an altitude of 833 km and the sensor’s half-angle of the field of view ($\theta) is 60°.</p>
<p>Using the formula <a class="reference internal" href="#equation-sw-formula-eq">(1.4)</a></p>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(W\)</span> is the swath width</p></li>
<li><p><span class="math notranslate nohighlight">\(H\)</span> is the satellite altitude (833 km)</p></li>
<li><p><span class="math notranslate nohighlight">\(θ\)</span> is the half-angle of the field of view (60°)</p></li>
</ul>
<p>Calculation:
<span class="math notranslate nohighlight">\(W = 2 \times 833 \times \tan(60°) = 1666 \times 1.73 ≈ 2885.60\)</span> km</p>
<p>Thus, for a satellite at 833 km altitude with a sensor half-angle of 60°, the swath width would be approximately 2886 km.</p>
</section>
</div><p><strong>Additional Considerations:</strong></p>
<ul class="simple">
<li><p><strong>Geometrical Properties</strong>: The swath width can vary based on the geometrical properties of the satellite’s orbit and the sensor’s design.</p></li>
<li><p><strong>Resolution</strong>: The swath width also affects the spatial resolution of the images captured. A wider swath generally means lower spatial resolution and vice versa.</p></li>
</ul>
<p>This formula and explanation provide a basic understanding of how to calculate the swath width of a satellite based on its altitude and sensor characteristics.</p>
</section>
<section id="importance-of-swath-width">
<h2><span class="section-number">1.4.5. </span>Importance of Swath Width<a class="headerlink" href="#importance-of-swath-width" title="Link to this heading">#</a></h2>
<p>Swath size is crucial in remote sensing as it affects:</p>
<ul class="simple">
<li><p>The <strong>extent</strong> of the Earth’s surface that can be imaged.</p></li>
<li><p>The <strong>frequency</strong> at which a specific location is revisited, which is tied to the concept of <strong>temporal resolution</strong>.</p></li>
</ul>
<p>A larger swath enables satellites to map extensive areas more quickly, which is vital in the design and application of remote sensing technologies. Understanding swath dimensions is key to planning thorough and regular imaging of particular areas.</p>
<p><a class="reference internal" href="#figure-landsatmodis"><span class="std std-numref">Fig. 1.17</span></a> compares the orbital swath coverage of two different Earth observation instruments:</p>
<ul class="simple">
<li><p><strong>MODIS (Moderate Resolution Imaging Spectroradiometer)</strong>: Illustrated by blue boxes, <a class="reference external" href="https://www.earthdata.nasa.gov/sensors/modis">MODIS</a> boasts a considerably wider imaging swath, enabling it to cover a larger portion of the Earth’s surface per pass and provide global coverage every 1-2 days.</p></li>
<li><p><strong>OLI (Operational Land Imager) aboard Landsat 8</strong>: Displayed as boxes with red dots, the OLI has a narrower swath than MODIS, leading to a longer interval, approximately 16 days, to achieve global coverage.</p></li>
</ul>
<figure class="align-center" id="figure-landsatmodis">
<a class="reference internal image-reference" href="../_images/landsatmodis.png"><img alt="../_images/landsatmodis.png" src="../_images/landsatmodis.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1.17 </span><span class="caption-text">Orbital swath of MODIS (blue boxes) versus the orbital swath of the OLI aboard Landsat 8 (boxes with red dots). Due to its much wider imaging swath, MODIS provides global coverage every 1-2 days versus 16 days for the OLI. Red dots indicate the center point of each Landsat tile. Image Credit: NASA Applied Remote Sensing Training (ARSET). <a class="reference external" href="https://www.earthdata.nasa.gov/s3fs-public/styles/medium_half_480px_/public/imported/passive.png">Link to Image</a></span><a class="headerlink" href="#figure-landsatmodis" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><a class="reference internal" href="#figure-landsatmodis"><span class="std std-numref">Fig. 1.17</span></a> effectively demonstrates the impact of swath width on the temporal resolution of satellite imagery. A wider swath, like that of MODIS, enables more frequent revisits to the same location on Earth, which is beneficial for monitoring changes over time. In contrast, the narrower swath of OLI results in less frequent coverage but can provide higher spatial resolution imagery.</p>
<p>For example, MODIS is ideal for tracking large-scale environmental changes such as deforestation and urban expansion due to its frequent coverage. Meanwhile, OLI is suitable for detailed analysis of smaller areas with high spatial resolution, such as monitoring crop health or urban infrastructure.</p>
<!-- ## Earth Coverage

To calculate Earth coverage, we need to consider the swath width in relation to the Earth's circumference. The number of orbits required for full Earth coverage can be estimated using:

\begin{equation}
 N = \dfrac{2\pi R_e}{W \cos(i)} 
\end{equation}

Where:
- $N$ is the number of orbits for full coverage.
- $R_e$ is the Earth's radius.
- $W$ is the swath width.
- $i$ is the inclination of the orbit.

**Additional Considerations:**

1. **Earth's Curvature**: For more accurate calculations, especially for wider swaths, the Earth's curvature should be taken into account.
2. **Orbit Characteristics**: The satellite's orbit (e.g., sun-synchronous, polar) affects coverage patterns.
3. **Sensor Type**: Different sensors (e.g., push-broom, whisk-broom) may have varying swath characteristics.
4. **Overlap**: Some degree of overlap between adjacent swaths is often desired for complete coverage.
5. **Ground Sampling Distance (GSD)**: This is related to the spatial resolution and can affect the effective swath width. --></section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_01"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="ENGG461_C01S03.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1.3. </span>Radiometric Resolution</p>
      </div>
    </a>
    <a class="right-next"
       href="ENGG461_C01S05.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">1.5. </span>Spectral Resolution</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#field-of-view-fov-and-instantaneous-field-of-view-ifov">1.4.1. Field of View (FOV) and Instantaneous Field of View (IFOV)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#field-of-view-fov">1.4.1.1. Field of View (FOV)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#instantaneous-field-of-view-ifov">1.4.1.2. Instantaneous Field of View (IFOV)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#importance-of-spatial-resolution-in-remote-sensing">1.4.2. Importance of Spatial Resolution in Remote Sensing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-spatial-resolution-should-we-use">1.4.3. What Spatial Resolution Should We Use?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#swaths-the-breadth-of-earth-observation">1.4.4. Swaths: The Breadth of Earth Observation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#importance-of-swath-width">1.4.5. Importance of Swath Width</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hatef Dastour
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>