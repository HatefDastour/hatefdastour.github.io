
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>1. Part 1: Understanding Large Language Models &#8212; AI Foundations for Graduate Research Excellence</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css?v=564be945" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notes/understanding_large_language_models';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Part 2: Prompt Engineering Fundamentals" href="prompt_engineering_fundamentals.html" />
    <link rel="prev" title="Workshop Overview" href="../Preface.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../Preface.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="AI Foundations for Graduate Research Excellence - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="AI Foundations for Graduate Research Excellence - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">1. Part 1: Understanding Large Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="prompt_engineering_fundamentals.html">2. Part 2: Prompt Engineering Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_prompting_techniques.html">3. Part 3: Advanced Prompting Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="research_applications.html">4. Part 4: Research Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="mini_lab_and_practical_application.html">5. Part 5: Mini-Lab and Practical Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="specialized_tools_and_resources.html">6. Part 6: Specialized Tools and Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethical_considerations_and_best_practices.html">7. Part 7: Ethical Considerations and Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix1.html">8. Appendix 1: Prompt Template Library</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix2.html">9. Appendix 2: Glossary of Key Terms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../References.html">10. References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Part 1: Understanding Large Language Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-are-large-language-models">1.1. What Are Large Language Models?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-exercise-you-be-the-model">1.2. Interactive Exercise: You Be the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tokens-tokenization-the-foundation">1.3. Tokens &amp; Tokenization: The Foundation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-llms-work-the-generation-pipeline">1.4. How LLMs Work: The Generation Pipeline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-capability-efficiency">1.5. Model Capability &amp; Efficiency</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parameters-the-laptop-specs-analogy">1.5.1. Parameters: The ‚ÄúLaptop Specs‚Äù Analogy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantization-the-camera-megapixel-analogy">1.5.2. Quantization: The ‚ÄúCamera Megapixel‚Äù Analogy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-context-window-active-memory-limits">1.6. The Context Window: ‚ÄúActive Memory‚Äù Limits</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-digital-desk-concept">1.6.1. The ‚ÄúDigital Desk‚Äù Concept</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-working-beyond-context-limits">1.7. Exercise: Working Beyond Context Limits</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="part-1-understanding-large-language-models">
<h1><span class="section-number">1. </span>Part 1: Understanding Large Language Models<a class="headerlink" href="#part-1-understanding-large-language-models" title="Link to this heading">#</a></h1>
<div class="note admonition">
<p class="admonition-title">Learning Objectives</p>
<p>By the end of this section, you will be able to:</p>
<ol class="arabic simple">
<li><p>Explain how LLMs generate text through probability-based token prediction</p></li>
<li><p>Calculate approximate token counts for research documents</p></li>
<li><p>Design prompts that respect context window limitations</p></li>
<li><p>Identify when to use quantized vs. full-precision models</p></li>
<li><p>Develop strategies for working within context window constraints</p></li>
</ol>
</div>
<section id="what-are-large-language-models">
<h2><span class="section-number">1.1. </span>What Are Large Language Models?<a class="headerlink" href="#what-are-large-language-models" title="Link to this heading">#</a></h2>
<div class="tip admonition">
<p class="admonition-title">Definition ‚Äì Large Language Models (LLMs)</p>
<p><strong>Large Language Models (LLMs)</strong> are neural networks trained on massive text datasets (billions of words) that predict the next word based on context‚Äîrepeatedly <span id="id1">[<a class="reference internal" href="../References.html#id2" title="Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D. Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language Models are Few-Shot Learners. Advances in Neural Information Processing Systems, 33:1877‚Äì1901, 2020. URL: https://proceedings.neurips.cc/paper_files/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html (visited on 2026-02-11).">Brown <em>et al.</em>, 2020</a>]</span>. They can perform diverse tasks without task-specific training through a process called ‚Äúin-context learning.‚Äù</p>
</div>
<div class="proof example admonition" id="example_01">
<p class="admonition-title"><span class="caption-number">Example 1.1 </span> (Early 2026 Examples)</p>
<section class="example-content" id="proof-content">
<ul class="simple">
<li><p><a href="https://openai.com/index/introducing-gpt-5-2/" target="_blank" rel="noopener">OpenAI‚Äôs GPT-5.2</a></p></li>
<li><p><a href="https://claude.ai/new" target="_blank" rel="noopener">Anthropic‚Äôs Claude</a></p></li>
<li><p><a href="https://deepmind.google/models/gemini/pro/" target="_blank" rel="noopener">Google Gemini 3 Pro</a></p></li>
<li><p><a href="https://x.ai/" target="_blank" rel="noopener">xAI‚Äôs Grok-4.1</a></p></li>
<li><p><a href="https://www.microsoft.com/en-us/microsoft-365-copilot" target="_blank" rel="noopener">Microsoft 365 Copilot</a></p></li>
<li><p><a href="https://ai.meta.com/blog/" target="_blank" rel="noopener">Meta‚Äôs Llama 4</a></p></li>
</ul>
</section>
</div><div class="warning admonition">
<p class="admonition-title">Note</p>
<p>LLMs don‚Äôt ‚Äúunderstand‚Äù language‚Äîthey predict the most likely next token based on probability and proximity in embedding space <span id="id2">[<a class="reference internal" href="../References.html#id3" title="Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Jill Burstein, Christy Doran, and Thamar Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 4171‚Äì4186. Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi:10.18653/v1/N19-1423.">Devlin <em>et al.</em>, 2019</a>]</span>. This fundamental difference from human comprehension has important implications for research applications.</p>
</div>
</section>
<section id="interactive-exercise-you-be-the-model">
<h2><span class="section-number">1.2. </span>Interactive Exercise: You Be the Model<a class="headerlink" href="#interactive-exercise-you-be-the-model" title="Link to this heading">#</a></h2>
<p>Understanding how LLMs work becomes clearer through hands-on experience.</p>
<!-- **‚è±Ô∏è Time:** 5 minutes | **üìä Difficulty:** Beginner | **üéØ Skills:** Pattern recognition, probability thinking -->
<p><strong>Objective:</strong> Internalize LLM mechanics through experiential learning.</p>
<p><strong>Activity:</strong></p>
<ol class="arabic simple">
<li><p>Present: <em>‚ÄúThe capital of Northern Ireland is ____‚Äù</em></p></li>
<li><p>Students write down:</p>
<ul class="simple">
<li><p>Top 3 predictions</p></li>
<li><p>Assign probability (%) to each</p></li>
<li><p>Compare with neighbor</p></li>
</ul>
</li>
</ol>
<p><strong>Discussion Questions:</strong></p>
<ul class="simple">
<li><p>What made you confident in your answer?</p></li>
<li><p>How did you assign probabilities?</p></li>
<li><p>What if you‚Äôd never heard of Northern Ireland?</p></li>
</ul>
<div class="warning admonition">
<p class="admonition-title">Note</p>
<p>Your brain just performed pattern matching based on prior knowledge‚Äîexactly what an LLM does, but with billions of training examples rather than personal experience.</p>
</div>
<div class="sd-card sd-sphinx-override sd-mb-3 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
üéØ Checkpoint</div>
<p class="sd-card-text">Before continuing, make sure you understand:</p>
<ul class="simple">
<li><p class="sd-card-text">[ ] LLMs predict tokens, not ‚Äúunderstand‚Äù meaning</p></li>
<li><p class="sd-card-text">[ ] Predictions are based on probability from training data</p></li>
<li><p class="sd-card-text">[ ] Pattern matching is the core mechanism</p></li>
</ul>
</div>
</div>
</section>
<section id="tokens-tokenization-the-foundation">
<h2><span class="section-number">1.3. </span>Tokens &amp; Tokenization: The Foundation<a class="headerlink" href="#tokens-tokenization-the-foundation" title="Link to this heading">#</a></h2>
<p>Before diving deeper into how LLMs work, we need to understand their basic unit of processing.</p>
<div class="tip admonition">
<p class="admonition-title">Definition ‚Äì Tokens</p>
<p><strong>Tokens</strong> are the basic units of text that LLMs process. Words are broken into smaller pieces (subwords or characters) for processing.</p>
</div>
<div class="proof example admonition" id="example_02">
<p class="admonition-title"><span class="caption-number">Example 1.2 </span> (Token Examples)</p>
<section class="example-content" id="proof-content">
<ul class="simple">
<li><p>‚ÄúHello‚Äù = 1 token</p></li>
<li><p>‚ÄúChatGPT‚Äù = 2 tokens (‚ÄúChat‚Äù + ‚ÄúGPT‚Äù)</p></li>
<li><p>‚Äúartificial intelligence‚Äù = 2-3 tokens depending on model</p></li>
<li><p>Average ratio: ~0.75 words per token</p></li>
</ul>
<p><strong>Practical Resource:</strong> <a href="https://platform.openai.com/tokenizer" target="_blank" rel="noopener">OpenAI Tokenizer Tool</a></p>
</section>
</div><p><strong>Why This Matters for Research:</strong></p>
<ol class="arabic simple">
<li><p><strong>Cost:</strong> Most LLM APIs charge per token</p></li>
<li><p><strong>Context Limits:</strong> Token counts determine what fits in context</p></li>
<li><p><strong>Precision:</strong> Understanding tokenization improves prompt efficiency</p></li>
</ol>
</section>
<section id="how-llms-work-the-generation-pipeline">
<h2><span class="section-number">1.4. </span>How LLMs Work: The Generation Pipeline<a class="headerlink" href="#how-llms-work-the-generation-pipeline" title="Link to this heading">#</a></h2>
<p>Now that we understand tokens, let‚Äôs see how models transform them into meaningful output.</p>
<div class="proof example admonition" id="example_03">
<p class="admonition-title"><span class="caption-number">Example 1.3 </span> (Generation Process)</p>
<section class="example-content" id="proof-content">
<p><strong>Example Demonstration:</strong></p>
<p><strong>Input:</strong> ‚ÄúThe capital of Canada is _____‚Äù</p>
<p><strong>Model Probabilities:</strong></p>
<ul class="simple">
<li><p>‚úì Ottawa: <strong>92%</strong></p></li>
<li><p>Toronto: 5%</p></li>
<li><p>Montreal: 2%</p></li>
<li><p>Maple Syrup: 0.001%</p></li>
</ul>
</section>
</div><figure class="align-center" id="simplified-llm-generation-pipeline">
<a class="reference internal image-reference" href="../_images/simplified_llm_generation_pipeline.png"><img alt="../_images/simplified_llm_generation_pipeline.png" src="../_images/simplified_llm_generation_pipeline.png" style="width: 500px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.1 </span><span class="caption-text">This flowchart illustrates the six-step technical process by which Large Language Models generate text. Starting with input tokenization, each step transforms the input sequentially through embedding, attention computation, probability calculation, token sampling, and iterative repetition until the desired output is complete.</span><a class="headerlink" href="#simplified-llm-generation-pipeline" title="Link to this image">#</a></p>
</figcaption>
</figure>
<!-- **Technical Process (Simplified):**

1. **Tokenization:** Input text ‚Üí tokens
2. **Embedding:** Tokens ‚Üí high-dimensional vectors (capturing semantic meaning)
3. **Attention Mechanism:** Model weighs importance of each token relative to others
4. **Probability Distribution:** Calculates probability for every token in vocabulary
5. **Sampling:** Selects next token (usually highest probability, with some randomness)
6. **Repeat:** New token added to context, process repeats -->
<div class="warning admonition">
<p class="admonition-title">Note</p>
<p>The model doesn‚Äôt look up ‚Äúcapital of Canada‚Äù in a database. Instead, it calculates that given the pattern ‚ÄúThe capital of [Country] is‚Äù, and given billions of examples where ‚ÄúOttawa‚Äù appeared after ‚ÄúThe capital of Canada is‚Äù, the token ‚ÄúOttawa‚Äù has the highest probability of being next <span id="id3">[<a class="reference internal" href="../References.html#id6" title="OpenAI. Prompt engineering. https://developers.openai.com/api/docs/guides/prompt-engineering, 2026. Accessed: 2026-02-10.">OpenAI, 2026</a>]</span>.</p>
</div>
</section>
<section id="model-capability-efficiency">
<h2><span class="section-number">1.5. </span>Model Capability &amp; Efficiency<a class="headerlink" href="#model-capability-efficiency" title="Link to this heading">#</a></h2>
<p>Two key factors determine an LLM‚Äôs practical utility: its parameter count and how efficiently it runs.</p>
<section id="parameters-the-laptop-specs-analogy">
<h3><span class="section-number">1.5.1. </span>Parameters: The ‚ÄúLaptop Specs‚Äù Analogy<a class="headerlink" href="#parameters-the-laptop-specs-analogy" title="Link to this heading">#</a></h3>
<p><strong>Concept:</strong> Parameters are like the specs of a computer‚Äîmore powerful specs enable more complex operations.</p>
<ul class="simple">
<li><p><strong>70B parameter model</strong> = High-end workstation (powerful reasoning, nuanced understanding)</p></li>
<li><p><strong>7B parameter model</strong> = Standard notebook (good for many tasks, faster, more efficient)</p></li>
<li><p><strong>405B parameter model</strong> = Supercomputer cluster (exceptional capabilities, expensive to run)</p></li>
</ul>
<div class="proof example admonition" id="example_04">
<p class="admonition-title"><span class="caption-number">Example 1.4 </span> (Parameter Scale in Practice)</p>
<section class="example-content" id="proof-content">
<p>GPT-4 reportedly has ~1.76 trillion parameters, while smaller models like Llama 3-8B have 8 billion. More parameters generally mean better performance on complex reasoning tasks but require more computational resources <span id="id4">[<a class="reference internal" href="../References.html#id7" title="Anthropic. Prompt engineering overview. https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/overview, 2026. Accessed: 2026-02-10.">Anthropic, 2026</a>]</span>.</p>
</section>
</div><div class="danger admonition">
<p class="admonition-title">Common Mistake: Confusing Parameters with Performance</p>
<p>‚ùå <strong>Misconception:</strong> ‚ÄúMore parameters always means better output‚Äù</p>
<p>‚úì <strong>Reality:</strong> Larger models excel at complex reasoning but may be overkill for simple tasks. A 7B model often performs just as well as a 70B model for straightforward text summarization.</p>
<p><strong>Rule of Thumb:</strong> Start with smaller models; upgrade only if output quality suffers.</p>
</div>
</section>
<section id="quantization-the-camera-megapixel-analogy">
<h3><span class="section-number">1.5.2. </span>Quantization: The ‚ÄúCamera Megapixel‚Äù Analogy<a class="headerlink" href="#quantization-the-camera-megapixel-analogy" title="Link to this heading">#</a></h3>
<figure class="align-center" id="params-quantization">
<a class="reference internal image-reference" href="../_images/params_quantization.png"><img alt="../_images/params_quantization.png" src="../_images/params_quantization.png" style="width: 700px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.2 </span><span class="caption-text">The ‚ÄúCamera Megapixel‚Äù Analogy (image generated by Google Gemini).</span><a class="headerlink" href="#params-quantization" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Concept:</strong> Quantization reduces the precision of model weights to make them smaller and faster.</p>
<ul class="simple">
<li><p><strong>100MP (Original):</strong> Perfect detail, massive file size, requires supercomputer</p></li>
<li><p><strong>10MP (Quantized):</strong> Looks nearly identical, much smaller, runs on laptop</p></li>
</ul>
<p><strong>Technical Detail:</strong></p>
<ul class="simple">
<li><p>FP32 (full precision): 32 bits per parameter</p></li>
<li><p>INT8 (quantized): 8 bits per parameter</p></li>
<li><p>4-bit quantization: Aggressive compression, ~75% reduction in size</p></li>
</ul>
<div class="warning admonition">
<p class="admonition-title">The Trade-off</p>
<p>We sacrifice tiny amounts of precision for the ability to run world-class AI on standard research laptops. For most research tasks, quantized models perform nearly identically to full-precision versions <span id="id5">[<a class="reference internal" href="../References.html#id8" title="Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. QLoRA: Efficient Finetuning of Quantized LLMs. Advances in Neural Information Processing Systems, 36:10088‚Äì10115, December 2023. URL: https://proceedings.neurips.cc/paper_files/paper/2023/hash/1feb87871436031bdc0f2beaa62a049b-Abstract-Conference.html (visited on 2026-02-11).">Dettmers <em>et al.</em>, 2023</a>]</span>.</p>
</div>
<div class="sd-card sd-sphinx-override sd-mb-3 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
üéØ Checkpoint</div>
<p class="sd-card-text">Before continuing, make sure you understand:</p>
<ul class="simple">
<li><p class="sd-card-text">[ ] Parameters determine model capability</p></li>
<li><p class="sd-card-text">[ ] Quantization reduces size with minimal quality loss</p></li>
<li><p class="sd-card-text">[ ] Smaller models can be sufficient for many tasks</p></li>
</ul>
</div>
</div>
</section>
</section>
<section id="the-context-window-active-memory-limits">
<h2><span class="section-number">1.6. </span>The Context Window: ‚ÄúActive Memory‚Äù Limits<a class="headerlink" href="#the-context-window-active-memory-limits" title="Link to this heading">#</a></h2>
<p>Perhaps the most critical constraint for research applications is the context window‚Äîthe amount of information a model can actively process.</p>
<section id="the-digital-desk-concept">
<h3><span class="section-number">1.6.1. </span>The ‚ÄúDigital Desk‚Äù Concept<a class="headerlink" href="#the-digital-desk-concept" title="Link to this heading">#</a></h3>
<figure class="align-center" id="context-window">
<a class="reference internal image-reference" href="../_images/context_window.png"><img alt="../_images/context_window.png" src="../_images/context_window.png" style="width: 700px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.3 </span><span class="caption-text">The ‚ÄúDigital Desk‚Äù Concept (image generated by Google Gemini).</span><a class="headerlink" href="#context-window" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Analogy:</strong> The context window is like a physical desk:</p>
<ul class="simple">
<li><p><strong>Desk Size:</strong> Represents the model‚Äôs capacity to ‚Äúsee‚Äù and ‚Äúconnect‚Äù information</p></li>
<li><p><strong>Hard Cutoff:</strong> Once full, new data pushes old data out (FIFO - First In, First Out)</p></li>
<li><p><strong>Can‚Äôt See the Floor:</strong> The model can only work with what‚Äôs on the desk</p></li>
</ul>
<div class="full-width docutils">
<div class="pst-scrollable-table-container"><table class="table" id="table-01">
<caption><span class="caption-number">Table 1.1 </span><span class="caption-text">Context Window Comparison (Early 2026)</span><a class="headerlink" href="#table-01" title="Link to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head text-center"><p>AI Model Family</p></th>
<th class="head text-center"><p>Latest Model</p></th>
<th class="head text-center"><p>Context Window (Tokens)</p></th>
<th class="head text-center"><p>Word Estimate</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>OpenAI</p></td>
<td class="text-center"><p>GPT-5.3</p></td>
<td class="text-center"><p>400,000</p></td>
<td class="text-center"><p>~300,000 words</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>Anthropic</p></td>
<td class="text-center"><p>Claude 5 Sonnet</p></td>
<td class="text-center"><p>1,000,000</p></td>
<td class="text-center"><p>~750,000 words</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>Meta (Open)</p></td>
<td class="text-center"><p>Llama 4 Scout</p></td>
<td class="text-center"><p>10,000,000</p></td>
<td class="text-center"><p>~7,500,000 words</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>Mistral</p></td>
<td class="text-center"><p>Mistral Large 3</p></td>
<td class="text-center"><p>128,000</p></td>
<td class="text-center"><p>~96,000 words</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>Google</p></td>
<td class="text-center"><p>Gemini 3 Pro</p></td>
<td class="text-center"><p>2,000,000+</p></td>
<td class="text-center"><p>~1,500,000+ words</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong>Critical Research Limitations:</strong> While context windows have grown dramatically, significant limitations remain:</p>
<ol class="arabic simple">
<li><p><strong>Recall Decay:</strong> Even within context limits, models struggle with information buried in the middle (the ‚Äúlost in the middle‚Äù problem) <span id="id6">[<a class="reference internal" href="../References.html#id9" title="Zhenyu Zhang, Runjin Chen, Shiwei Liu, Zhewei Yao, Olatunji Ruwase, Beidi Chen, Xiaoxia Wu, and Zhangyang Wang. Found in the Middle: How Language Models Use Long Contexts Better via Plug-and-Play Positional Encoding. Advances in Neural Information Processing Systems, 37:60755‚Äì60775, December 2024. doi:10.52202/079017-1943.">Zhang <em>et al.</em>, 2024</a>]</span></p></li>
<li><p><strong>No External Memory:</strong> LLMs cannot access information outside their context window</p></li>
<li><p><strong>No Real-Time Search:</strong> They cannot look up current information unless explicitly provided</p></li>
</ol>
<div class="tip admonition">
<p class="admonition-title">The Research Solution</p>
<p>‚ùå <strong>The Trap:</strong> ‚ÄúReview all health-informatics articles‚Äù fails because:</p>
<ul class="simple">
<li><p>Models can‚Äôt access external databases</p></li>
<li><p>Even with large context, they can‚Äôt process thousands of papers</p></li>
<li><p>They only work with what you explicitly provide</p></li>
</ul>
<p>‚úÖ <strong>The Fix:</strong> Manually place specific, high-value papers in the context via your prompt:</p>
<ul class="simple">
<li><p>Upload PDFs of key papers</p></li>
<li><p>Paste abstracts directly</p></li>
<li><p>Provide structured summaries</p></li>
<li><p>Use chunking strategies for large documents</p></li>
</ul>
</div>
<div class="danger admonition">
<p class="admonition-title">Copyright &amp; Access Considerations</p>
<p>Keep in mind, generally speaking, we are <strong>not allowed</strong> to upload any PDF from any publisher to any proprietary chat LLM platform (e.g., ChatGPT, Google Gemini, etc.).</p>
<p><strong>Alternatives:</strong></p>
<ul class="simple">
<li><p>Use open-source offline models (e.g., Ollama with Llama)</p></li>
<li><p>Extract and paste only relevant sections (within fair use)</p></li>
<li><p>Use institutional LLM services with data protection agreements</p></li>
<li><p>Rely on abstracts from public databases (PubMed, arXiv)</p></li>
</ul>
</div>
</section>
</section>
<section id="exercise-working-beyond-context-limits">
<h2><span class="section-number">1.7. </span>Exercise: Working Beyond Context Limits<a class="headerlink" href="#exercise-working-beyond-context-limits" title="Link to this heading">#</a></h2>
<p>When your research task exceeds context limits, strategic planning becomes essential.</p>
<!-- **‚è±Ô∏è Time:** 8 minutes (5 min individual, 3 min pair-share) | **üìä Difficulty:** Intermediate | **üéØ Skills:** Strategic thinking, chunking strategies -->
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-0">
Scenario</label><div class="sd-tab-content docutils">
<p>You have 300 article abstracts and need to identify research themes.</p>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-1">
The Problem</label><div class="sd-tab-content docutils">
<ul class="simple">
<li><p>300 abstracts √ó ~200 words = ~60,000 words</p></li>
<li><p>Too large for reliable processing in one go</p></li>
<li><p>Risk of information loss and degradation</p></li>
</ul>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-2">
Student Task</label><div class="sd-tab-content docutils">
<p>Think through these questions:</p>
<ol class="arabic simple">
<li><p>How would you break this into smaller pieces?</p>
<ul class="simple">
<li><p>Process in batches? How many per batch?</p></li>
</ul>
</li>
<li><p>What would you ask the LLM to do at each step?</p>
<ul class="simple">
<li><p>Identify themes in each batch, then combine?</p></li>
<li><p>Something else?</p></li>
</ul>
</li>
<li><p>How would you handle overlaps or conflicts between batches?</p></li>
</ol>
<p><strong>Pair-Share:</strong> Compare approaches with neighbor.</p>
</div>
</div>
<div class="warning admonition">
<p class="admonition-title">Design Principle</p>
<p>When tasks exceed context limits, design multi-stage workflows rather than single prompts. Think of it as breaking a research paper into introduction, methods, results, and discussion‚Äîeach section is manageable, together they form a complete work <span id="id7">[<a class="reference internal" href="../References.html#id10" title="Stig Pedersen Korsholm. Mastering prompt engineering: a comparative guide to nine prompt engineering frameworks for tech professionals. https://www.linkedin.com/pulse/mastering-prompt-engineering-comparative-guide-nine-tech-korsholm-hnjif/, February 2024. Accessed: 2026-02-10.">Korsholm, 2024</a>]</span>.</p>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../Preface.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Workshop Overview</p>
      </div>
    </a>
    <a class="right-next"
       href="prompt_engineering_fundamentals.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2. </span>Part 2: Prompt Engineering Fundamentals</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-are-large-language-models">1.1. What Are Large Language Models?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-exercise-you-be-the-model">1.2. Interactive Exercise: You Be the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tokens-tokenization-the-foundation">1.3. Tokens &amp; Tokenization: The Foundation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-llms-work-the-generation-pipeline">1.4. How LLMs Work: The Generation Pipeline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-capability-efficiency">1.5. Model Capability &amp; Efficiency</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parameters-the-laptop-specs-analogy">1.5.1. Parameters: The ‚ÄúLaptop Specs‚Äù Analogy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantization-the-camera-megapixel-analogy">1.5.2. Quantization: The ‚ÄúCamera Megapixel‚Äù Analogy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-context-window-active-memory-limits">1.6. The Context Window: ‚ÄúActive Memory‚Äù Limits</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-digital-desk-concept">1.6.1. The ‚ÄúDigital Desk‚Äù Concept</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-working-beyond-context-limits">1.7. Exercise: Working Beyond Context Limits</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hatef Dastour
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>