
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>1. Part 1: Understanding Large Language Models &#8212; AI Foundations for Graduate Research Excellence</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css?v=564be945" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notes/understanding_large_language_models';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Part 2: Prompt Engineering Fundamentals" href="prompt_engineering_fundamentals.html" />
    <link rel="prev" title="Workshop Overview" href="../Preface.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../Preface.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="AI Foundations for Graduate Research Excellence - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="AI Foundations for Graduate Research Excellence - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">1. Part 1: Understanding Large Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="prompt_engineering_fundamentals.html">2. Part 2: Prompt Engineering Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_prompting_techniques.html">3. Part 3: Advanced Prompting Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="research_applications.html">4. Part 4: Research Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="mini_lab_and_practical_application.html">5. Part 5: Mini-Lab and Practical Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="specialized_tools_and_resources.html">6. Part 6: Specialized Tools and Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="ethical_considerations_and_best_practices.html">7. Part 7: Ethical Considerations and Best Practices</a></li>

<li class="toctree-l1"><a class="reference internal" href="appendix.html">9. Appendix: Prompt Template Library</a></li>

<li class="toctree-l1"><a class="reference internal" href="../References.html">11. References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Part 1: Understanding Large Language Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-are-large-language-models">1.1. What Are Large Language Models?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-exercise-you-be-the-model">1.2. Interactive Exercise: You Be the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tokens-tokenization-the-foundation">1.3. Tokens &amp; Tokenization: The Foundation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-llms-work-the-generation-pipeline">1.4. How LLMs Work: The Generation Pipeline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-capability-efficiency">1.5. Model Capability &amp; Efficiency</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-context-window-active-memory-limits">1.6. The Context Window: “Active Memory” Limits</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-working-beyond-context-limits">1.7. Exercise: Working Beyond Context Limits</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="part-1-understanding-large-language-models">
<h1><span class="section-number">1. </span>Part 1: Understanding Large Language Models<a class="headerlink" href="#part-1-understanding-large-language-models" title="Link to this heading">#</a></h1>
<section id="what-are-large-language-models">
<h2><span class="section-number">1.1. </span>What Are Large Language Models?<a class="headerlink" href="#what-are-large-language-models" title="Link to this heading">#</a></h2>
<div class="tip admonition">
<p class="admonition-title">Definition</p>
<p>Large Language Models (LLMs) are neural networks trained on massive text datasets (billions of words) that predict the next word based on context—repeatedly <span id="id1">[<a class="reference internal" href="../References.html#id2" title="Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D. Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language Models are Few-Shot Learners. Advances in Neural Information Processing Systems, 33:1877–1901, 2020. URL: https://proceedings.neurips.cc/paper_files/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html (visited on 2026-02-11).">Brown <em>et al.</em>, 2020</a>]</span>. They can perform diverse tasks without task-specific training through a process called “in-context learning.”</p>
</div>
<div class="proof example admonition" id="example_01">
<p class="admonition-title"><span class="caption-number">Example 1.1 </span> (Key Examples (Early 2026))</p>
<section class="example-content" id="proof-content">
<ul class="simple">
<li><p><a href="https://openai.com/index/introducing-gpt-5-2/" target="_blank" rel="noopener">OpenAI’s GPT-5.2</a></p></li>
<li><p><a href="https://claude.ai/new" target="_blank" rel="noopener">Anthropic’s Claude</a></p></li>
<li><p><a href="https://deepmind.google/models/gemini/pro/" target="_blank" rel="noopener">Google Gemini 3 Pro</a></p></li>
<li><p><a href="https://x.ai/" target="_blank" rel="noopener">xAI’s Grok-4.1</a></p></li>
<li><p><a href="https://www.microsoft.com/en-us/microsoft-365-copilot" target="_blank" rel="noopener">Microsoft 365 Copilot</a></p></li>
<li><p><a href="https://ai.meta.com/blog/" target="_blank" rel="noopener">Meta’s Llama 4</a></p></li>
</ul>
</section>
</div><div class="warning admonition">
<p class="admonition-title">Note</p>
<p>LLMs don’t “understand” language—they predict the most likely next token based on probability and proximity in embedding space <span id="id2">[<a class="reference internal" href="../References.html#id3" title="Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Jill Burstein, Christy Doran, and Thamar Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 4171–4186. Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi:10.18653/v1/N19-1423.">Devlin <em>et al.</em>, 2019</a>]</span>. This is fundamentally different from human comprehension and has important implications for research applications.</p>
</div>
</section>
<section id="interactive-exercise-you-be-the-model">
<h2><span class="section-number">1.2. </span>Interactive Exercise: You Be the Model<a class="headerlink" href="#interactive-exercise-you-be-the-model" title="Link to this heading">#</a></h2>
<p><strong>Objective:</strong> Help students internalize how LLMs work through experiential learning.</p>
<p><strong>Activity (5 minutes):</strong></p>
<ol class="arabic simple">
<li><p>Present: <em>“The capital of Northern Ireland is ____”</em></p></li>
<li><p>Students write down:</p>
<ul class="simple">
<li><p>Top 3 predictions</p></li>
<li><p>Assign probability (%) to each</p></li>
<li><p>Compare with neighbor</p></li>
</ul>
</li>
</ol>
<!-- **Expected Results:**
- Belfast: ~85-95%
- Dublin: ~3-8% (common mistake)
- Other cities: <5%

**Teaching Point:** Your brain just performed pattern matching based on prior knowledge—exactly what an LLM does, but LLMs use billions of training examples to calculate probabilities. They don't "know" Belfast is correct; they predict it's the most likely completion based on training data patterns {cite}`wei_chain_thought_2022`. -->
<p><strong>Discussion Questions:</strong></p>
<ul class="simple">
<li><p>What made you confident in your answer?</p></li>
<li><p>How did you assign probabilities?</p></li>
<li><p>What if you’d never heard of Northern Ireland?</p></li>
</ul>
</section>
<section id="tokens-tokenization-the-foundation">
<h2><span class="section-number">1.3. </span>Tokens &amp; Tokenization: The Foundation<a class="headerlink" href="#tokens-tokenization-the-foundation" title="Link to this heading">#</a></h2>
<div class="tip admonition">
<p class="admonition-title">Definition</p>
<p>Tokens are the basic units of text that LLMs process. Words are broken into smaller pieces (subwords or characters) for processing.</p>
</div>
<p><strong>Key Concepts:</strong></p>
<ul class="simple">
<li><p>“Hello” = 1 token</p></li>
<li><p>“ChatGPT” = 2 tokens (“Chat” + “GPT”)</p></li>
<li><p>“artificial intelligence” = 2-3 tokens depending on model</p></li>
<li><p>Average ratio: ~0.75 words per token</p></li>
</ul>
<p><strong>Practical Resource:</strong> OpenAI Tokenizer Tool (<a class="reference external" href="https://platform.openai.com/tokenizer">https://platform.openai.com/tokenizer</a>)</p>
<p><strong>Why This Matters for Research:</strong></p>
<ol class="arabic simple">
<li><p><strong>Cost:</strong> Most LLM APIs charge per token</p></li>
<li><p><strong>Context Limits:</strong> Token counts determine what fits in context</p></li>
<li><p><strong>Precision:</strong> Understanding tokenization improves prompt efficiency</p></li>
</ol>
</section>
<section id="how-llms-work-the-generation-pipeline">
<h2><span class="section-number">1.4. </span>How LLMs Work: The Generation Pipeline<a class="headerlink" href="#how-llms-work-the-generation-pipeline" title="Link to this heading">#</a></h2>
<div class="proof example admonition" id="example_02">
<p class="admonition-title"><span class="caption-number">Example 1.2 </span></p>
<section class="example-content" id="proof-content">
<p><strong>Example Demonstration:</strong></p>
<p><strong>Input:</strong> “The capital of Canada is _____”</p>
<p><strong>Model Probabilities:</strong></p>
<ul class="simple">
<li><p>✓ Ottawa: <strong>92%</strong></p></li>
<li><p>Toronto: 5%</p></li>
<li><p>Montreal: 2%</p></li>
<li><p>Maple Syrup: 0.001%</p></li>
</ul>
<p><strong>Technical Process (Simplified):</strong></p>
<ol class="arabic simple">
<li><p><strong>Tokenization:</strong> Input text → tokens</p></li>
<li><p><strong>Embedding:</strong> Tokens → high-dimensional vectors (capturing semantic meaning)</p></li>
<li><p><strong>Attention Mechanism:</strong> Model weighs importance of each token relative to others</p></li>
<li><p><strong>Probability Distribution:</strong> Calculates probability for every token in vocabulary</p></li>
<li><p><strong>Sampling:</strong> Selects next token (usually highest probability, with some randomness)</p></li>
<li><p><strong>Repeat:</strong> New token added to context, process repeats</p></li>
</ol>
</section>
</div><div class="warning admonition">
<p class="admonition-title">Note</p>
<p>The model doesn’t look up “capital of Canada” in a database. It calculates that given the pattern “The capital of [Country] is”, and given billions of examples where “Ottawa” appeared after “The capital of Canada is”, the token “Ottawa” has the highest probability of being next <span id="id3">[<a class="reference internal" href="../References.html#id6" title="OpenAI. Prompt engineering. https://developers.openai.com/api/docs/guides/prompt-engineering, 2026. Accessed: 2026-02-10.">OpenAI, 2026</a>]</span>.</p>
</div>
</section>
<section id="model-capability-efficiency">
<h2><span class="section-number">1.5. </span>Model Capability &amp; Efficiency<a class="headerlink" href="#model-capability-efficiency" title="Link to this heading">#</a></h2>
<p><strong>Parameters: The “Laptop Specs” Analogy</strong></p>
<p><strong>Concept:</strong> Parameters are like the specs of a computer—more powerful specs enable more complex operations.</p>
<ul class="simple">
<li><p><strong>70B parameter model</strong> = High-end workstation (powerful reasoning, nuanced understanding)</p></li>
<li><p><strong>7B parameter model</strong> = Standard notebook (good for many tasks, faster, more efficient)</p></li>
<li><p><strong>405B parameter model</strong> = Supercomputer cluster (exceptional capabilities, expensive to run)</p></li>
</ul>
<div class="proof example admonition" id="example_021">
<p class="admonition-title"><span class="caption-number">Example 1.3 </span></p>
<section class="example-content" id="proof-content">
<p>GPT-4 reportedly has ~1.76 trillion parameters, while smaller models like Llama 3-8B have 8 billion. More parameters generally mean better performance on complex reasoning tasks but require more computational resources <span id="id4">[<a class="reference internal" href="../References.html#id7" title="Anthropic. Prompt engineering overview. https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/overview, 2026. Accessed: 2026-02-10.">Anthropic, 2026</a>]</span>.</p>
<p><strong>Quantization: The “Camera Megapixel” Analogy</strong></p>
<figure class="align-center" id="params-quantization">
<a class="reference internal image-reference" href="../_images/params_quantization.png"><img alt="../_images/params_quantization.png" src="../_images/params_quantization.png" style="width: 600px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.1 </span><span class="caption-text">The “Camera Megapixel” Analogy (image generated by Google Gemini).</span><a class="headerlink" href="#params-quantization" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Concept:</strong> Quantization reduces the precision of model weights to make them smaller and faster.</p>
<ul class="simple">
<li><p><strong>100MP (Original):</strong> Perfect detail, massive file size, requires supercomputer</p></li>
<li><p><strong>10MP (Quantized):</strong> Looks nearly identical, much smaller, runs on laptop</p></li>
</ul>
<p><strong>Technical Detail:</strong></p>
<ul class="simple">
<li><p>FP32 (full precision): 32 bits per parameter</p></li>
<li><p>INT8 (quantized): 8 bits per parameter</p></li>
<li><p>4-bit quantization: Aggressive compression, ~75% reduction in size</p></li>
</ul>
</section>
</div><div class="warning admonition">
<p class="admonition-title">Trade-off</p>
<p>We sacrifice tiny amounts of precision for the ability to run world-class AI on standard research laptops. For most research tasks, quantized models perform nearly identically to full-precision versions <span id="id5">[<a class="reference internal" href="../References.html#id8" title="Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. QLoRA: Efficient Finetuning of Quantized LLMs. Advances in Neural Information Processing Systems, 36:10088–10115, December 2023. URL: https://proceedings.neurips.cc/paper_files/paper/2023/hash/1feb87871436031bdc0f2beaa62a049b-Abstract-Conference.html (visited on 2026-02-11).">Dettmers <em>et al.</em>, 2023</a>]</span>.</p>
</div>
</section>
<section id="the-context-window-active-memory-limits">
<h2><span class="section-number">1.6. </span>The Context Window: “Active Memory” Limits<a class="headerlink" href="#the-context-window-active-memory-limits" title="Link to this heading">#</a></h2>
<p><strong>The “Digital Desk” Concept</strong></p>
<figure class="align-center" id="context-window">
<a class="reference internal image-reference" href="../_images/context_window.png"><img alt="../_images/context_window.png" src="../_images/context_window.png" style="width: 600px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.2 </span><span class="caption-text">The “Digital Desk” Concept (image generated by Google Gemini).</span><a class="headerlink" href="#context-window" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Analogy:</strong> The context window is like a physical desk:</p>
<ul class="simple">
<li><p><strong>Desk Size:</strong> Represents the model’s capacity to “see” and “connect” information</p></li>
<li><p><strong>Hard Cutoff:</strong> Once full, new data pushes old data out (FIFO - First In, First Out)</p></li>
<li><p><strong>Can’t See the Floor:</strong> The model can only work with what’s on the desk</p></li>
</ul>
<div class="pst-scrollable-table-container"><table class="table" id="table-01">
<caption><span class="caption-number">Table 1.1 </span><span class="caption-text">Context Window Comparison (Early 2026)</span><a class="headerlink" href="#table-01" title="Link to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head text-center"><p>AI Model Family</p></th>
<th class="head text-center"><p>Latest Model</p></th>
<th class="head text-center"><p>Context Window (Tokens)</p></th>
<th class="head text-center"><p>Word Estimate</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>OpenAI</p></td>
<td class="text-center"><p>GPT-5.3</p></td>
<td class="text-center"><p>400,000</p></td>
<td class="text-center"><p>~300,000 words</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>Anthropic</p></td>
<td class="text-center"><p>Claude 5 Sonnet</p></td>
<td class="text-center"><p>1,000,000</p></td>
<td class="text-center"><p>~750,000 words</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>Meta (Open)</p></td>
<td class="text-center"><p>Llama 4 Scout</p></td>
<td class="text-center"><p>10,000,000</p></td>
<td class="text-center"><p>~7,500,000 words</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>Mistral</p></td>
<td class="text-center"><p>Mistral Large 3</p></td>
<td class="text-center"><p>128,000</p></td>
<td class="text-center"><p>~96,000 words</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>Google</p></td>
<td class="text-center"><p>Gemini 3 Pro</p></td>
<td class="text-center"><p>2,000,000+</p></td>
<td class="text-center"><p>~1,500,000+ words</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Critical Research Limitation:</strong> Context windows have grown dramatically, but limitations remain:</p>
<ol class="arabic simple">
<li><p><strong>Recall Decay:</strong> Even within context limits, models struggle with information buried in the middle (the “lost in the middle” problem) <span id="id6">[<a class="reference internal" href="../References.html#id9" title="Zhenyu Zhang, Runjin Chen, Shiwei Liu, Zhewei Yao, Olatunji Ruwase, Beidi Chen, Xiaoxia Wu, and Zhangyang Wang. Found in the Middle: How Language Models Use Long Contexts Better via Plug-and-Play Positional Encoding. Advances in Neural Information Processing Systems, 37:60755–60775, December 2024. doi:10.52202/079017-1943.">Zhang <em>et al.</em>, 2024</a>]</span></p></li>
<li><p><strong>No External Memory:</strong> LLMs cannot access information outside their context window</p></li>
<li><p><strong>No Real-Time Search:</strong> They cannot look up current information unless explicitly provided</p></li>
</ol>
<div class="admonition-the-research-solution admonition">
<p class="admonition-title">The Research Solution</p>
<p>❌ <strong>The Trap:</strong> “Review all health-informatics articles” fails because:</p>
<ul class="simple">
<li><p>Models can’t access external databases</p></li>
<li><p>Even with large context, they can’t process thousands of papers</p></li>
<li><p>They only work with what you explicitly provide</p></li>
</ul>
<p>✅ <strong>The Fix:</strong> Manually place specific, high-value papers in the context via your prompt:</p>
<ul class="simple">
<li><p>Upload PDFs of key papers</p></li>
<li><p>Paste abstracts directly</p></li>
<li><p>Provide structured summaries</p></li>
<li><p>Use chunking strategies for large documents</p></li>
</ul>
</div>
</section>
<section id="exercise-working-beyond-context-limits">
<h2><span class="section-number">1.7. </span>Exercise: Working Beyond Context Limits<a class="headerlink" href="#exercise-working-beyond-context-limits" title="Link to this heading">#</a></h2>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-0">
<strong>Scenario</strong></label><div class="sd-tab-content docutils">
<p>You have 300 article abstracts and need to identify research themes.</p>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-1">
<strong>The Problem</strong></label><div class="sd-tab-content docutils">
<ul class="simple">
<li><p>300 abstracts × ~200 words = ~60,000 words</p></li>
<li><p>Too large for reliable processing in one go</p></li>
<li><p>Risk of information loss and degradation</p></li>
</ul>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" for="sd-tab-item-2">
<strong>Student Task (5 minutes)</strong></label><div class="sd-tab-content docutils">
<p>Think through these questions:</p>
<ol class="arabic simple">
<li><p>How would you break this into smaller pieces?</p>
<ul class="simple">
<li><p>Process in batches? How many per batch?</p></li>
</ul>
</li>
<li><p>What would you ask the LLM to do at each step?</p>
<ul class="simple">
<li><p>Identify themes in each batch, then combine?</p></li>
<li><p>Something else?</p></li>
</ul>
</li>
<li><p>How would you handle overlaps or conflicts between batches?</p></li>
</ol>
<p><strong>Pair-Share (3 minutes):</strong> Compare approaches with neighbor.</p>
</div>
</div>
<!-- **Effective Strategies (Teaching Points):**

````{card} **Strategy 1: Batch Processing with Hierarchical Summarization**

Step 1: Process 20 abstracts at a time
Prompt: "Identify 3-5 key themes in these abstracts with supporting evidence"

Step 2: Collect theme summaries from all batches

Step 3: Meta-analysis
Prompt: "Here are theme summaries from 15 batches. Consolidate into 5-7 major research themes, noting frequency and evolution"

````

````{card} **Strategy 2: Pre-clustering + LLM Interpretation**

Step 1: Use topic modeling (BERTopic, LDA) to create initial clusters

Step 2: Extract representative abstracts from each cluster

Step 3: LLM analysis
Prompt: "Here are 5 representative abstracts from Cluster 1. Describe the underlying research theme, key questions, and methodological approaches"

````

````{card} **Strategy 3: Keyword Extraction → Synthesis**

Step 1: Extract keywords from each abstract (via LLM or TF-IDF)

Step 2: Create keyword frequency matrix

Step 3: LLM synthesis with condensed information
Prompt: "Based on these keyword frequencies and co-occurrences, identify and describe major research themes"

```` -->
<div class="warning admonition">
<p class="admonition-title">Note</p>
<p>When tasks exceed context limits, design multi-stage workflows rather than single prompts. Think of it as breaking a research paper into introduction, methods, results, and discussion—each section is manageable, together they form a complete work <span id="id7">[<a class="reference internal" href="../References.html#id10" title="Stig Pedersen Korsholm. Mastering prompt engineering: a comparative guide to nine prompt engineering frameworks for tech professionals. https://www.linkedin.com/pulse/mastering-prompt-engineering-comparative-guide-nine-tech-korsholm-hnjif/, February 2024. Accessed: 2026-02-10.">Korsholm, 2024</a>]</span>.</p>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../Preface.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Workshop Overview</p>
      </div>
    </a>
    <a class="right-next"
       href="prompt_engineering_fundamentals.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2. </span>Part 2: Prompt Engineering Fundamentals</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-are-large-language-models">1.1. What Are Large Language Models?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-exercise-you-be-the-model">1.2. Interactive Exercise: You Be the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tokens-tokenization-the-foundation">1.3. Tokens &amp; Tokenization: The Foundation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-llms-work-the-generation-pipeline">1.4. How LLMs Work: The Generation Pipeline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-capability-efficiency">1.5. Model Capability &amp; Efficiency</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-context-window-active-memory-limits">1.6. The Context Window: “Active Memory” Limits</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-working-beyond-context-limits">1.7. Exercise: Working Beyond Context Limits</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hatef Dastour
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>