
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>4.1. Probability Distribution Function (PDF) for a Discrete Random Variable &#8212; Introduction to Probability and Statistics</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css?v=564be945" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter_04/STATS_C04S01';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="4.2. Mean or Expected Value and Standard Deviation" href="STATS_C04S02.html" />
    <link rel="prev" title="4. Discrete Random Variables" href="STATS_C04.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../Introduction.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Introduction to Probability and Statistics - Home"/>
    <img src="../_static/logo.png" class="logo__image only-dark pst-js-only" alt="Introduction to Probability and Statistics - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_01/STATS_C01.html">1. Fundamentals of Statistics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/STATS_C01S01.html">1.1. Definitions of Statistics, Probability, and Key Terms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/STATS_C01S02.html">1.2. Quantitative and Qualitative Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/STATS_C01S03.html">1.3. Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_01/STATS_C01S04.html">1.4. Levels of Measurement</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_02/STATS_C02.html">2. Exploring Data Distribution and Measures</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/STATS_C02S01.html">2.1. Frequency and Frequency Table</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/STATS_C02S02.html">2.2. Visualizing Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/STATS_C02S03.html">2.3. Measures of Centre of the Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/STATS_C02S04.html">2.4. Commonly Observed Shapes of Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/STATS_C02S05.html">2.5. Commonly Observed Shapes of Skewness</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/STATS_C02S06.html">2.6. Understanding Percentiles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/STATS_C02S07.html">2.7. Box Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_02/STATS_C02S08.html">2.8. Measures of Variation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_03/STATS_C03.html">3. Probability Topics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/STATS_C03S01.html">3.1. What is Probability?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/STATS_C03S02.html">3.2. Tree and Venn Diagrams</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/STATS_C03S03.html">3.3. The Addition Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/STATS_C03S04.html">3.4. The Role of Complements and Equally Likely Outcomes in Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/STATS_C03S05.html">3.5. Contingency Table</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/STATS_C03S06.html">3.6. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/STATS_C03S07.html">3.7. Independent Events</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_03/STATS_C03S08.html">3.8. Law of Total Probability and Generalized form of Bayes’ Theorem</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="STATS_C04.html">4. Discrete Random Variables</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">4.1. Probability Distribution Function (PDF) for a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="STATS_C04S02.html">4.2. Mean or Expected Value and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="STATS_C04S03.html">4.3. Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="STATS_C04S04.html">4.4. Poisson Distribution</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_05/STATS_C05.html">5. Continuous Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/STATS_C05S01.html">5.1. Continuous Probability Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/STATS_C05S02.html">5.2. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/STATS_C05S03.html">5.3. The Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/STATS_C05S04.html">5.4. Standard Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/STATS_C05S05.html">5.5. The Lognormal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/STATS_C05S06.html">5.6. Sampling Distributions and Estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_05/STATS_C05S07.html">5.7. The Central Limit Theorem</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_06/STATS_C06.html">6. Confidence Intervals</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/STATS_C06S01.html">6.1. Single Population Confidence Intervals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/STATS_C06S02.html">6.2. Confidence Intervals for a Single Population Mean When <span class="math notranslate nohighlight">\(\sigma\)</span> is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/STATS_C06S03.html">6.3. Understanding the t-Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/STATS_C06S04.html">6.4. Confidence Intervals for a Single Population Mean When <span class="math notranslate nohighlight">\(\sigma\)</span> is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_06/STATS_C06S05.html">6.5. Confidence Intervals for a Single Population Proportion</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter_07/STATS_C07.html">7. Hypothesis Testing with One Sample</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/STATS_C07S01.html">7.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/STATS_C07S02.html">7.2. Null and Alternative Hypotheses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/STATS_C07S03.html">7.3. Outcomes and Type I and Type II Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/STATS_C07S04.html">7.4. One-Tail, Two-Tail Tests, and Critical Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/STATS_C07S05.html">7.5. P-Value</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/STATS_C07S06.html">7.6. Hypothesis Testing of a Single Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/STATS_C07S07.html">7.7. Hypothesis Tests for One Population Mean When <span class="math notranslate nohighlight">\(\sigma\)</span> Is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/STATS_C07S08.html">7.8. Hypothesis Tests for One Population Mean When <span class="math notranslate nohighlight">\(\sigma\)</span> Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_07/STATS_C07S09.html">7.9. Hypothesis Testing of a Single Proportion</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../appendices/appendices.html">8. Appendices</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendices/appendixA.html">8.1. Normal Distribution Table</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendices/appendixB.html">8.2. t-Distribution Table</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../References.html">9. References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Probability Distribution Function (PDF) for a Discrete Random Variable</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-variable">4.1.1. Random Variable</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-mass-function-pmf-for-a-discrete-random-variable">4.1.2. Probability Mass Function (PMF) for a Discrete Random Variable</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cumulative-distribution-function-cdf">4.1.3. Cumulative Distribution Function (CDF)</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="probability-distribution-function-pdf-for-a-discrete-random-variable">
<h1><span class="section-number">4.1. </span>Probability Distribution Function (PDF) for a Discrete Random Variable<a class="headerlink" href="#probability-distribution-function-pdf-for-a-discrete-random-variable" title="Link to this heading">#</a></h1>
<section id="random-variable">
<h2><span class="section-number">4.1.1. </span>Random Variable<a class="headerlink" href="#random-variable" title="Link to this heading">#</a></h2>
<p>A <strong>random variable</strong> is a fundamental concept in probability and statistics. It essentially serves as a function that assigns a numerical value to each possible outcome of a random experiment <span id="id1">[<a class="reference internal" href="../References.html#id46" title="P.M. Shankar. Probability, Random Variables, and Data Analytics with Engineering Applications. Springer International Publishing, 2021. ISBN 9783030562595. URL: https://books.google.ca/books?id=e4YbEAAAQBAJ.">Shankar, 2021</a>]</span>.</p>
<p>When you perform an experiment, like flipping a coin or rolling a die, there are multiple possible outcomes. A random variable provides a way to quantify these outcomes. For instance, if you flip a coin, you can define a random variable <span class="math notranslate nohighlight">\(X\)</span> such that <span class="math notranslate nohighlight">\(X = 0\)</span> if the outcome is tails and <span class="math notranslate nohighlight">\(X = 1\)</span> if the outcome is heads.</p>
<div class="tip admonition">
<p class="admonition-title">Definition - Random Variable</p>
<p>A <strong>random variable</strong> is a function that assigns a numerical value to each outcome of a random experiment. It maps outcomes from the sample space (the set of all possible results) to real numbers, allowing us to perform mathematical analysis and probability calculations.</p>
</div>
<p><strong>Types of Random Variables:</strong></p>
<p>There are two main types of random variables:</p>
<ul>
<li><p><strong>Discrete Random Variable</strong>: This type of random variable has a finite or countably infinite set of values it can assume. These values are distinct and separate, often representing countable outcomes.</p>
<p><strong>Examples</strong>:</p>
<ul class="simple">
<li><p><strong>Number of heads</strong> in 10 coin tosses: Possible values are 0, 1, 2, …, 10.</p></li>
<li><p><strong>Daily customer count</strong> at a cafe: Values could be 0, 1, 2, …, n, where n is the maximum capacity of the cafe.</p></li>
</ul>
</li>
<li><p><strong>Continuous Random Variable</strong>: A continuous random variable can take on any value within a given range or interval. The possibilities are infinite and uncountable, typically associated with measurements.</p>
<p><strong>Examples</strong>:</p>
<ul class="simple">
<li><p><strong>Height of adults</strong> in a city: Any value within a realistic range, say from 140 cm to 200 cm.</p></li>
<li><p><strong>Amount of water</strong> in a jug: Any value from 0 liters up to the jug’s capacity, measured precisely.</p></li>
</ul>
</li>
</ul>
<p><strong>Understanding Random Variables:</strong></p>
<p>The value of a random variable is realized only after the random experiment is conducted. For example, before we flip a coin, we don’t know if we’ll get a head or a tail—each outcome is determined by chance.</p>
<p><strong>Discrete Example</strong>: Consider a lottery where the random variable <span class="math notranslate nohighlight">\(X\)</span> represents the number of matching numbers on a ticket. <span class="math notranslate nohighlight">\(X\)</span> can take on values 0, 1, 2, 3, 4, 5, or 6, each corresponding to the number of matches.</p>
<p><strong>Continuous Example</strong>: If we measure the time <span class="math notranslate nohighlight">\(T\)</span> it takes for a chemical reaction to complete, <span class="math notranslate nohighlight">\(T\)</span> is a continuous random variable because it can take any value within a range, say from 0 to 10 minutes, depending on various factors like temperature and concentration.</p>
</section>
<section id="probability-mass-function-pmf-for-a-discrete-random-variable">
<h2><span class="section-number">4.1.2. </span>Probability Mass Function (PMF) for a Discrete Random Variable<a class="headerlink" href="#probability-mass-function-pmf-for-a-discrete-random-variable" title="Link to this heading">#</a></h2>
<p>The Probability Mass Function (PMF) is a function that gives the probability of a discrete random variable taking on a specific value. In other words, it maps each value of the random variable to its corresponding probability of occurrence. For a discrete random variable <span class="math notranslate nohighlight">\(X\)</span>, the PMF is typically denoted as <span class="math notranslate nohighlight">\(P(X = x)\)</span> or <span class="math notranslate nohighlight">\(p_X(x)\)</span>, where <span class="math notranslate nohighlight">\(x\)</span> represents a specific value that <span class="math notranslate nohighlight">\(X\)</span> can take <span id="id2">[<a class="reference internal" href="../References.html#id40" title="J.L. Devore, K.N. Berk, and M.A. Carlton. Modern Mathematical Statistics with Applications. Springer Texts in Statistics. Springer International Publishing, 2021. ISBN 9783030551568. URL: https://books.google.ca/books?id=ghcsEAAAQBAJ.">Devore <em>et al.</em>, 2021</a>]</span>.</p>
<div class="tip admonition">
<p class="admonition-title">Definition - Probability Mass Function (PMF)</p>
<p>The <strong>Probability Mass Function (PMF)</strong> of a discrete random variable <span class="math notranslate nohighlight">\(X\)</span> is a function that gives the probability that <span class="math notranslate nohighlight">\(X\)</span> will take on a particular value <span class="math notranslate nohighlight">\(x\)</span>. It is typically denoted as <span class="math notranslate nohighlight">\(P(X = x)\)</span> or <span class="math notranslate nohighlight">\(p_X(x)\)</span>, and is defined as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-34d8371b-5af4-4ca7-b187-1ef703a51093">
<span class="eqno">(4.1)<a class="headerlink" href="#equation-34d8371b-5af4-4ca7-b187-1ef703a51093" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(X = x) = \text{Pr}(X = x)
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\text{Pr}(X = x)\)</span> represents the probability that the random variable <span class="math notranslate nohighlight">\(X\)</span> equals <span class="math notranslate nohighlight">\(x\)</span>.</p>
</div>
<div class="proof example admonition" id="example4.1.0">
<p class="admonition-title"><span class="caption-number">Example 4.1 </span> (Example of PMF - Coin Toss)</p>
<section class="example-content" id="proof-content">
<p>For coin flips, let <span class="math notranslate nohighlight">\(X\)</span> be the number of heads in one coin flip:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p><span class="math notranslate nohighlight">\(X\)</span> (Number of Heads)</p></th>
<th class="head text-center"><p><span class="math notranslate nohighlight">\(P(X)\)</span> (Probability)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>0</p></td>
<td class="text-center"><p>1/2</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>1</p></td>
<td class="text-center"><p>1/2</p></td>
</tr>
</tbody>
</table>
</div>
<p>The Probability Mass Function (PMF) here tells us:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(X = 0) = 1/2\)</span> (probability of getting 0 heads)</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X = 1) = 1/2\)</span> (probability of getting 1 head)</p></li>
</ul>
<p>This PMF completely describes the probability distribution for the random variable X, which represents the number of heads in a single fair coin flip.</p>
<p>Interpretation</p>
<ul class="simple">
<li><p>There’s a 50% chance of getting no heads (i.e., getting a tail).</p></li>
<li><p>There’s a 50% chance of getting one head.</p></li>
<li><p>The probabilities sum to 1, as required for a valid PMF.</p></li>
</ul>
</section>
</div><p>The PMF satisfies the following conditions:</p>
<ol class="arabic simple">
<li><p><strong>Non-Negativity:</strong> The probability mass function values are non-negative for all possible values of X:</p></li>
</ol>
<div class="amsmath math notranslate nohighlight" id="equation-ae4638c8-33a8-486d-87e4-be6a647e4a6c">
<span class="eqno">(4.2)<a class="headerlink" href="#equation-ae4638c8-33a8-486d-87e4-be6a647e4a6c" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(X = x) \geq 0 \quad \text{for all } x \in \mathcal{X}
\end{equation}\]</div>
<ol class="arabic simple" start="2">
<li><p><strong>Summation:</strong> The sum of the probabilities over all possible values of X is equal to 1:</p></li>
</ol>
<div class="amsmath math notranslate nohighlight" id="equation-9e908d75-3696-4571-ab3a-45135dc70ac3">
<span class="eqno">(4.3)<a class="headerlink" href="#equation-9e908d75-3696-4571-ab3a-45135dc70ac3" title="Permalink to this equation">#</a></span>\[\begin{equation}
\sum_{x \in \mathcal{X}} P(X = x) = 1
\end{equation}\]</div>
<p>Where <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> denotes the set of all possible values that the random variable X can take.</p>
<p>The PMF can be represented in various ways:</p>
<ul class="simple">
<li><p><strong>Table:</strong> A list of possible values of X and their corresponding probabilities.</p></li>
<li><p><strong>Histogram:</strong> A graphical representation where each bar’s height represents the probability of a specific value.</p></li>
<li><p><strong>Formula:</strong> A mathematical expression that gives the probability for any value of X.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Definitions - Probability Histogram</p>
<p>A probability histogram is a graphical representation of the probability distribution for a discrete random variable. It displays the possible values of the random variable on the horizontal axis and the probabilities associated with each value on the vertical axis. Each value is represented by a vertical bar whose height corresponds to the probability of that value occurring. The bars are typically disjoint and are spaced according to the gaps between the values of the discrete random variable.</p>
<p>Probability histograms are a visual tool used to understand and analyze the probabilities of different outcomes in a discrete random variable. They allow us to observe the relative likelihood of each value occurring and identify the most probable outcomes. Probability histograms can be useful for decision-making, risk assessment, and understanding the behavior of random processes.</p>
</div>
<p>To construct the probability histogram, we follow these steps:</p>
<ul class="simple">
<li><p><strong>Identify the possible values of X:</strong> Determine all the distinct values that the “number of siblings” variable X can take based on the data collected from the students.</p></li>
<li><p><strong>Calculate the probabilities:</strong> Use the <span class="math notranslate nohighlight">\(f/N\)</span> rule, as mentioned before, to compute the probabilities for each value of X. Divide the
frequency (<span class="math notranslate nohighlight">\(f\)</span>) of each value by the total number of observations (<span class="math notranslate nohighlight">\(N\)</span>) to obtain the probability of that specific value.</p></li>
<li><p><strong>Plotting the histogram:</strong> On the horizontal axis, mark the possible values of X (e.g., 0, 1, 2, 3, etc.). On the vertical axis, represent the probabilities corresponding to each value as vertical bars. The height of each bar will be proportional to the probability of the respective value.</p></li>
<li><p><strong>Ensuring appropriate scaling:</strong> To ensure that the histogram accurately represents the probabilities, make sure that the vertical axis is appropriately scaled to accommodate the probabilities ranging from 0 to 1.</p></li>
</ul>
<div class="proof example admonition" id="example4.1.11">
<p class="admonition-title"><span class="caption-number">Example 4.2 </span> (Probability Mass Function and Histogram of a Fair Coin Flip)</p>
<section class="example-content" id="proof-content">
<p>When you flip a fair coin, the random variable “X” can take on only two values: 0 (for tails) and 1 (for heads). The
probability mass function (PMF) for this discrete random variable is given by:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}P(X = 0) = 0.5\quad\text{(probability of tails)}\end{equation*}\]</div>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}P(X = 1) = 0.5\quad\text{(probability of heads)}\end{equation*}\]</div>
<figure class="align-center" id="discrete-random-variable-coins">
<a class="reference internal image-reference" href="../_images/discrete_random_variable_coins.png"><img alt="../_images/discrete_random_variable_coins.png" src="../_images/discrete_random_variable_coins.png" style="width: 180px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.1 </span><span class="caption-text">The probability mass function (PMF) for a fair coin flip. The random variable “X” can take on two values: 0 (for tails) and 1 (for heads). Each outcome has an equal probability of 0.5, as shown by the bars reaching a height of 0.5 on the y-axis.</span><a class="headerlink" href="#discrete-random-variable-coins" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</div><div class="proof example admonition" id="example4.1.12">
<p class="admonition-title"><span class="caption-number">Example 4.3 </span> (Probability Mass Function and Histogram of a Fair Six-Sided Die Roll)</p>
<section class="example-content" id="proof-content">
<p>When you roll a standard six-sided die, the random variable “Y” can take on values from 1 to 6. The PMF for this discrete
random variable is uniform because each outcome is equally likely:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}P(Y\  = \ 1)\  = \ P(Y\  = \ 2)\  = \ P(Y\  = \ 3)\  = \ P(Y\  = \ 4)\  = \ P(Y\  = \ 5)\  = \ P(Y\  = \ 6)\  = \dfrac{1}{6}\end{equation*}\]</div>
<figure class="align-center" id="discrete-random-variable-dice">
<a class="reference internal image-reference" href="../_images/discrete_random_variable_dice.png"><img alt="../_images/discrete_random_variable_dice.png" src="../_images/discrete_random_variable_dice.png" style="width: 380px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.2 </span><span class="caption-text">The probability mass function (PMF) for rolling a standard six-sided die. The random variable “Y” can take on values from 1 to 6, with each outcome being equally likely. The height of each bar is <span class="math notranslate nohighlight">\(\dfrac{1}{6}\)</span>, indicating that the probability of rolling any specific number (1 through 6) is the same, <span class="math notranslate nohighlight">\(\dfrac{1}{6}\)</span>.</span><a class="headerlink" href="#discrete-random-variable-dice" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</div><div class="proof example admonition" id="example4.1.13">
<p class="admonition-title"><span class="caption-number">Example 4.4 </span> (PMF and Probability Histogram of Defective Items in a Batch)</p>
<section class="example-content" id="proof-content">
<p>Let’s say we are inspecting a batch of products, and the random variable “Z” represents the number of
defective items in the batch. The values Z can take are non-negative integers (0, 1, 2, 3, …). The PMF might look like this:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
P(Z = 0) &amp;= 0.1 \quad\text{(10% chance of having no defective items)},
\\
P(Z = 1) &amp;= 0.3 \quad\text{(30% chance of having one defective item)},
\\
P(Z = 2) &amp;= 0.4 \quad\text{(40% chance of having two defective items)},
\\
P(Z = 3) &amp;= 0.2 \quad\text{(20% chance of having three defective items)}.
\end{align*}\]</div>
<figure class="align-center" id="discrete-random-variable-numbers">
<a class="reference internal image-reference" href="../_images/discrete_random_variable_numbers.png"><img alt="../_images/discrete_random_variable_numbers.png" src="../_images/discrete_random_variable_numbers.png" style="width: 300px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.3 </span><span class="caption-text">The probability mass function (PMF) for the number of defective items, <span class="math notranslate nohighlight">\(Z\)</span>, in a batch of products. The random variable <span class="math notranslate nohighlight">\(Z\)</span> can take on values 0, 1, 2, and 3, with the corresponding probabilities: <span class="math notranslate nohighlight">\(P(Z = 0) = 0.1\)</span> (10% chance of no defective items), <span class="math notranslate nohighlight">\(P(Z = 1) = 0.3\)</span> (30% chance of one defective item), <span class="math notranslate nohighlight">\(P(Z = 2) = 0.4\)</span> (40% chance of two defective items), and <span class="math notranslate nohighlight">\(P(Z = 3) = 0.2\)</span> (20% chance of three defective items).</span><a class="headerlink" href="#discrete-random-variable-numbers" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</div><div class="proof example admonition" id="example4.1.14">
<p class="admonition-title"><span class="caption-number">Example 4.5 </span> (PMF and Probability Histogram for Drawing Balls Without Replacement)</p>
<section class="example-content" id="proof-content">
<!-- Suppose you have a bag with red and blue balls, and you randomly pick balls without replacement until you get a
blue one. The random variable \"W\" represents the number of red balls picked. The values W can take are non-negative integers (0, 1, 2, 3,
\...). The PMF is not as straightforward as the previous examples, but it can be calculated based on probabilities of different scenarios.

As an example, -->
<p>Suppose you have a bag with 10 balls: 7 red balls and 3 blue balls. You randomly pick balls without replacement until you get a blue one. The random variable “W” represents the number of red balls picked. The values W can take are non-negative integers (0, 1, 2, 3, …, 7). The PMF can be calculated based on the probabilities of different scenarios.</p>
<p>Let’s calculate the PMF for W:</p>
<ul>
<li><p><strong>P(W = 0)</strong>: The probability of picking a blue ball on the first draw.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P(W = 0) = \dfrac{3}{10}
\end{equation*}\]</div>
</li>
<li><p><strong>P(W = 1)</strong>: The probability of picking one red ball first, then a blue ball.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P(W = 1) = \dfrac{7}{10} \times \dfrac{3}{9} = \dfrac{7}{30}
\end{equation*}\]</div>
</li>
<li><p><strong>P(W = 2)</strong>: The probability of picking two red balls first, then a blue ball.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P(W = 2) = \dfrac{7}{10} \times \dfrac{6}{9} \times \dfrac{3}{8} = \dfrac{7}{40}
\end{equation*}\]</div>
</li>
<li><p><strong>P(W = 3)</strong>: The probability of picking three red balls first, then a blue ball.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P(W = 3) = \dfrac{7}{10} \times \dfrac{6}{9} \times \dfrac{5}{8} \times \dfrac{3}{7} = \dfrac{1}{8}
\end{equation*}\]</div>
</li>
<li><p><strong>P(W = 4)</strong>: The probability of picking four red balls first, then a blue ball.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P(W = 4) = \dfrac{7}{10} \times \dfrac{6}{9} \times \dfrac{5}{8} \times \dfrac{4}{7} \times \dfrac{3}{6} = \dfrac{1}{12}
\end{equation*}\]</div>
</li>
<li><p><strong>P(W = 5)</strong>: The probability of picking five red balls first, then a blue ball.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P(W = 5) = \dfrac{7}{10} \times \dfrac{6}{9} \times \dfrac{5}{8} \times \dfrac{4}{7} \times \dfrac{3}{6} \times \dfrac{2}{5} = \dfrac{1}{20}
\end{equation*}\]</div>
</li>
<li><p><strong>P(W = 6)</strong>: The probability of picking six red balls first, then a blue ball.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P(W = 6) = \dfrac{7}{10} \times \dfrac{6}{9} \times \dfrac{5}{8} \times \dfrac{4}{7} \times \dfrac{3}{6} \times \dfrac{2}{5} \times \dfrac{1}{4} = \dfrac{1}{40}
\end{equation*}\]</div>
</li>
<li><p><strong>P(W = 7)</strong>: The probability of picking all seven red balls first, then a blue ball.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P(W = 7) = \dfrac{7}{10} \times \dfrac{6}{9} \times \dfrac{5}{8} \times \dfrac{4}{7} \times \dfrac{3}{6} \times \dfrac{2}{5} \times \dfrac{1}{4} \times \dfrac{3}{3} = \dfrac{1}{120}
\end{equation*}\]</div>
</li>
</ul>
<p>This example shows how the PMF for the number of red balls picked before getting a blue one can be calculated based on the probabilities of different scenarios.</p>
<figure class="align-center" id="discrete-random-variable-balls">
<a class="reference internal image-reference" href="../_images/discrete_random_variable_balls.png"><img alt="../_images/discrete_random_variable_balls.png" src="../_images/discrete_random_variable_balls.png" style="width: 480px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.4 </span><span class="caption-text">The probability mass function (PMF) for the number of red balls picked, (W), before getting a blue one from a bag containing 10 balls (7 red and 3 blue). The random variable (W) can take values from 0 to 7.</span><a class="headerlink" href="#discrete-random-variable-balls" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</div><!-- ````{prf:example} Example of Discrete Random Variables - Number of Red Balls
:label: example4.1.14

Suppose you have a bag with red and blue balls, and you randomly pick balls without replacement until you get a
blue one. The random variable \"W\" represents the number of red balls picked. The values W can take are non-negative integers (0, 1, 2, 3,
\...). The PMF is not as straightforward as the previous examples, but it can be calculated based on probabilities of different scenarios.


As an example, suppose you have a bag with 10 balls: 7 red balls and 3 blue balls. You randomly pick balls without replacement until you get a blue one. The random variable "W" represents the number of red balls picked. The values W can take are non-negative integers (0, 1, 2, 3, ..., 7). The PMF can be calculated based on the probabilities of different scenarios.

Let's calculate the PMF for W:

- **P(W = 0)**: The probability of picking a blue ball on the first draw.
  \begin{equation*}
  P(W = 0) = \dfrac{3}{10}
  \end{equation*}

- **P(W = 1)**: The probability of picking one red ball first, then a blue ball.
  \begin{equation*}
  P(W = 1) = \dfrac{7}{10} \times \dfrac{3}{9} = \dfrac{7}{30}
  \end{equation*}

- **P(W = 2)**: The probability of picking two red balls first, then a blue ball.
  \begin{equation*}
  P(W = 2) = \dfrac{7}{10} \times \dfrac{6}{9} \times \dfrac{3}{8} = \dfrac{7 \times 6 \times 3}{10 \times 9 \times 8} = \dfrac{7}{40}
  \end{equation*}

- **P(W = 3)**: The probability of picking three red balls first, then a blue ball.
  \begin{equation*}
  P(W = 3) = \dfrac{7}{10} \times \dfrac{6}{9} \times \dfrac{5}{8} \times \dfrac{3}{7} = \dfrac{7 \times 6 \times 5 \times 3}{10 \times 9 \times 8 \times 7} = \dfrac{1}{8}
  \end{equation*}

- **P(W = 4)**: The probability of picking four red balls first, then a blue ball.
  \begin{equation*}
  P(W = 4) = \dfrac{7}{10} \times \dfrac{6}{9} \times \dfrac{5}{8} \times \dfrac{4}{7} \times \dfrac{3}{6} = \dfrac{7 \times 6 \times 5 \times 4 \times 3}{10 \times 9 \times 8 \times 7 \times 6} = \dfrac{1}{12}
  \end{equation*}

- **P(W = 5)**: The probability of picking five red balls first, then a blue ball.
  \begin{equation*}
  P(W = 5) = \dfrac{7}{10} \times \dfrac{6}{9} \times \dfrac{5}{8} \times \dfrac{4}{7} \times \dfrac{3}{6} \times \dfrac{2}{5} = \dfrac{7 \times 6 \times 5 \times 4 \times 3 \times 2}{10 \times 9 \times 8 \times 7 \times 6 \times 5} = \dfrac{1}{20}
  \end{equation*}

- **P(W = 6)**: The probability of picking six red balls first, then a blue ball.
  \begin{equation*}
  P(W = 6) = \dfrac{7}{10} \times \dfrac{6}{9} \times \dfrac{5}{8} \times \dfrac{4}{7} \times \dfrac{3}{6} \times \dfrac{2}{5} \times \dfrac{1}{4} = \dfrac{7 \times 6 \times 5 \times 4 \times 3 \times 2 \times 1}{10 \times 9 \times 8 \times 7 \times 6 \times 5 \times 4} = \dfrac{1}{40}
  \end{equation*}

- **P(W = 7)**: The probability of picking all seven red balls first, then a blue ball.
  \begin{equation*}
  P(W = 7) = \dfrac{7}{10} \times \dfrac{6}{9} \times \dfrac{5}{8} \times \dfrac{4}{7} \times \dfrac{3}{6} \times \dfrac{2}{5} \times \dfrac{1}{4} \times \dfrac{3}{3} = \dfrac{7 \times 6 \times 5 \times 4 \times 3 \times 2 \times 1 \times 3}{10 \times 9 \times 8 \times 7 \times 6 \times 5 \times 4 \times 3} = \dfrac{1}{120}
  \end{equation*}

This example shows how the PMF for the number of red balls picked before getting a blue one can be calculated based on the probabilities of different scenarios.

```{figure} discrete_random_variable_balls.png
---
width: 600px
align: center
name: discrete_random_variable_balls
---
The probability mass function (PMF) for the number of red balls picked, ( W ), before getting a blue one from a bag containing 10 balls (7 red and 3 blue). The random variable ( W ) can take values from 0 to 7.
```

```` --></section>
<section id="cumulative-distribution-function-cdf">
<h2><span class="section-number">4.1.3. </span>Cumulative Distribution Function (CDF)<a class="headerlink" href="#cumulative-distribution-function-cdf" title="Link to this heading">#</a></h2>
<p>The <strong>Cumulative Distribution Function (CDF)</strong> of a discrete random variable <span class="math notranslate nohighlight">\(X\)</span> is a function that gives the probability that <span class="math notranslate nohighlight">\(X\)</span> will take on a value less than or equal to a certain value <span class="math notranslate nohighlight">\(x\)</span>. It’s typically denoted as <span class="math notranslate nohighlight">\(F_X(x)\)</span> and is defined as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-69270954-8e07-435f-8cbe-ae89c07f8141">
<span class="eqno">(4.4)<a class="headerlink" href="#equation-69270954-8e07-435f-8cbe-ae89c07f8141" title="Permalink to this equation">#</a></span>\[\begin{equation}
F_X(x) = P(X \leq x) = \sum_{k \leq x} P(X = k)
\end{equation}\]</div>
<p>Key properties of the CDF:</p>
<ul class="simple">
<li><p>It accumulates the probabilities of the random variable from the lowest possible value up to <span class="math notranslate nohighlight">\(x\)</span>.</p></li>
<li><p>For any given value <span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(F_X(x)\)</span> represents the probability that the random variable <span class="math notranslate nohighlight">\(X\)</span> will have a value less than or equal to <span class="math notranslate nohighlight">\(x\)</span>.</p></li>
<li><p>As <span class="math notranslate nohighlight">\(x\)</span> increases, <span class="math notranslate nohighlight">\(F_X(x)\)</span> is non-decreasing (it either increases or remains constant).</p></li>
<li><p><span class="math notranslate nohighlight">\(\lim_{x \to -\infty} F_X(x) = 0\)</span> and <span class="math notranslate nohighlight">\(\lim_{x \to \infty} F_X(x) = 1\)</span></p></li>
</ul>
<div class="proof example admonition" id="example4.1.1">
<p class="admonition-title"><span class="caption-number">Example 4.6 </span></p>
<section class="example-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X\)</span> represent the outcome of rolling a fair six-sided die. The PMF <span class="math notranslate nohighlight">\(p_X(x)\)</span> would be <span class="math notranslate nohighlight">\(\frac{1}{6}\)</span> for <span class="math notranslate nohighlight">\(x \in \{1, 2, 3, 4, 5, 6\}\)</span>. The CDF <span class="math notranslate nohighlight">\(F_X(x)\)</span> would be:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(F_X(1) = P(X \leq 1) = \frac{1}{6}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(F_X(2) = P(X \leq 2) = \frac{1}{6} + \frac{1}{6} = \frac{2}{6}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(F_X(3) = P(X \leq 3) = \frac{1}{6} + \frac{1}{6} + \frac{1}{6} = \frac{3}{6}\)</span></p></li>
<li><p>… and so on, until <span class="math notranslate nohighlight">\(F_X(6) = 1\)</span></p></li>
</ul>
<p>The CDF is useful for finding probabilities of ranges. For example, <span class="math notranslate nohighlight">\(P(2 &lt; X \leq 4) = F_X(4) - F_X(2)\)</span>.</p>
<figure class="align-center" id="cdf-example1">
<a class="reference internal image-reference" href="../_images/cdf_example1.png"><img alt="../_images/cdf_example1.png" src="../_images/cdf_example1.png" style="width: 420px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.5 </span><span class="caption-text">Cumulative Distribution Function (CDF) for a Six-Sided Die. The graph illustrates the CDF for rolling a fair six-sided die. The x-axis represents the possible outcomes (1 to 6), and the y-axis shows the cumulative probability <span class="math notranslate nohighlight">\(F_X(x)\)</span>. Each step height corresponds to the cumulative probability up to that outcome, starting from <span class="math notranslate nohighlight">\(\frac{1}{6}\)</span> for 1 and reaching 1 for 6.</span><a class="headerlink" href="#cdf-example1" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</div><div class="tip admonition">
<p class="admonition-title">Summary</p>
<ol class="arabic">
<li><p><strong>Probability Mass Function (PMF)</strong>: The PMF of a discrete random variable <span class="math notranslate nohighlight">\(X\)</span> is typically denoted as <span class="math notranslate nohighlight">\(p_X(x)\)</span> or <span class="math notranslate nohighlight">\(P(X = x)\)</span>. It is defined as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-38a67169-a0d0-4828-a8e2-00a528f449a6">
<span class="eqno">(4.5)<a class="headerlink" href="#equation-38a67169-a0d0-4828-a8e2-00a528f449a6" title="Permalink to this equation">#</a></span>\[\begin{equation}
p_X(x) = P(X = x)
\end{equation}\]</div>
<p>This function gives the probability that the random variable <span class="math notranslate nohighlight">\(X\)</span> will take on the specific value <span class="math notranslate nohighlight">\(x\)</span>. For example, if <span class="math notranslate nohighlight">\(X\)</span> represents the roll of a fair die, then <span class="math notranslate nohighlight">\(p_X(3) = P(X = 3) = \frac{1}{6}\)</span>.</p>
</li>
<li><p><strong>Cumulative Distribution Function (CDF)</strong>: The CDF of <span class="math notranslate nohighlight">\(X\)</span>, denoted as <span class="math notranslate nohighlight">\(F_X(x)\)</span>, is defined as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-351e8531-5ed6-4dc9-89ea-f23c5dff9f51">
<span class="eqno">(4.6)<a class="headerlink" href="#equation-351e8531-5ed6-4dc9-89ea-f23c5dff9f51" title="Permalink to this equation">#</a></span>\[\begin{equation}
F_X(x) = P(X \leq x)
\end{equation}\]</div>
<p>This function provides the probability that the random variable <span class="math notranslate nohighlight">\(X\)</span> will take on a value less than or equal to <span class="math notranslate nohighlight">\(x\)</span>. It accumulates the probabilities for all outcomes up to and including <span class="math notranslate nohighlight">\(x\)</span>.</p>
</li>
<li><p><strong>Calculation of CDF using PMF</strong>: For a discrete random variable, the CDF <span class="math notranslate nohighlight">\(F_X(x)\)</span> can be calculated by summing up the PMF <span class="math notranslate nohighlight">\(p_X(t)\)</span> for all values <span class="math notranslate nohighlight">\(t\)</span> that are less than or equal to <span class="math notranslate nohighlight">\(x\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-5af0d93b-3068-4530-bdfe-6d5e46fa1f56">
<span class="eqno">(4.7)<a class="headerlink" href="#equation-5af0d93b-3068-4530-bdfe-6d5e46fa1f56" title="Permalink to this equation">#</a></span>\[\begin{equation}
F_X(x) = \sum_{t \leq x} p_X(t) = \sum_{t \leq x} P(X = t)
\end{equation}\]</div>
<p>This equation shows that to find <span class="math notranslate nohighlight">\(F_X(x)\)</span>, you add up all the probabilities <span class="math notranslate nohighlight">\(p_X(t)\)</span> where <span class="math notranslate nohighlight">\(t\)</span> is any value that <span class="math notranslate nohighlight">\(X\)</span> could take that is also less than or equal to <span class="math notranslate nohighlight">\(x\)</span>.</p>
</li>
<li><p><strong>Normalization of PMF</strong>: The sum of the PMF over all possible values of <span class="math notranslate nohighlight">\(X\)</span> must equal 1. This is a fundamental property of probability distributions:</p>
<div class="amsmath math notranslate nohighlight" id="equation-1ae805ed-5686-45a8-9a8e-11b10a12c585">
<span class="eqno">(4.8)<a class="headerlink" href="#equation-1ae805ed-5686-45a8-9a8e-11b10a12c585" title="Permalink to this equation">#</a></span>\[\begin{equation}
\sum_{x} p_X(x) = \sum_{x} P(X = x) = 1
\end{equation}\]</div>
<p>Here, the summation is over all the possible values that <span class="math notranslate nohighlight">\(X\)</span> can take.</p>
</li>
</ol>
</div>
<div class="important admonition">
<p class="admonition-title">Remark</p>
<p>It’s important to note that <span class="math notranslate nohighlight">\( P(X = x) \)</span> denotes the probability that the random variable <span class="math notranslate nohighlight">\( X \)</span> equals a specific value <span class="math notranslate nohighlight">\( x \)</span>. However, for simplicity, in some textbooks may use the notation <span class="math notranslate nohighlight">\( P(x) \)</span> as shorthand for <span class="math notranslate nohighlight">\( P(X = x) \)</span>.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Definitions - Probability Distribution</p>
<p>A probability distribution for a discrete random variable is a function that maps each possible value to its probability. It must satisfy the following conditions:</p>
<ol class="arabic simple">
<li><p>All probabilities are non-negative.</p></li>
<li><p>The sum of all probabilities is 1.</p></li>
</ol>
<p>This distribution can be represented as a table, graph, or formula that lists the possible values and their associated probabilities.</p>
</div>
<!-- Consider a survey where students report the number of siblings they have. The data yields the following frequency and relative-frequency distributions:

| Siblings ($ x $) | Frequency ($ f $) | Relative Frequency |
|:------------------:|:-------------------:|:------------------:|
|         0          |          8          |        0.200       |
|         1          |         17          |        0.425       |
|         2          |         11          |        0.275       |
|         3          |          3          |        0.075       |
|         4          |          1          |        0.025       |
|    **Total**       |         40          |        1.000       |

To find the probability associated with each value of the random variable $ X $, representing the number of siblings, we apply the frequency ($ f $) over the total number of observations ($ N $) rule, denoted as $ f/N $.

For example, the probability that a randomly selected student has two siblings, $ P(X = 2) $, is calculated by dividing the frequency of students with two siblings by the total number of students surveyed.

The probabilities for each value of $ X $ are as follows:

| Siblings ($ x $) | Probability ($ P(X = x) $) |
|:------------------:|:----------------------------:|
|         0          |            0.200             |
|         1          |            0.425             |
|         2          |            0.275             |
|         3          |            0.075             |
|         4          |            0.025             |
|    **Total**       |            1.000             |

In this context, $ X $ denotes the number of siblings, and $ x $ represents a specific outcome within that variable's range of possible values.
    student may have. --><div class="proof example admonition" id="example4.1.2">
<p class="admonition-title"><span class="caption-number">Example 4.7 </span> (Probability Analysis of a Dice Game)</p>
<section class="example-content" id="proof-content">
<p>Calculate the probability of each possible sum when two six-sided dice are rolled. The sum <span class="math notranslate nohighlight">\( X \)</span> can range from 2 to 12, and the probability <span class="math notranslate nohighlight">\( P(X = x) \)</span> reflects the number of ways the sum <span class="math notranslate nohighlight">\( x \)</span> can occur divided by the total number of possible outcomes, which is 36. For instance, there is only one way to roll a sum of 2 (1 on both dice), and there are six ways to roll a sum of 7 (1-6, 2-5, 3-4, 4-3, 5-2, 6-1).</p>
<!-- a. **Expected Value Calculation:**
   Calculate the expected value (mean) of $ X $. The expected value is the average outcome if the dice game is played many times. Use the formula:
   \begin{equation*} E(X) = \sum [x \cdot P(X = x)] \end{equation*}

b. **Variance and Standard Deviation:**
   Determine the variance and standard deviation of $ X $. These measures indicate how spread out the sums are around the expected value. Use the formulas:
   \begin{equation*} \text{Variance} = \sum [(x - E(X))^2 \cdot P(X = x)] \end{equation*}
   \begin{equation*} \text{Standard Deviation} = \sqrt{\text{Variance}} \end{equation*}

c. **Probability of an Even Sum:**
   Find the probability that the sum $ X $ is an even number. Sum up the probabilities of all even outcomes.

d. **Probability of a Sum Greater Than 8:**
   Calculate the probability that the sum $ X $ is greater than 8. Add the probabilities of the sums 9, 10, 11, and 12.

e. **Cumulative Distribution Function (CDF):**
   Create the cumulative distribution function for $ X $. The CDF at a number $ x $ is the probability that $ X $ will take a value less than or equal to $ x $. It can be calculated as:
   \begin{equation*} F(x) = P(X \leq x) \end{equation*} -->
</section>
</div><p><font color='Green'><b>Solution:</b></font></p>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="../_images/dice_combinations_grid.png"><img alt="../_images/dice_combinations_grid.png" src="../_images/dice_combinations_grid.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.6 </span><span class="caption-text">Visualization of all possible outcomes when rolling two dice. Image based on icons from <a class="reference external" href="https://www.iconpacks.net/">this source</a>.</span><a class="headerlink" href="#id3" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>To calculate the probabilities, we need to consider all possible combinations that can result in each sum. Here’s how we can calculate it:</p>
<ul class="simple">
<li><p><strong>Sum of 2:</strong> There is only 1 combination (1+1), so <span class="math notranslate nohighlight">\(P(X = 2) = \frac{1}{36}\)</span>.</p></li>
<li><p><strong>Sum of 3:</strong> There are 2 combinations (1+2, 2+1), so <span class="math notranslate nohighlight">\(P(X = 3) = \frac{2}{36}\)</span>.</p></li>
<li><p><strong>Sum of 4:</strong> There are 3 combinations (1+3, 2+2, 3+1), so <span class="math notranslate nohighlight">\(P(X = 4) = \frac{3}{36}\)</span>.</p></li>
<li><p><strong>Sum of 5:</strong> There are 4 combinations (1+4, 2+3, 3+2, 4+1), so <span class="math notranslate nohighlight">\(P(X = 5) = \frac{4}{36}\)</span>.</p></li>
<li><p><strong>Sum of 6:</strong> There are 5 combinations (1+5, 2+4, 3+3, 4+2, 5+1), so <span class="math notranslate nohighlight">\(P(X = 6) = \frac{5}{36}\)</span>.</p></li>
<li><p><strong>Sum of 7:</strong> There are 6 combinations (1+6, 2+5, 3+4, 4+3, 5+2, 6+1), so <span class="math notranslate nohighlight">\(P(X = 7) = \frac{6}{36}\)</span>.</p></li>
<li><p><strong>Sum of 8:</strong> There are 5 combinations (2+6, 3+5, 4+4, 5+3, 6+2), so <span class="math notranslate nohighlight">\(P(X = 8) = \frac{5}{36}\)</span>.</p></li>
<li><p><strong>Sum of 9:</strong> There are 4 combinations (3+6, 4+5, 5+4, 6+3), so <span class="math notranslate nohighlight">\(P(X = 9) = \frac{4}{36}\)</span>.</p></li>
<li><p><strong>Sum of 10:</strong> There are 3 combinations (4+6, 5+5, 6+4), so <span class="math notranslate nohighlight">\(P(X = 10) = \frac{3}{36}\)</span>.</p></li>
<li><p><strong>Sum of 11:</strong> There are 2 combinations (5+6, 6+5), so <span class="math notranslate nohighlight">\(P(X = 11) = \frac{2}{36}\)</span>.</p></li>
<li><p><strong>Sum of 12:</strong> There is only one combination (6+6), so <span class="math notranslate nohighlight">\(P(X = 12) = \frac{1}{36}\)</span>.</p></li>
</ul>
<p>These probabilities are based on the fact that each die is fair and has an equal chance of landing on any of its six faces. The total number of possible outcomes when rolling two dice is <span class="math notranslate nohighlight">\(6 \times 6 = 36\)</span>, and each combination is equally likely.</p>
<p>Here’s a summary table of the probabilities:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-right"><p>Sum (<span class="math notranslate nohighlight">\(X\)</span>)</p></th>
<th class="head text-left"><p>Probability (<span class="math notranslate nohighlight">\(P(X = x)\)</span>)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-right"><p>2</p></td>
<td class="text-left"><p>1/36</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>3</p></td>
<td class="text-left"><p>1/18</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>4</p></td>
<td class="text-left"><p>1/12</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>5</p></td>
<td class="text-left"><p>1/9</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>6</p></td>
<td class="text-left"><p>5/36</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>7</p></td>
<td class="text-left"><p>1/6</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>8</p></td>
<td class="text-left"><p>5/36</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>9</p></td>
<td class="text-left"><p>1/9</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>10</p></td>
<td class="text-left"><p>1/12</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>11</p></td>
<td class="text-left"><p>1/18</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>12</p></td>
<td class="text-left"><p>1/36</p></td>
</tr>
</tbody>
</table>
</div>
<p>This table shows the probability distribution for the sum of two six-sided dice. The probabilities add up to one, as expected in a valid probability distribution.</p>
<p><a class="reference internal" href="#pmf-example-dice-sum"><span class="std std-numref">Fig. 4.7</span></a> visually demonstrates the varying probabilities of sums when rolling two dice, highlighting that some sums, like seven, are more likely to occur than others.</p>
<figure class="align-center" id="pmf-example-dice-sum">
<a class="reference internal image-reference" href="../_images/pmf_example_dice_sum.png"><img alt="../_images/pmf_example_dice_sum.png" src="../_images/pmf_example_dice_sum.png" style="width: 550px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.7 </span><span class="caption-text">Probability distribution graph showing that in rolling two six-sided dice, some sums occur more frequently than others; with a peak at sum seven where the probability is highest.</span><a class="headerlink" href="#pmf-example-dice-sum" title="Link to this image">#</a></p>
</figcaption>
</figure>
<!-- **1. Expected Value Calculation:**

The expected value \( E(X) \) is calculated by summing the product of each outcome and its probability:

$$
E(X) = \sum [x \cdot P(X = x)] = (2 \cdot \frac{1}{36}) + (3 \cdot \frac{2}{36}) + (4 \cdot \frac{3}{36}) + \ldots + (12 \cdot \frac{1}{36})
$$

Calculating this, we get:

$$
E(X) = \frac{2}{36} + \frac{6}{36} + \frac{12}{36} + \frac{20}{36} + \frac{30}{36} + \frac{42}{36} + \frac{40}{36} + \frac{36}{36} + \frac{30}{36} + \frac{22}{36} + \frac{12}{36}
$$

$$
E(X) = \frac{252}{36} = 7
$$

So, the expected value of \( X \) is 7.

**2. Variance and Standard Deviation:**

To find the variance, we calculate the squared difference between each outcome and the expected value, then multiply by the probability of each outcome:

$$
\text{Variance} = \sum [(x - E(X))^2 \cdot P(X = x)]
$$

$$
= (2 - 7)^2 \cdot \frac{1}{36} + (3 - 7)^2 \cdot \frac{2}{36} + \ldots + (12 - 7)^2 \cdot \frac{1}{36}
$$

$$
= 25 \cdot \frac{1}{36} + 16 \cdot \frac{2}{36} + 9 \cdot \frac{3}{36} + \ldots + 25 \cdot \frac{1}{36}
$$

$$
= \frac{25}{36} + \frac{32}{36} + \frac{27}{36} + \ldots + \frac{25}{36}
$$

$$
= \frac{210}{36} = 5.83
$$

The standard deviation is the square root of the variance:

$$
\text{Standard Deviation} = \sqrt{5.83} \approx 2.42
$$

**3. Probability of an Even Sum:**

The probability that the sum \( X \) is an even number is the sum of the probabilities of all even outcomes (2, 4, 6, 8, 10, 12):

$$
P(\text{even}) = P(X = 2) + P(X = 4) + P(X = 6) + P(X = 8) + P(X = 10) + P(X = 12)
$$

$$
= \frac{1}{36} + \frac{3}{36} + \frac{5}{36} + \frac{5}{36} + \frac{3}{36} + \frac{1}{36}
$$

$$
= \frac{18}{36} = 0.5
$$

So, the probability of rolling an even sum is 0.5.

**4. Probability of a Sum Greater Than 8:**

The probability that the sum \( X \) is greater than 8 is the sum of the probabilities of the sums 9, 10, 11, and 12:

$$
P(X > 8) = P(X = 9) + P(X = 10) + P(X = 11) + P(X = 12)
$$

$$
= \frac{4}{36} + \frac{3}{36} + \frac{2}{36} + \frac{1}{36}
$$

$$
= \frac{10}{36} \approx 0.278
$$

So, the probability of rolling a sum greater than 8 is approximately 0.278.

**5. Cumulative Distribution Function (CDF):**

The CDF at a number \( x \) is the probability that \( X \) will take a value less than or equal to \( x \). We can calculate it as follows:

- \( F(2) = P(X \leq 2) = \frac{1}{36} \)
- \( F(3) = P(X \leq 3) = \frac{1}{36} + \frac{2}{36} = \frac{3}{36} \)
- \( F(4) = P(X \leq 4) = \frac{3}{36} + \frac{3}{36} = \frac{6}{36} \)
- ... and so on, until \( F(12) = 1 \), because all possible outcomes have been accumulated.

Here's the CDF table:

| Sum (\( x \)) | \( F(x) \) |
|:-------------:|:----------:|
|       2       |   1/36     |
|       3       |   3/36     |
|       4       |   6/36     |
|       5       |  10/36     |
|       6       |  15/36     |
|       7       |  21/36     |
|       8       |  26/36     |
|       9       |  30/36     |
|      10       |  33/36     |
|      11       |  35/36     |
|      12       |   1        |

This completes the exercise. If you have any further questions or need additional explanations, feel free to ask! --><div class="proof example admonition" id="example4.1.4">
<p class="admonition-title"><span class="caption-number">Example 4.8 </span></p>
<section class="example-content" id="proof-content">
<p>Given the table below, determine if the sum of the values of <span class="math notranslate nohighlight">\( P(X = x) \)</span> equals 1, as required for a probability distribution. Does the table describe a probability distribution?</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\( x \)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\( P(X = x) \)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>0.05</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>0.10</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>0.20</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>0.25</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>0.30</p></td>
</tr>
<tr class="row-odd"><td><p>5</p></td>
<td><p>0.10</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</div><p><font color='Green'><b>Solution:</b></font></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( X \)</span> is the random variable.</p></li>
<li><p>The notation <span class="math notranslate nohighlight">\( P(X = x) \)</span> represents the probability that the random variable <span class="math notranslate nohighlight">\( X \)</span> takes on a specific value <span class="math notranslate nohighlight">\( x \)</span>.</p></li>
</ul>
<p>To verify if the table represents a probability distribution, we must satisfy two conditions:</p>
<ol class="arabic simple">
<li><p>The sum of the values of <span class="math notranslate nohighlight">\( P(x) \)</span> must equal 1.</p></li>
<li><p>Each value of <span class="math notranslate nohighlight">\( P(x) \)</span> must be non-negative (greater than or equal to 0).</p></li>
</ol>
<p>Let’s evaluate both conditions for the provided table:</p>
<ol class="arabic simple">
<li><p>The sum of the values of <span class="math notranslate nohighlight">\( P(x) \)</span> is: <span class="math notranslate nohighlight">\( 0.05 + 0.10 + 0.20 + 0.25 + 0.30 + 0.10 \)</span>. Calculate this sum to check if it equals 1.</p></li>
<li><p>Verify that each value of <span class="math notranslate nohighlight">\( P(x) \)</span> is non-negative.</p></li>
</ol>
<p>If both conditions are met, the table represents a valid probability distribution, and the probabilities assigned to each value of <span class="math notranslate nohighlight">\( x \)</span> are collectively exhaustive of all possible outcomes.</p>
<p><a class="reference internal" href="#pmf-example1-sum"><span class="std std-numref">Fig. 4.8</span></a> visually represents the probability distribution of a random variable (X), showing that the sum of all probabilities equals one, which is a requirement for a valid probability distribution.</p>
<figure class="align-center" id="pmf-example1-sum">
<a class="reference internal image-reference" href="../_images/pmf_example1_sum.png"><img alt="../_images/pmf_example1_sum.png" src="../_images/pmf_example1_sum.png" style="width: 700px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.8 </span><span class="caption-text">The sum of probabilities in this discrete distribution equals one for <a class="reference internal" href="#example4.1.4">Example 4.8</a>.</span><a class="headerlink" href="#pmf-example1-sum" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="cell tag_remove-input docutils container">
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter_04"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="STATS_C04.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Discrete Random Variables</p>
      </div>
    </a>
    <a class="right-next"
       href="STATS_C04S02.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4.2. </span>Mean or Expected Value and Standard Deviation</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-variable">4.1.1. Random Variable</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-mass-function-pmf-for-a-discrete-random-variable">4.1.2. Probability Mass Function (PMF) for a Discrete Random Variable</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cumulative-distribution-function-cdf">4.1.3. Cumulative Distribution Function (CDF)</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hatef Dastour
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>