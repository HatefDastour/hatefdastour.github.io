

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>5. Image Filtering &#8212; Computer Vision</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/myfile.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'CV_C5';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="6. Morphological Transformations" href="CV_C6.html" />
    <link rel="prev" title="4. Image Thresholding" href="CV_C4.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="Getting_Started.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Computer Vision - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Computer Vision - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="CV_C1.html">1. Getting Started with OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="CV_C2.html">2. Geometric Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="CV_C3.html">3. Drawing Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="CV_C4.html">4. Image Thresholding</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">5. Image Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="CV_C6.html">6. Morphological Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="References.html">7. References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Image Filtering</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#smoothing-images">5.1. Smoothing Images</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-convolution-image-filtering">5.1.1. 2D Convolution (Image Filtering)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-blurring-image-smoothing">5.2. Image Blurring (Image Smoothing)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#box-blur-average-blur">5.2.1. Box Blur (Average Blur)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#box-filter">5.2.2. Box Filter</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-blur">5.2.3. Gaussian Blur</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#median-blur">5.2.4. Median Blur</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bilateral-filtering">5.2.5. Bilateral Filtering</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-detection">5.3. Feature Detection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sobel-derivatives">5.3.1. Sobel Derivatives</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#canny-edge-detection-algorithm">5.3.2. Canny Edge Detection Algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#canny-edge-detection-in-opencv">5.3.3. Canny Edge Detection in OpenCV</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cv2-canny-function">5.3.4. <code class="docutils literal notranslate"><span class="pre">cv2.Canny</span></code> Function</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="tex2jax_ignore mathjax_ignore section" id="image-filtering">
<h1><span class="section-number">5. </span>Image Filtering<a class="headerlink" href="#image-filtering" title="Permalink to this heading">#</a></h1>
<p>Image filtering is a fundamental concept in computer vision and image processing. It involves applying a filter (also known as a kernel) to an image in order to perform operations such as blurring, sharpening, edge detection, and more. The OpenCV library (cv2) in Python is a powerful tool for image processing, including image filtering.</p>
<div class="section" id="smoothing-images">
<h2><span class="section-number">5.1. </span>Smoothing Images<a class="headerlink" href="#smoothing-images" title="Permalink to this heading">#</a></h2>
<p>Image smoothing, also known as blurring, is a widely used image processing technique. It’s employed to decrease noise, suppress fine details, or ready an image for subsequent analysis. To continue with the following steps, we’ll use the following reference image and its noisy variant.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import necessary libraries</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>  <span class="c1"># Import the plotting library</span>

<span class="c1"># Define color codes for convenience</span>
<span class="n">Colors</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;White&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span>
            <span class="s1">&#39;Black&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="s1">&#39;Red&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="s1">&#39;Green&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="s1">&#39;Blue&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span>
            <span class="s1">&#39;Yellow&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="s1">&#39;Purple&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="s1">&#39;Indigo&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">75</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">130</span><span class="p">),</span>
            <span class="s1">&#39;OrangeRed&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">69</span><span class="p">,</span> <span class="mi">0</span><span class="p">)}</span>

<span class="c1"># Set font properties for plots</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;font.family&#39;</span><span class="p">:</span> <span class="s1">&#39;Calibri&#39;</span><span class="p">,</span> <span class="s1">&#39;axes.titlesize&#39;</span><span class="p">:</span> <span class="mi">16</span><span class="p">})</span>

<span class="c1"># Define a function to display images with titles and optional settings</span>
<span class="k">def</span> <span class="nf">ImShow</span><span class="p">(</span><span class="n">Images</span><span class="p">,</span> <span class="n">Names</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Images&#39;</span><span class="p">,</span> <span class="n">grayscale</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="c1"># Create a figure with two subplots</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">9.5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>  <span class="c1"># Create a figure with 1 row and 2 columns of subplots</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>  <span class="c1"># Flatten the subplots for easier manipulation</span>

    <span class="c1"># Iterate over the first two images</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="c1"># Display the image in grayscale if grayscale is True, otherwise in color</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">Images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span> <span class="k">if</span> <span class="n">grayscale</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Set aspect ratio to 1 (square aspect)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>  <span class="c1"># Turn off axis</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">Names</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>  <span class="c1"># Set image title with bold font</span>

    <span class="k">if</span> <span class="n">title</span><span class="p">:</span>
        <span class="c1"># Set main title if provided</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>  <span class="c1"># Adjust layout for better spacing</span>

    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span>
</pre></div>
</div>
</div>
</div>
<p><font color='Blue'><b>Example - Noisy Image:</b></font></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import necessary libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">io</span>

<span class="c1"># Load an image from a URL</span>
<span class="n">Img</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;https://conted.ucalgary.ca/maincampus/maincampus.jpg&#39;</span><span class="p">)</span>

<span class="c1"># Define a function that standardizes image values</span>
<span class="k">def</span> <span class="nf">ImgStd</span><span class="p">(</span><span class="n">Inp</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Standardizes image values.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        Inp (numpy.ndarray): Input image.</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Standardized image.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">Out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">Inp</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>  <span class="c1"># Round the input values and convert to integers</span>
    <span class="n">Out</span><span class="p">[</span><span class="n">Out</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Set any negative values to 0</span>
    <span class="n">Out</span><span class="p">[</span><span class="n">Out</span> <span class="o">&gt;</span> <span class="mi">255</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>  <span class="c1"># Set any values above 255 to 255 (maximum pixel value)</span>
    <span class="k">return</span> <span class="n">Out</span>  <span class="c1"># Return the standardized image</span>

<span class="c1"># Define the parameters for generating a noisy image</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Mean of the noise</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">30</span>  <span class="c1"># Standard deviation of the noise</span>

<span class="c1"># Create a noisy image by adding Gaussian noise to a copy of the original image</span>
<span class="n">Img_noise</span> <span class="o">=</span> <span class="n">Img</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Standardize the noisy image using the defined ImgStd function</span>
<span class="n">Img_noise</span> <span class="o">=</span> <span class="n">ImgStd</span><span class="p">(</span><span class="n">Img_noise</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;uint8&#39;</span><span class="p">)</span>

<span class="c1"># Display the original image and the noisy image side by side</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ImShow</span><span class="p">(</span><span class="n">Images</span><span class="o">=</span><span class="p">[</span><span class="n">Img</span><span class="p">,</span> <span class="n">Img_noise</span><span class="p">],</span>
           <span class="n">Names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;UofC&#39;</span><span class="p">,</span> <span class="s1">&#39;UofC + Noise&#39;</span><span class="p">],</span>
           <span class="n">title</span><span class="o">=</span> <span class="s1">&#39;Image and Noisy Image&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f99b4ba10fc700ec1d2dddd3be165dfe0ea753738312b871506cc91f0fc726f3.png" src="_images/f99b4ba10fc700ec1d2dddd3be165dfe0ea753738312b871506cc91f0fc726f3.png" />
</div>
</div>
<p>Let’s break down the main steps of the code:</p>
<ol class="arabic simple">
<li><p><strong>Load an Image from a URL:</strong></p>
<ul class="simple">
<li><p>Using <code class="docutils literal notranslate"><span class="pre">io.imread()</span></code>, the code loads an image from a specified URL (<code class="docutils literal notranslate"><span class="pre">https://conted.ucalgary.ca/maincampus/maincampus.jpg</span></code>) and stores it in the variable <code class="docutils literal notranslate"><span class="pre">Img</span></code>.</p></li>
</ul>
</li>
<li><p><strong>Define a Function for Standardizing Image Values:</strong></p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">ImgStd</span></code> function takes an input image (<code class="docutils literal notranslate"><span class="pre">Inp</span></code>) and standardizes its pixel values.</p></li>
<li><p>It rounds the input values to the nearest integer, ensuring that pixel values are integers.</p></li>
<li><p>Negative values are set to 0, and values greater than 255 are capped at 255, which is the maximum pixel value.</p></li>
<li><p>The function returns the standardized image.</p></li>
</ul>
</li>
<li><p><em>Define Parameters for Generating a Noisy Image:</em>*</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mu</span></code> represents the mean of the noise.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sigma</span></code> represents the standard deviation of the noise.</p></li>
</ul>
</li>
<li><p><strong>Create a Noisy Image:</strong></p>
<ul class="simple">
<li><p>The code creates a noisy image (<code class="docutils literal notranslate"><span class="pre">Img_noise</span></code>) by adding Gaussian noise to a copy of the original image (<code class="docutils literal notranslate"><span class="pre">Img</span></code>).</p></li>
<li><p>It uses NumPy’s <code class="docutils literal notranslate"><span class="pre">np.random.normal()</span></code> function to generate random Gaussian noise and subtracts it from the original image.</p></li>
</ul>
</li>
<li><p><strong>Standardize the Noisy Image:</strong></p>
<ul class="simple">
<li><p>The noisy image (<code class="docutils literal notranslate"><span class="pre">Img_noise</span></code>) is standardized using the <code class="docutils literal notranslate"><span class="pre">ImgStd</span></code> function.</p></li>
<li><p>The pixel values of the noisy image are rounded, negative values are set to 0, and values above 255 are capped at 255.</p></li>
</ul>
</li>
</ol>
<div class="section" id="d-convolution-image-filtering">
<h3><span class="section-number">5.1.1. </span>2D Convolution (Image Filtering)<a class="headerlink" href="#d-convolution-image-filtering" title="Permalink to this heading">#</a></h3>
<ol class="arabic">
<li><p><strong>Padding</strong>:
Padding is a technique used in convolutional operations to control the spatial dimensions of the output feature map. It involves adding extra rows and columns of zeros around the input image before applying the convolution operation. Padding is typically used to:</p>
<ul class="simple">
<li><p><strong>Preserve Spatial Dimensions</strong>: Padding helps maintain the spatial dimensions of the output feature map, ensuring that it has the same size as the input. This can be important when you want to preserve spatial information.</p></li>
<li><p><strong>Mitigate Boundary Effects</strong>: Without padding, the convolution operation tends to lose information near the image borders. Padding helps mitigate this issue by allowing the kernel to process pixels at the image boundaries more effectively.</p></li>
</ul>
<p>In OpenCV (cv2), you can specify the type of padding you want when using the <code class="docutils literal notranslate"><span class="pre">cv2.filter2D()</span></code> function. Common padding modes include ‘valid’ (no padding), ‘same’ (padding to match the output size with the input size), and ‘full’ (maximum padding to ensure the kernel covers the entire input).</p>
</li>
<li><p><strong>Strides</strong>:
Strides determine how the convolutional kernel moves or steps across the input image during the convolution operation. A stride value of 1 means the kernel moves one pixel at a time, while a stride value greater than 1 means it skips some pixels.</p>
<ul class="simple">
<li><p><strong>Stride of 1</strong>: A stride of 1 processes each pixel in the input image, resulting in output feature maps with similar spatial dimensions as the input.</p></li>
<li><p><strong>Stride greater than 1</strong>: A larger stride value skips pixels, resulting in output feature maps with reduced spatial dimensions. This can be useful for downsampling and reducing computational complexity.</p></li>
</ul>
</li>
</ol>
<p>In OpenCV (cv2), you can specify the stride when using the <code class="docutils literal notranslate"><span class="pre">cv2.filter2D()</span></code> function. By default, the stride is set to 1, but you can modify it to control the spatial downsampling or upsampling effect.</p>
<div class="figure align-center" id="id23">
<a class="reference internal image-reference" href="_images/Conv3by3.gif"><img alt="_images/Conv3by3.gif" src="_images/Conv3by3.gif" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 5.1 </span><span class="caption-text">Illustration of the convolution process using a 3 by 3 kernel applied to a 5 by 5 matrix with a stride of 1 and padding of 1. Image courtesy of <span id="id1">[<a class="reference internal" href="References.html#id142" title="Vincent Dumoulin and Francesco Visin. A guide to convolution arithmetic for deep learning. arXiv preprint arXiv:1603.07285, 2016.">Dumoulin and Visin, 2016</a>, <a class="reference internal" href="References.html#id141" title="Irhum Shafkat. Intuitively understanding convolutions for deep learning. https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1, 2023. [Online; accessed 01-August-2023].">Shafkat, 2023</a>]</span>.</span><a class="headerlink" href="#id23" title="Permalink to this image">#</a></p>
</div>
<div class="important admonition">
<p class="admonition-title">Remark</p>
<p>To determine the size of padding required based on the size of the kernel and the desired stride, you can use the following formula:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b5399a47-0140-4148-91c3-0298dc99b46b">
<span class="eqno">(5.1)<a class="headerlink" href="#equation-b5399a47-0140-4148-91c3-0298dc99b46b" title="Permalink to this equation">#</a></span>\[\begin{equation} \text{Padding size} = \left\lfloor \frac{\text{Kernel size} - 1}{2} \right\rfloor \times \text{Stride} \end{equation}\]</div>
<p>Here’s what each component means:</p>
<ul class="simple">
<li><p><strong>Padding size</strong>: This is the size of the padding you need to add to the input image or matrix.</p></li>
<li><p><strong>Kernel size</strong>: This refers to the dimensions of your convolutional kernel. For example, a 3x3 kernel has a size of 3.</p></li>
<li><p><strong>Stride</strong>: The stride determines how much the kernel moves between each convolution operation. A stride of 1 means it moves one step at a time.</p></li>
</ul>
<p>Let’s consider an example:</p>
<p>Suppose you have a 3x3 kernel and you want to apply it with a stride of 2. Using the formula:</p>
<div class="amsmath math notranslate nohighlight" id="equation-10f991fb-aead-4415-b2e5-51bb06c4bb47">
<span class="eqno">(5.2)<a class="headerlink" href="#equation-10f991fb-aead-4415-b2e5-51bb06c4bb47" title="Permalink to this equation">#</a></span>\[\begin{equation} \text{Padding size} = \left\lfloor \frac{3 - 1}{2} \right\rfloor \times 2 = \left\lfloor \frac{2}{2} \right\rfloor \times 2 = 1 \times 2 = 2 \end{equation}\]</div>
<p>Thus, in this case, you would need to add a padding of 2 units around your input image or matrix to achieve the desired stride of 2 while maintaining the dimensions.</p>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">cv2.filter2D()</span></code> function applies an arbitrary linear filter to an image. In-place operation is supported. When the aperture is partially outside the image, the function interpolates outlier pixel values according to the specified border mode.</p>
<p>The function does actually compute correlation, not the convolution <span id="id2">[<a class="reference internal" href="References.html#id25" title="G. Bradski. The OpenCV Library. Dr. Dobb's Journal of Software Tools, 2000.">Bradski, 2000</a>, <a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-95c856f7-b15d-4f6d-813e-1b57a74988d2">
<span class="eqno">(5.3)<a class="headerlink" href="#equation-95c856f7-b15d-4f6d-813e-1b57a74988d2" title="Permalink to this equation">#</a></span>\[\begin{equation}
\texttt{dst} (x,y) = \sum _{ \substack{0\leq x' &lt; \texttt{kernel.cols}\\{0\leq y' &lt; \texttt{kernel.rows}}}} \texttt{kernel} (x',y')* \texttt{src} (x+x'- \texttt{anchor.x} ,y+y'- \texttt{anchor.y} )
\end{equation} \]</div>
<p><strong>Notes</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Correlation vs. Convolution</strong>:</p>
<ul class="simple">
<li><p>The statement “The function does actually compute correlation, not the convolution” refers to the mathematical operation performed by the <code class="docutils literal notranslate"><span class="pre">cv2.filter2D()</span></code> function. In image processing, correlation and convolution are closely related operations, but they differ in how the kernel is applied to the image.</p></li>
<li><p>Correlation in this context means that the kernel is applied directly without flipping (mirroring) it. Convolution, on the other hand, involves flipping the kernel before applying it. This distinction can be significant in certain image processing tasks.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">dst</span></code> (x, y)</strong>:</p>
<ul class="simple">
<li><p>This notation represents a pixel in the destination image (<code class="docutils literal notranslate"><span class="pre">dst</span></code>) that is being calculated or modified. The <code class="docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">y)</span></code> coordinates indicate the position of this pixel in the output image.</p></li>
</ul>
</li>
<li><p><strong>Summation (Σ)</strong>:</p>
<ul class="simple">
<li><p>The summation symbol Σ represents a mathematical sum. In this context, it is used to indicate that a series of calculations are performed, and the results are summed up.</p></li>
</ul>
</li>
<li><p><strong>Subscript Notation (<code class="docutils literal notranslate"><span class="pre">kernel.cols</span></code> and <code class="docutils literal notranslate"><span class="pre">kernel.rows</span></code>)</strong>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">kernel.cols</span></code> and <code class="docutils literal notranslate"><span class="pre">kernel.rows</span></code> refer to the number of columns and rows in the kernel, respectively. These values determine the dimensions of the kernel matrix.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">kernel</span></code> (x’, y’)</strong>:</p>
<ul class="simple">
<li><p>This notation signifies a specific element within the kernel matrix. <code class="docutils literal notranslate"><span class="pre">x'</span></code> and <code class="docutils literal notranslate"><span class="pre">y'</span></code> are the indices used to access individual elements within the kernel. The <code class="docutils literal notranslate"><span class="pre">kernel</span></code> matrix contains the values that are applied to the corresponding pixels in the source image during the filtering process.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">src</span></code> (x + x’ - <code class="docutils literal notranslate"><span class="pre">anchor.x</span></code>, y + y’ - <code class="docutils literal notranslate"><span class="pre">anchor.y</span></code>)</strong>:</p>
<ul class="simple">
<li><p>Here, <code class="docutils literal notranslate"><span class="pre">src</span></code> represents the source image, and <code class="docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">y)</span></code> are the coordinates of the pixel in the destination image (<code class="docutils literal notranslate"><span class="pre">dst</span></code>) that is currently being computed. <code class="docutils literal notranslate"><span class="pre">x'</span></code> and <code class="docutils literal notranslate"><span class="pre">y'</span></code> are used to traverse the kernel matrix, and <code class="docutils literal notranslate"><span class="pre">anchor.x</span></code> and <code class="docutils literal notranslate"><span class="pre">anchor.y</span></code> specify the relative position of the anchor point within the kernel. This expression calculates the contribution of a pixel in the source image to the destination image based on the kernel and anchor point positions.</p></li>
</ul>
</li>
</ol>
<!-- That is, the kernel is not mirrored around the anchor point. If you need a real convolution, flip the kernel using flip and set the new anchor to (kernel.cols - anchor.x - 1, kernel.rows - anchor.y - 1). -->
<p>The Python function <code class="docutils literal notranslate"><span class="pre">cv2.filter2D()</span></code> is a method from the OpenCV (Open Source Computer Vision Library) used for applying a custom convolutional filter to an input image (source) in order to perform image processing operations. Here’s a refined explanation of its parameters and return value:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>cv2.filter2D(src, ddepth, kernel[, dst[, anchor[, delta[, borderType]]]]) → dst
</pre></div>
</div>
<ul class="simple">
<li><p><strong>src</strong>: This parameter represents the input image, often referred to as the “source” image, on which the filter operation is applied. It’s a mandatory argument and should be a multi-channel image (e.g., RGB or grayscale).</p></li>
<li><p><strong>ddepth</strong>: This specifies the desired depth of the output image (destination). It determines the data type of the destination image, which can be different from the source image. Common data types include <code class="docutils literal notranslate"><span class="pre">cv2.CV_8U</span></code> for 8-bit unsigned integers, <code class="docutils literal notranslate"><span class="pre">cv2.CV_32F</span></code> for 32-bit floating-point numbers, etc.</p></li>
<li><p><strong>kernel</strong>: The kernel is a user-defined convolution matrix that defines the filter’s behavior. This parameter is essential and should be a numerical matrix (numpy array) used for filtering the source image. The kernel defines the weights applied to the image pixels to compute the output.</p></li>
<li><p><strong>dst</strong> (optional): This is the destination image, which is where the filtered result is stored. If not provided, the function creates a new image to store the result. It should have the same size and type as the source image.</p></li>
<li><p><strong>anchor</strong> (optional): This parameter denotes the relative position within the kernel. It specifies the anchor point with respect to which the convolution operation is performed. The anchor point determines the alignment of the kernel over the source image.</p></li>
<li><p><strong>delta</strong> (optional): The value added to the filtered pixels, which can be used for contrast adjustment or to shift the intensity range of the output image.</p></li>
<li><p><strong>borderType</strong> (optional): This parameter determines the border mode applied when the kernel extends beyond the edges of the source image. Common border types include constant border, replicate border, reflect border, etc.</p></li>
<li><p><strong>Returns</strong>: The function returns the filtered image, which is the result of applying the specified kernel to the input image. The destination image (dst) contains the filtered output.</p></li>
</ul>
<p>You can see the full description of the function <a class="reference external" href="https://docs.opencv.org/2.4/modules/ocl/doc/image_filtering.html?highlight=filter2d#ocl-filter2d">here</a>.</p>
<p><font color='Blue'><b>Example</b></font>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import necessary libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>  <span class="c1"># Import NumPy for array operations</span>
<span class="kn">import</span> <span class="nn">cv2</span>  <span class="c1"># Import OpenCV for image processing</span>

<span class="c1"># Define a kernel for filtering (8x8 averaging kernel)</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mi">25</span>

<span class="c1"># Apply the filter2D operation to the original image</span>
<span class="n">Out</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">filter2D</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">Img</span><span class="p">,</span>  <span class="c1"># Source image</span>
                   <span class="n">ddepth</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># Use the same depth as the source image</span>
                   <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span>  <span class="c1"># 2D array of filter coefficients</span>
                   <span class="p">)</span>

<span class="c1"># Display the original noisy image and the filtered image side by side</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ImShow</span><span class="p">(</span><span class="n">Images</span><span class="o">=</span><span class="p">[</span><span class="n">Img</span><span class="p">,</span> <span class="n">Out</span><span class="p">],</span> <span class="n">Names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;UofC&#39;</span><span class="p">,</span> <span class="s1">&#39;Filter2D (UofC)&#39;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Filter 2D on Original Image&#39;</span><span class="p">)</span>

<span class="c1"># Add text indicating the size of the original and transformed images</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.02</span> <span class="o">*</span> <span class="n">Img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">s</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Size: </span><span class="si">{</span><span class="n">Img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> by </span><span class="si">{</span><span class="n">Img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
               <span class="n">size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;square&quot;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;LightSkyBlue&#39;</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.02</span> <span class="o">*</span> <span class="n">Out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">s</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Size: </span><span class="si">{</span><span class="n">Out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> by </span><span class="si">{</span><span class="n">Out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
               <span class="n">size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;square&quot;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;LightSkyBlue&#39;</span><span class="p">))</span>

<span class="c1"># Apply the filter2D operation to the noisy image</span>
<span class="n">Out</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">filter2D</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">Img_noise</span><span class="p">,</span>  <span class="c1"># Source image with noise</span>
                   <span class="n">ddepth</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># Use the same depth as the source image</span>
                   <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span>  <span class="c1"># 2D array of filter coefficients</span>
                   <span class="p">)</span>

<span class="c1"># Display the original noisy image and the filtered image side by side</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ImShow</span><span class="p">(</span><span class="n">Images</span><span class="o">=</span><span class="p">[</span><span class="n">Img_noise</span><span class="p">,</span> <span class="n">Out</span><span class="p">],</span> <span class="n">Names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;UofC + Noise&#39;</span><span class="p">,</span> <span class="s1">&#39;Filter2D (UofC + Noise)&#39;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Filter 2D on Noisy Image&#39;</span><span class="p">)</span>

<span class="c1"># Add text indicating the size of the original and transformed images</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.02</span> <span class="o">*</span> <span class="n">Img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">s</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Size: </span><span class="si">{</span><span class="n">Img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> by </span><span class="si">{</span><span class="n">Img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
               <span class="n">size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;square&quot;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;LightSkyBlue&#39;</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.02</span> <span class="o">*</span> <span class="n">Out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">s</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Size: </span><span class="si">{</span><span class="n">Out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> by </span><span class="si">{</span><span class="n">Out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
               <span class="n">size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;square&quot;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;LightSkyBlue&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8a183b0281e9d9e2582da3b705be880ddd01dc65def88271752cacab31c1ca86.png" src="_images/8a183b0281e9d9e2582da3b705be880ddd01dc65def88271752cacab31c1ca86.png" />
<img alt="_images/08cfcb46ebdd101d163fdd6ae75fbcbaa93c36919e28ba3ee21147a1261ebfe0.png" src="_images/08cfcb46ebdd101d163fdd6ae75fbcbaa93c36919e28ba3ee21147a1261ebfe0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="image-blurring-image-smoothing">
<h2><span class="section-number">5.2. </span>Image Blurring (Image Smoothing)<a class="headerlink" href="#image-blurring-image-smoothing" title="Permalink to this heading">#</a></h2>
<p>Image blurring, also known as image smoothing or image filtering, is a fundamental image processing technique employed to mitigate high-frequency components within an image, such as noise and edges. Its primary purpose is to eliminate undesired details, resulting in a more visually cohesive and smoother appearance. Various blurring methods exist, each serving distinct purposes <span id="id3">[<a class="reference internal" href="References.html#id25" title="G. Bradski. The OpenCV Library. Dr. Dobb's Journal of Software Tools, 2000.">Bradski, 2000</a>, <a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>:</p>
<ol class="arabic simple">
<li><p><strong>Gaussian Blur</strong>: This technique employs a Gaussian kernel that convolves with the image pixels, producing a weighted average of neighboring pixels. These weights are determined by the Gaussian distribution, making it adept at reducing high-frequency noise while preserving image structure.</p></li>
<li><p><strong>Median Blur</strong>: In this approach, every pixel in the image is replaced with the median value of its neighboring pixels. It is particularly effective in removing “salt-and-pepper” noise, where isolated pixels have extreme intensity values, leading to a cleaner image.</p></li>
<li><p><strong>Bilateral Filter</strong>: A non-linear filter that considers both spatial and intensity differences during the blurring process. It excels at noise reduction while retaining the sharpness of significant image features and edges.</p></li>
<li><p><strong>Box Blur</strong>: Also known as average blur, this method replaces each pixel with the average value of its neighboring pixels. While providing a simple and uniform blurring effect, it may not preserve intricate image details as effectively as other methods.</p></li>
<li><p><strong>Motion Blur</strong>: Simulates the effect of camera or object motion, creating streak-like artifacts within the image. This blurring technique imparts a sense of movement and dynamics to the scene.</p></li>
</ol>
<p>These diverse blurring methods can be implemented using a range of image processing libraries, such as OpenCV in the Python programming language. The choice of a specific blurring technique hinges on the unique requirements of the application and the intrinsic characteristics of the image content, allowing practitioners to tailor the approach to their specific needs.</p>
<div class="section" id="box-blur-average-blur">
<h3><span class="section-number">5.2.1. </span>Box Blur (Average Blur)<a class="headerlink" href="#box-blur-average-blur" title="Permalink to this heading">#</a></h3>
<p>Box blur, also known as a box linear filter or average blur, constitutes a widespread low-pass filtering technique used to introduce image blurring. The central concept driving the box blur is to compute the value of each pixel in the resulting image by averaging the values of its neighboring pixels from the input image. This averaging operation serves to diminish high-frequency intricacies within the image, resulting in a smoother appearance.</p>
<p>The application of a box blur involves the placement of a fixed-size rectangular window, often denoted as a kernel or filter, over each pixel in the input image. The dimensions of this window dictate the degree of blurring. The value of any given pixel in the output image is determined by calculating the average of the pixel values encompassed by the window.</p>
<p>For instance, a 3x3 box blur involves averaging the pixel values within the 3x3 vicinity surrounding each pixel. This procedure is replicated for every pixel in the image, leading to the creation of a blurred version of the original image.</p>
<p>Box blur is renowned for its simplicity and computational efficiency. However, it may entail a certain loss of detail and might not retain sharp edges as effectively as some other blurring methods. It is commonly employed when a moderate level of blurring suffices, such as in image preprocessing tasks or as a foundational element within more intricate blur algorithms.</p>
<p>Various image processing libraries, including OpenCV in Python, offer functions that allow users to apply box blur filters to images, with the flexibility to adjust the kernel size. This empowers users to tailor the extent of blurring applied based on their specific requirements.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">cv2.blur</span></code> function in Python serves to apply a straightforward averaging or blurring operation to an input image. The function encompasses several essential parameters, each of which governs the behavior of the blurring operation. Here’s an enhanced description of the function signature <span id="id4">[<a class="reference internal" href="References.html#id25" title="G. Bradski. The OpenCV Library. Dr. Dobb's Journal of Software Tools, 2000.">Bradski, 2000</a>, <a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cv2</span><span class="o">.</span><span class="n">blur</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">ksize</span><span class="p">[,</span> <span class="n">dst</span><span class="p">[,</span> <span class="n">anchor</span><span class="p">[,</span> <span class="n">borderType</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">dst</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">src</span></code>: This parameter represents the input image (source) upon which the blurring operation is to be executed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ksize</span></code>: A tuple that defines the size of the kernel or blurring filter. This specification indicates the dimensions of the local neighborhood over which the averaging occurs. Larger <code class="docutils literal notranslate"><span class="pre">ksize</span></code> values yield a more pronounced blur effect.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dst</span></code>: An optional parameter, this designates the output image (destination) where the result of the blurring operation is stored. If omitted, the function generates a new image to accommodate the result.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">anchor</span></code>: This parameter, also optional, specifies the position of the anchor within the kernel. The anchor point identifies the kernel’s pixel corresponding to the center of the neighborhood under processing. When unspecified, the default is the center of the kernel.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">borderType</span></code>: Another optional parameter, it specifies the type of border extrapolation used when the kernel extends beyond the confines of the input image. Various border types are available to address this scenario, such as replicating border pixels, reflecting the image, or employing a constant value. If not explicitly provided, a default border type is employed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-&gt;</span> <span class="pre">dst</span></code>: This indicator signifies that the function yields the blurred output image (<code class="docutils literal notranslate"><span class="pre">dst</span></code>) subsequent to applying the specified blurring operation.</p></li>
</ul>
<p>This blurring operation is achieved by convolving the image with a normalized box filter. The process involves calculating the average of all the pixels within the kernel area and subsequently replacing the central element. The function <code class="docutils literal notranslate"><span class="pre">cv2.blur()</span></code> or <code class="docutils literal notranslate"><span class="pre">cv2.boxFilter()</span></code> can be employed for this purpose. For additional kernel details, reference the documentation. It’s important to specify the width and height of the kernel. For instance, a 3x3 normalized box filter appears as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-7c1efb27-7596-408d-9b8f-f522d504d621">
<span class="eqno">(5.4)<a class="headerlink" href="#equation-7c1efb27-7596-408d-9b8f-f522d504d621" title="Permalink to this equation">#</a></span>\[\begin{equation}
K = \frac{1}{9} \begin{bmatrix} 1 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 1 \end{bmatrix}
\end{equation}\]</div>
<p>You can see the full description of the function <a class="reference external" href="https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html?highlight=blur#cv2.blur">here</a>.</p>
<p><font color='Blue'><b>Example</b></font>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import necessary libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>  <span class="c1"># Import NumPy for array operations</span>
<span class="kn">import</span> <span class="nn">cv2</span>  <span class="c1"># Import OpenCV for image processing</span>

<span class="c1"># Apply the blur filter to the original image</span>
<span class="n">Out</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">blur</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">Img</span><span class="p">,</span>  <span class="c1"># Source image</span>
               <span class="n">ksize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># Kernel size for blurring</span>
              <span class="p">)</span>

<span class="c1"># Display the original noisy image and the filtered image side by side</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ImShow</span><span class="p">(</span><span class="n">Images</span><span class="o">=</span><span class="p">[</span><span class="n">Img</span><span class="p">,</span> <span class="n">Out</span><span class="p">],</span> <span class="n">Names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;UofC&#39;</span><span class="p">,</span> <span class="s1">&#39;Blurred (UofC)&#39;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Blur Filter on Original Image&#39;</span><span class="p">)</span>

<span class="c1"># Add text indicating the size of the original and transformed images</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.02</span> <span class="o">*</span> <span class="n">Img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">s</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Size: </span><span class="si">{</span><span class="n">Img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> by </span><span class="si">{</span><span class="n">Img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
               <span class="n">size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;square&quot;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;LightSkyBlue&#39;</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.02</span> <span class="o">*</span> <span class="n">Out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">s</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Size: </span><span class="si">{</span><span class="n">Out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> by </span><span class="si">{</span><span class="n">Out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
               <span class="n">size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;square&quot;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;LightSkyBlue&#39;</span><span class="p">))</span>

<span class="c1"># Apply the blur filter to the noisy image</span>
<span class="n">Out</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">blur</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">Img_noise</span><span class="p">,</span>  <span class="c1"># Source image with noise</span>
               <span class="n">ksize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>  <span class="c1"># Kernel size for blurring</span>
              <span class="p">)</span>

<span class="c1"># Display the original noisy image with noise and the filtered image side by side</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ImShow</span><span class="p">(</span><span class="n">Images</span><span class="o">=</span><span class="p">[</span><span class="n">Img_noise</span><span class="p">,</span> <span class="n">Out</span><span class="p">],</span> <span class="n">Names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;UofC + Noise&#39;</span><span class="p">,</span> <span class="s1">&#39;Blurred (UofC + Noise)&#39;</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Blur Filter on Noisy Image&#39;</span><span class="p">)</span>

<span class="c1"># Add text indicating the size of the original and transformed images</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.02</span> <span class="o">*</span> <span class="n">Img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">s</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Size: </span><span class="si">{</span><span class="n">Img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> by </span><span class="si">{</span><span class="n">Img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
               <span class="n">size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;square&quot;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;LightSkyBlue&#39;</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.02</span> <span class="o">*</span> <span class="n">Out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">s</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Size: </span><span class="si">{</span><span class="n">Out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> by </span><span class="si">{</span><span class="n">Out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
               <span class="n">size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s2">&quot;square&quot;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;Navy&#39;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;LightSkyBlue&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/33056462405f0d0a4005e7bbc3b343c0a975a25586bb2b19b10ca26a84dc54e9.png" src="_images/33056462405f0d0a4005e7bbc3b343c0a975a25586bb2b19b10ca26a84dc54e9.png" />
<img alt="_images/88d36e4654697040420233c5bdb53c1e0c8ffa690295af89cae1848c6ba2e496.png" src="_images/88d36e4654697040420233c5bdb53c1e0c8ffa690295af89cae1848c6ba2e496.png" />
</div>
</div>
<p><font color='Blue'><b>Example</b></font>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create an empty black image with a size of 800x800 pixels and 3 color channels</span>
<span class="n">Img2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">800</span><span class="p">,</span> <span class="mi">800</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>

<span class="c1"># Define the text to be added to the image</span>
<span class="n">txt</span> <span class="o">=</span> <span class="s1">&#39;Sample Text&#39;</span>

<span class="c1"># Add &#39;Sample Text&#39; to the image with specified properties</span>
<span class="n">Img2</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">Img2</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">txt</span><span class="p">,</span> <span class="n">org</span><span class="o">=</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="mi">300</span><span class="p">),</span>
                  <span class="n">fontFace</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_TRIPLEX</span><span class="p">,</span> <span class="n">fontScale</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Colors</span><span class="p">[</span><span class="s1">&#39;Yellow&#39;</span><span class="p">],</span> <span class="n">thickness</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Add another instance of &#39;Sample Text&#39; to the image with a different color and position</span>
<span class="n">Img2</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">Img2</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">txt</span><span class="p">,</span> <span class="n">org</span><span class="o">=</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="mi">400</span><span class="p">),</span>
                  <span class="n">fontFace</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_TRIPLEX</span><span class="p">,</span> <span class="n">fontScale</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Colors</span><span class="p">[</span><span class="s1">&#39;Red&#39;</span><span class="p">],</span> <span class="n">thickness</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Add one more &#39;Sample Text&#39; to the image with a different color and position</span>
<span class="n">Img2</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">Img2</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">txt</span><span class="p">,</span> <span class="n">org</span><span class="o">=</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
                  <span class="n">fontFace</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_TRIPLEX</span><span class="p">,</span> <span class="n">fontScale</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Colors</span><span class="p">[</span><span class="s1">&#39;Green&#39;</span><span class="p">],</span> <span class="n">thickness</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Generating a noisy image using mu = 0 and sigma = 80</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">80</span>
<span class="n">Img2_noise</span> <span class="o">=</span> <span class="n">Img2</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Img2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">Img2_noise</span> <span class="o">=</span> <span class="n">ImgStd</span><span class="p">(</span><span class="n">Img2_noise</span><span class="p">)</span>  <span class="c1"># Assuming ImgStd is a function for image standardization</span>

<span class="c1"># Display both the original image with text and the noisy image</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ImShow</span><span class="p">(</span><span class="n">Images</span><span class="o">=</span><span class="p">[</span><span class="n">Img2</span><span class="p">,</span> <span class="n">Img2_noise</span><span class="p">],</span>
           <span class="n">Names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Original Image&#39;</span><span class="p">,</span> <span class="s1">&#39;Noisy Image&#39;</span><span class="p">],</span>
           <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Image with Texts&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1e3f6b3f8cb7e728d0d80d538359dc8f817fd8c7d0fa413cd8709a54888ea078.png" src="_images/1e3f6b3f8cb7e728d0d80d538359dc8f817fd8c7d0fa413cd8709a54888ea078.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Apply box blur (average blur) to the noisy image (Img2_noise)</span>
<span class="n">Out</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">blur</span><span class="p">(</span><span class="n">Img2_noise</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>  <span class="c1"># Applying an average blur with a kernel size of 8x8 pixels</span>

<span class="c1"># Display both the original noisy image and the blurred image side by side</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ImShow</span><span class="p">(</span><span class="n">Images</span><span class="o">=</span><span class="p">[</span><span class="n">Img2_noise</span><span class="p">,</span> <span class="n">Out</span><span class="p">],</span>
           <span class="n">Names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Noisy Image&#39;</span><span class="p">,</span> <span class="s1">&#39;Blurred (Noisy Image)&#39;</span><span class="p">],</span>
           <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Box Blurred (Average Blur)&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/def53ead7bdf2ad5845a4fa86cf7aaf243e8671cc09c86800c0b86047e4fc8a8.png" src="_images/def53ead7bdf2ad5845a4fa86cf7aaf243e8671cc09c86800c0b86047e4fc8a8.png" />
</div>
</div>
</div>
<div class="section" id="box-filter">
<h3><span class="section-number">5.2.2. </span>Box Filter<a class="headerlink" href="#box-filter" title="Permalink to this heading">#</a></h3>
<p>The box filter is a blurring technique applied to an image using a specific kernel, which has the form of a matrix filled with ones. The primary purpose of this filter is to smooth the image. The blurring operation is performed by averaging the pixel values within a local neighborhood defined by the size of the kernel <span id="id5">[<a class="reference internal" href="References.html#id25" title="G. Bradski. The OpenCV Library. Dr. Dobb's Journal of Software Tools, 2000.">Bradski, 2000</a>, <a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>.</p>
<p>The mathematical representation of the kernel is as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-32d58f01-91e3-42e3-8567-099375398881">
<span class="eqno">(5.5)<a class="headerlink" href="#equation-32d58f01-91e3-42e3-8567-099375398881" title="Permalink to this equation">#</a></span>\[\begin{equation}
\texttt{K} = \alpha \begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; \cdots &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 1 &amp; \cdots &amp; 1 &amp; 1 \\ 
\vdots &amp; \vdots &amp; \vdots &amp;  &amp; \vdots &amp; \vdots  \\ 1 &amp; 1 &amp; 1 &amp; \cdots &amp; 1 &amp; 1 \end{bmatrix}
\end{equation} \]</div>
<p>where</p>
<div class="amsmath math notranslate nohighlight" id="equation-418fa00d-f743-4b50-bc3d-22cfe2d05d09">
<span class="eqno">(5.6)<a class="headerlink" href="#equation-418fa00d-f743-4b50-bc3d-22cfe2d05d09" title="Permalink to this equation">#</a></span>\[\begin{equation}
\alpha = \begin{cases} \frac{1}{\texttt{ksize.width*ksize.height}} &amp; \texttt{when } \texttt{normalize=true} \\1 &amp; \texttt{otherwise}\end{cases}
\end{equation} \]</div>
<p>The unnormalized box filter has a specific utility in computing integral characteristics over each pixel neighborhood. For instance, it can be employed to calculate covariance matrices of image derivatives, which are used in various algorithms like dense optical flow algorithms. However, if the goal is to compute pixel sums over windows of varying sizes, the integral image approach should be utilized.</p>
<p>The Python function <code class="docutils literal notranslate"><span class="pre">cv2.boxFilter()</span></code> is a part of the OpenCV library, which is commonly used for computer vision tasks in Python. This function performs a box filter operation on an input image (source image) and returns the result in the destination image (if provided). Here’s a refined explanation of the function signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>cv2.boxFilter(src, ddepth, ksize[, dst[, anchor[, normalize[, borderType]]]]) → dst
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">src</span></code>: The source image, on which the box filter operation will be applied.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ddepth</span></code>: The desired depth of the destination image. It specifies the data type (e.g., <code class="docutils literal notranslate"><span class="pre">cv2.CV_8U</span></code>, <code class="docutils literal notranslate"><span class="pre">cv2.CV_32F</span></code>) of the output image. The result of the filtering will be converted to this depth.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ksize</span></code>: The size of the box filter kernel. It is a tuple <code class="docutils literal notranslate"><span class="pre">(ksize_x,</span> <span class="pre">ksize_y)</span></code> representing the width and height of the kernel. The kernel size must be positive and odd.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dst</span></code>: (Optional) The destination image where the filtered result will be stored. If not provided, a new image will be created to store the result.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">anchor</span></code>: (Optional) The anchor point within the kernel. It specifies the relative position of the filtered pixel being computed. The default value is <code class="docutils literal notranslate"><span class="pre">(-1,</span> <span class="pre">-1)</span></code>, which means the anchor is at the center of the kernel.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">normalize</span></code>: (Optional) A flag that indicates whether the kernel should be normalized or not. If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the kernel is normalized to have a sum of 1. If set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, no normalization is applied. The default value is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">borderType</span></code>: (Optional) The type of border extrapolation. It determines how to handle pixels at the image borders. Common values are <code class="docutils literal notranslate"><span class="pre">cv2.BORDER_CONSTANT</span></code>, <code class="docutils literal notranslate"><span class="pre">cv2.BORDER_REPLICATE</span></code>, etc. The default value is <code class="docutils literal notranslate"><span class="pre">cv2.BORDER_DEFAULT</span></code>.</p></li>
</ul>
<p>The function returns the destination image <code class="docutils literal notranslate"><span class="pre">dst</span></code> after applying the box filter operation on the source image with the specified parameters. The box filter is a simple and commonly used filter for smoothing and blurring images. It computes the average value of pixel intensities in a local neighborhood defined by the kernel size.</p>
<p>You can see the full description of the function <a class="reference external" href="https://docs.opencv.org/2.4/modules/ocl/doc/image_filtering.html?highlight=filter2d#ocl-boxfilter">here</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a 2x2 grid of subplots for displaying images</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">9.5</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>  <span class="c1"># Flatten the subplots for easier manipulation</span>

<span class="c1"># Display the original image in the first subplot</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">Img</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original Image&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

<span class="c1"># Loop to display images with box filtering at different kernel sizes</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span>
    <span class="c1"># Calculate the kernel size based on the loop iteration</span>
    <span class="n">ksize_x</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="mi">1</span>
    
    <span class="c1"># Apply box filtering to the image and display it in the corresponding subplot</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">boxFilter</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">Img</span><span class="p">,</span> <span class="n">ddepth</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">ksize</span> <span class="o">=</span> <span class="p">(</span><span class="n">ksize_x</span><span class="p">,</span> <span class="n">ksize_x</span><span class="p">)))</span>
    
    <span class="c1"># Set the title for the subplot with information about the kernel size</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;boxFilter (Kernel Size: </span><span class="si">{</span><span class="n">ksize_x</span><span class="si">}</span><span class="s1"> by </span><span class="si">{</span><span class="n">ksize_x</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
     
<span class="c1"># Additional settings for each subplot</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="p">)):</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Set aspect ratio to 1 (square aspect)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>    <span class="c1"># Turn off axis</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Various Kernel Sizes for cv2.boxFilter&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="c1"># Ensure tight layout for better spacing</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/de321f10d0b164173a6dea1af73c8d7c1904429a6ad9a3919e3a817fd20a1e83.png" src="_images/de321f10d0b164173a6dea1af73c8d7c1904429a6ad9a3919e3a817fd20a1e83.png" />
</div>
</div>
<p>This code creates a visual comparison of the original image and the image obtained by applying the <code class="docutils literal notranslate"><span class="pre">cv2.boxFilter</span></code> operation with different kernel sizes. The results are displayed in a 2x2 grid of subplots, each with appropriate titles and annotations indicating the kernel size used.</p>
</div>
<div class="section" id="gaussian-blur">
<h3><span class="section-number">5.2.3. </span>Gaussian Blur<a class="headerlink" href="#gaussian-blur" title="Permalink to this heading">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">cv2.GaussianBlur()</span></code> function in Python is a part of the OpenCV library, widely used for image processing and computer vision tasks. This function applies Gaussian blurring to an input image (source image) and returns the result in the destination image (if provided) <span id="id6">[<a class="reference internal" href="References.html#id25" title="G. Bradski. The OpenCV Library. Dr. Dobb's Journal of Software Tools, 2000.">Bradski, 2000</a>, <a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>.</p>
<p>This function is used to generate a Gaussian kernel, often used in image processing for tasks like blurring and smoothing. Let’s break down the documentation and its parameters academically:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ksize</span></code>: This parameter represents the aperture size of the Gaussian kernel. It should be an odd, positive integer. In mathematical terms, it must satisfy the condition <code class="docutils literal notranslate"><span class="pre">(ksize</span> <span class="pre">%</span> <span class="pre">2)</span> <span class="pre">==</span> <span class="pre">1</span></code>. The kernel size determines the size of the kernel matrix.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sigma</span></code>: The Gaussian standard deviation. This parameter controls the spread or “width” of the Gaussian distribution. If it is non-positive (e.g., zero or negative), the function computes <code class="docutils literal notranslate"><span class="pre">sigma</span></code> from <code class="docutils literal notranslate"><span class="pre">ksize</span></code> using the formula <code class="docutils literal notranslate"><span class="pre">sigma</span> <span class="pre">=</span> <span class="pre">0.3</span> <span class="pre">*</span> <span class="pre">((ksize</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">*</span> <span class="pre">0.5</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">+</span> <span class="pre">0.8</span></code>. This calculation ensures that a reasonable standard deviation is chosen based on the kernel size.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ktype</span></code>: This parameter specifies the type of filter coefficients. It can take one of two values: <code class="docutils literal notranslate"><span class="pre">cv2.CV_32F</span></code> for 32-bit floating-point coefficients or <code class="docutils literal notranslate"><span class="pre">cv2.CV_64F</span></code> for 64-bit floating-point coefficients. The choice of data type affects the precision of the filter coefficients.</p></li>
</ul>
<p>The function <code class="docutils literal notranslate"><span class="pre">cv2.getGaussianKernel</span></code> calculates and returns a <code class="docutils literal notranslate"><span class="pre">ksize</span> <span class="pre">x</span> <span class="pre">1</span></code> matrix (column vector) containing the Gaussian filter coefficients. The coefficients are computed using the Gaussian function formula:</p>
<div class="amsmath math notranslate nohighlight" id="equation-7fffb952-60e2-42af-819e-1e00d4fff7c2">
<span class="eqno">(5.7)<a class="headerlink" href="#equation-7fffb952-60e2-42af-819e-1e00d4fff7c2" title="Permalink to this equation">#</a></span>\[\begin{equation}G_i = \alpha \cdot \exp\left({-\frac{(i - \frac{{\text{ksize}} - 1}{2})^2}{2 \cdot \text{sigma}^2}}\right)
\end{equation}\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(i\)</span> ranges from 0 to <code class="docutils literal notranslate"><span class="pre">ksize</span> <span class="pre">-</span> <span class="pre">1</span></code>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span> is a scale factor chosen so that the sum of all Gaussian filter coefficients equals 1: <span class="math notranslate nohighlight">\(\sum_i G_i = 1\)</span>.</p></li>
</ul>
<p>The generated Gaussian kernel is typically used in image filtering operations to apply Gaussian smoothing to an image. Gaussian smoothing helps reduce noise and blur the image in a controlled manner. The kernel can be passed to functions like <code class="docutils literal notranslate"><span class="pre">sepFilter2D</span></code> or <code class="docutils literal notranslate"><span class="pre">createSeparableLinearFilter</span></code>, which are designed to work with kernels efficiently. Alternatively, you can use the higher-level function <code class="docutils literal notranslate"><span class="pre">GaussianBlur</span></code> in OpenCV to apply Gaussian smoothing directly to an image.</p>
<p>For more details, please see <a class="reference external" href="https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html?highlight=cv2.blur#gaussianblur">Gaussian Blur</a>.</p>
<p>The formula used in <code class="docutils literal notranslate"><span class="pre">cv2.getGaussianKernel</span></code> for computing Gaussian filter coefficients is a discretized version of the continuous Gaussian function. Let’s explore the relationship between the two:</p>
<ol class="arabic">
<li><p><strong>Continuous Gaussian Function</strong>:</p>
<ul>
<li><p>The continuous Gaussian function is a mathematical function used to describe the Gaussian probability distribution. It’s defined as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-cc629176-cbd3-4595-942b-2045185886e5">
<span class="eqno">(5.8)<a class="headerlink" href="#equation-cc629176-cbd3-4595-942b-2045185886e5" title="Permalink to this equation">#</a></span>\[\begin{equation}G(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x - \mu)^2}{2\sigma^2}}\end{equation}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is the continuous independent variable.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mu\)</span> (mu) is the mean (average) value.</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma\)</span> (sigma) is the standard deviation, controlling the spread or width.</p></li>
<li><p><span class="math notranslate nohighlight">\(e\)</span> is the base of the natural logarithm (approximately 2.71828).</p></li>
<li><p><span class="math notranslate nohighlight">\(\pi\)</span> is the mathematical constant pi (approximately 3.14159).</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Discretized Gaussian Kernel</strong> (from <code class="docutils literal notranslate"><span class="pre">cv2.getGaussianKernel</span></code>):</p>
<ul>
<li><p>The formula for computing <span class="math notranslate nohighlight">\(G_i\)</span> in the discretized Gaussian kernel is as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-7f3cb06c-f77b-415a-bc2d-757c829f0280">
<span class="eqno">(5.9)<a class="headerlink" href="#equation-7f3cb06c-f77b-415a-bc2d-757c829f0280" title="Permalink to this equation">#</a></span>\[\begin{equation}G_i = \alpha \cdot \exp\left(-\frac{(i - \frac{{\text{ksize}} - 1}{2})^2}{2 \cdot \text{sigma}^2}\right)\end{equation}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(i\)</span> ranges from 0 to <code class="docutils literal notranslate"><span class="pre">ksize</span> <span class="pre">-</span> <span class="pre">1</span></code>, representing discrete positions within the kernel.</p></li>
<li><p><span class="math notranslate nohighlight">\(\frac{{\text{ksize}} - 1}{2}\)</span> represents the center position of the kernel, ensuring symmetry.</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{sigma}\)</span> is the standard deviation, controlling the width of the Gaussian distribution.</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span> is a scaling factor to normalize the kernel weights.</p></li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>Relationship</strong>:</p>
<ul class="simple">
<li><p>The relationship between the two formulas lies in their underlying concept.</p></li>
<li><p>The continuous Gaussian function describes a smooth, continuous distribution.</p></li>
<li><p>The discretized Gaussian kernel is an approximation of this continuous function, suitable for use in discrete systems like digital image processing.</p></li>
<li><p>By discretizing the Gaussian function, we obtain a set of discrete weights (the <span class="math notranslate nohighlight">\(G_i\)</span> values) that approximate the behavior of the continuous Gaussian distribution.</p></li>
<li><p>These weights are used as coefficients in a convolution operation to achieve Gaussian smoothing or blurring in digital images.</p></li>
</ul>
<p><font color='Blue'><b>Example</b></font>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a 2x2 grid of subplots for displaying images</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">9.5</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>  <span class="c1"># Flatten the subplots for easier manipulation</span>

<span class="c1"># Display the original image in the first subplot</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">Img</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original Image&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

<span class="c1"># Loop to display images with Gaussian blur at different kernel sizes</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span>
    <span class="c1"># Calculate the kernel size based on the loop iteration</span>
    <span class="n">ksize_x</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="mi">1</span>
    
    <span class="c1"># Apply Gaussian blur to the image and display it in the corresponding subplot</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">Img</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="p">(</span><span class="n">ksize_x</span><span class="p">,</span> <span class="n">ksize_x</span><span class="p">),</span> <span class="n">sigmaX</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    
    <span class="c1"># Set the title for the subplot with information about the kernel size</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;GaussianBlur (Kernel Size: </span><span class="si">{</span><span class="n">ksize_x</span><span class="si">}</span><span class="s1"> by </span><span class="si">{</span><span class="n">ksize_x</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    
<span class="c1"># Additional settings for each subplot</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="p">)):</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Set aspect ratio to 1 (square aspect)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>    <span class="c1"># Turn off axis</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Various Kernel Sizes for cv2.GaussianBlur&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="c1"># Ensure tight layout for better spacing</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/374dd01b28c3dd220bf9529607f0473db45d664fa984b3bce974973de59dd8e0.png" src="_images/374dd01b28c3dd220bf9529607f0473db45d664fa984b3bce974973de59dd8e0.png" />
</div>
</div>
</div>
<div class="section" id="median-blur">
<h3><span class="section-number">5.2.4. </span>Median Blur<a class="headerlink" href="#median-blur" title="Permalink to this heading">#</a></h3>
<p>The median blur technique is a valuable image filtering method primarily used for noise reduction while preserving the edges and finer details in an image. This technique is especially effective at mitigating the impact of “salt-and-pepper” noise, which are isolated, randomly occurring bright or dark pixels that can distort the appearance of an image. The median blur operation computes the median value within a local neighborhood (specified by a kernel) for each pixel, effectively reducing the influence of noise outliers.</p>
<p>For a more detailed exploration of the median filter, you can refer to the research paper titled “<a class="reference external" href="https://www.uio.no/studier/emner/matnat/ifi/INF2310/v12/undervisningsmateriale/artikler/Huang-etal-median.pdf">A Fast Two-Dimensional Median Filtering Algorithm</a>” by Thomas S. Huang et al. <span id="id7">[<a class="reference internal" href="References.html#id27" title="Thomas Huang, GJTGY Yang, and Greory Tang. A fast two-dimensional median filtering algorithm. IEEE transactions on acoustics, speech, and signal processing, 27(1):13–18, 1979.">Huang <em>et al.</em>, 1979</a>]</span>.</p>
<p>In OpenCV, the <a class="reference external" href="https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html?highlight=cv2.blur#medianblur">Median Blur</a> function, denoted as <code class="docutils literal notranslate"><span class="pre">cv2.medianBlur()</span></code>, provides a convenient way to apply the median blur operation to an image. This function is widely used in computer vision tasks and image processing pipelines to enhance the quality of images by reducing noise while preserving important image structures.</p>
<!-- The key advantage of median blur is its ability to effectively handle various types of noise, making it a crucial tool in image preprocessing and denoising applications. It's particularly useful when other blurring methods might smear the edges or fine features of an image, which is not the case with median blur. -->
<p><strong>Function Signature:</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>cv2.medianBlur(src, ksize[, dst]) → dst
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">src</span></code>: The source image to which median blurring will be applied.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ksize</span></code>: The size of the median filter kernel. It specifies the window over which the median is computed. The kernel size must be a positive odd integer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dst</span></code>: (Optional) The destination image where the median-blurred result will be stored. If not provided, a new image will be created to store the result.</p></li>
</ul>
<p>The function employs a median filter to smooth an image, utilizing a square aperture of size <code class="docutils literal notranslate"><span class="pre">ksize</span> <span class="pre">x</span> <span class="pre">ksize</span></code>. It’s important to note that each channel of a multi-channel image is processed independently, and the operation can be performed in-place if needed.</p>
<p><strong>Output:</strong>
The function returns the destination image <code class="docutils literal notranslate"><span class="pre">dst</span></code> after applying median blurring to the source image with the specified parameters. Median blurring is a non-linear image filtering technique that is particularly effective at reducing salt-and-pepper noise in images.</p>
<p><strong>Note:</strong></p>
<ul class="simple">
<li><p>The median filter works by replacing the value of each pixel in the image with the median value of the pixel intensities within the specified window (kernel) centered around that pixel.</p></li>
<li><p>Median blurring is especially useful for preserving edges and fine details in an image while reducing noise, making it a valuable tool in various image enhancement and denoising applications.</p></li>
<li><p>The choice of <code class="docutils literal notranslate"><span class="pre">ksize</span></code> determines the size of the local neighborhood used for median computation. Larger <code class="docutils literal notranslate"><span class="pre">ksize</span></code> values provide more aggressive noise reduction but may also result in some loss of detail.</p></li>
<li><p>OpenCV’s <code class="docutils literal notranslate"><span class="pre">cv2.medianBlur()</span></code> function is a commonly used method for noise reduction and is a key component in image pre-processing pipelines.</p></li>
</ul>
<p><font color='Blue'><b>Example</b></font>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a 2x2 grid of subplots for displaying images</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">9.5</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>  <span class="c1"># Flatten the subplots for easier manipulation</span>

<span class="c1"># Display the original image in the first subplot</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">Img</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original Image&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

<span class="c1"># Loop to display images with median filtering at different kernel sizes</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span>
    <span class="c1"># Calculate the kernel size based on the loop iteration</span>
    <span class="n">ksize_x</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span>
    
    <span class="c1"># Apply median filtering to the image and display it in the corresponding subplot</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">medianBlur</span><span class="p">(</span><span class="n">Img</span><span class="p">,</span> <span class="n">ksize_x</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">BORDER_DEFAULT</span><span class="p">))</span>
    
    <span class="c1"># Set the title for the subplot with information about the kernel size</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;medianBlur (Image)&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
        
<span class="c1"># Additional settings for each subplot</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="p">)):</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Set aspect ratio to 1 (square aspect)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>    <span class="c1"># Turn off axis</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Various Kernel Sizes for cv2.GaussianBlur&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="c1"># Ensure tight layout for better spacing</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/01a0c87914cb8ae15baed932cf86aec2d5f13135c5faf5e1a9b0db5f7df98912.png" src="_images/01a0c87914cb8ae15baed932cf86aec2d5f13135c5faf5e1a9b0db5f7df98912.png" />
</div>
</div>
</div>
<div class="section" id="bilateral-filtering">
<h3><span class="section-number">5.2.5. </span>Bilateral Filtering<a class="headerlink" href="#bilateral-filtering" title="Permalink to this heading">#</a></h3>
<p>A <strong>bilateral filter</strong> is a sophisticated image smoothing technique that is non-linear, preserves edges, and reduces noise. It operates by combining neighboring pixel values in a way that considers both the differences in pixel intensities (referred to as the “range”) and the spatial distances between pixels. This unique combination allows the bilateral filter to effectively smooth an image while retaining important features such as edges.</p>
<p>The mathematical definition of the bilateral filter can be expressed as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-8a2782ff-1d72-438b-bae5-15c782fe7d01">
<span class="eqno">(5.10)<a class="headerlink" href="#equation-8a2782ff-1d72-438b-bae5-15c782fe7d01" title="Permalink to this equation">#</a></span>\[\begin{equation}I^{\text{filtered}}(x) = \frac{1}{W_{p}} \sum_{x_{i}\in \Omega} I(x_{i}) f_{r}(\|I(x_{i})-I(x)\|) g_{s}(\|x_{i}-x\|).\end{equation}\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(I^{\text{filtered}}\)</span> is the resulting filtered image.</p></li>
<li><p><span class="math notranslate nohighlight">\(I\)</span> is the original input image to be filtered.</p></li>
<li><p><span class="math notranslate nohighlight">\(x\)</span> represents the coordinates of the current pixel being filtered.</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the window centered at <span class="math notranslate nohighlight">\(x\)</span>, and <span class="math notranslate nohighlight">\(x_{i}\)</span> refers to another pixel within this window.</p></li>
<li><p><span class="math notranslate nohighlight">\(f_r\)</span> is the range kernel, used for smoothing differences in pixel intensities. This function is often represented as a Gaussian function.</p></li>
<li><p><span class="math notranslate nohighlight">\(g_{s}\)</span> is the spatial (or domain) kernel, used for smoothing differences in pixel coordinates. This function is often represented as a Gaussian function.</p></li>
<li><p><span class="math notranslate nohighlight">\(W_{p}\)</span> is the normalization term, which ensures that the filtered pixel value is properly weighted based on the contributions of neighboring pixels.</p></li>
</ul>
<p>For a detailed understanding of the bilateral filter, you can refer to the article <a class="reference external" href="http://www.dai.ed.ac.uk/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html">Bilateral Filtering for Gray and Color Images</a>. Additionally, for the adaptive bilateral filter, you may be interested in the work by Gavaskar et al. <span id="id8">[<a class="reference internal" href="References.html#id28" title="Ruturaj G Gavaskar and Kunal N Chaudhury. Fast adaptive bilateral filtering. IEEE Transactions on Image Processing, 28(2):779–790, 2018.">Gavaskar and Chaudhury, 2018</a>]</span>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">cv2.bilateralFilter()</span></code> function in Python is a part of the OpenCV library, commonly used for image processing tasks. This function applies bilateral filtering to an input image (source image) and returns the result in the destination image (if provided) <span id="id9">[<a class="reference internal" href="References.html#id25" title="G. Bradski. The OpenCV Library. Dr. Dobb's Journal of Software Tools, 2000.">Bradski, 2000</a>, <a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>.</p>
<p><strong>Function Signature:</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>cv2.bilateralFilter(src, d, sigmaColor, sigmaSpace[, dst[, borderType]]) → dst
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">src</span></code>: The source image to which bilateral filtering will be applied.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">d</span></code>: Diameter of each pixel neighborhood used for filtering. It specifies the size of the pixel neighborhood, which affects the amount of blurring. Larger <code class="docutils literal notranslate"><span class="pre">d</span></code> values result in more smoothing across a wider region.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sigmaColor</span></code>: The standard deviation of the color space. It influences the color similarity between the central pixel and its neighbors. A larger <code class="docutils literal notranslate"><span class="pre">sigmaColor</span></code> value allows for more variation in color within the neighborhood while still preserving edges.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sigmaSpace</span></code>: The standard deviation of the coordinate space. It influences the spatial proximity between the central pixel and its neighbors. A larger <code class="docutils literal notranslate"><span class="pre">sigmaSpace</span></code> value causes pixels that are farther away from the central pixel to have a reduced influence on the filtering.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dst</span></code>: (Optional) The destination image where the filtered result will be stored. If not provided, a new image will be created to store the result.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">borderType</span></code>: (Optional) The type of border extrapolation. It determines how to handle pixels at the image borders. Common values are <code class="docutils literal notranslate"><span class="pre">cv2.BORDER_CONSTANT</span></code>, <code class="docutils literal notranslate"><span class="pre">cv2.BORDER_REPLICATE</span></code>, etc. The default value is <code class="docutils literal notranslate"><span class="pre">cv2.BORDER_DEFAULT</span></code>.</p></li>
</ul>
<p><strong>Output:</strong>
The function returns the destination image <code class="docutils literal notranslate"><span class="pre">dst</span></code> after applying bilateral filtering to the source image with the specified parameters. Bilateral filtering is a non-linear filtering technique that preserves edges in the image while reducing noise, making it especially useful for image smoothing without blurring important features.</p>
<p><strong>Note:</strong></p>
<ul class="simple">
<li><p>The bilateral filter considers both the intensity differences (controlled by <code class="docutils literal notranslate"><span class="pre">sigmaColor</span></code>) and the spatial distances (controlled by <code class="docutils literal notranslate"><span class="pre">sigmaSpace</span></code>) between pixels. This makes it effective at preserving edges and fine details while reducing noise.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">d</span></code> parameter determines the size of the filtering neighborhood, and both <code class="docutils literal notranslate"><span class="pre">sigmaColor</span></code> and <code class="docutils literal notranslate"><span class="pre">sigmaSpace</span></code> control the extent of blurring. Adjusting these parameters allows users to achieve the desired level of smoothing.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">cv2.bilateralFilter()</span></code> function is a versatile tool for various image enhancement tasks, denoising, and detail-preserving smoothing in computer vision applications.</p></li>
</ul>
<p>See <a class="reference external" href="https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html?highlight=cv2.blur#bilateralfilter">Bilateral Filtering</a> for more details.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a 2x2 grid of subplots for displaying images</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">9.5</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>  <span class="c1"># Flatten the subplots for easier manipulation</span>

<span class="c1"># Display the original image in the first subplot</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">Img</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original Image&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

<span class="c1"># Loop to display images with bilateral filtering at different diameters</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span>
    <span class="c1"># Calculate the diameter based on the loop iteration</span>
    <span class="n">diameter</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="mi">1</span>
    
    <span class="c1"># Apply bilateral filtering to the image and display it in the corresponding subplot</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">bilateralFilter</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">Img</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">diameter</span><span class="p">,</span> <span class="n">sigmaColor</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">sigmaSpace</span><span class="o">=</span><span class="mi">75</span><span class="p">))</span>
    
    <span class="c1"># Set the title for the subplot with information about the diameter</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;bilateralFilter (Diameter = </span><span class="si">{</span><span class="n">diameter</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    
<span class="c1"># Additional settings for each subplot</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="p">)):</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Set aspect ratio to 1 (square aspect)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>    <span class="c1"># Turn off axis</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Various Kernel Sizes for cv2.bilateralFilter&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="c1"># Ensure tight layout for better spacing</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/737133559013ce302c5754d7b37610d16adc70e30a7e747c468b06e9f32f02d3.png" src="_images/737133559013ce302c5754d7b37610d16adc70e30a7e747c468b06e9f32f02d3.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a 2x2 grid of subplots for displaying images</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">9.5</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>  <span class="c1"># Flatten the subplots for easier manipulation</span>

<span class="c1"># Display the original noisy image in the first subplot</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">Img_noise</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original Noisy Image&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

<span class="c1"># Loop to display images with bilateral filtering at different diameters</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span>
    <span class="c1"># Calculate the diameter based on the loop iteration</span>
    <span class="n">diameter</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="mi">1</span>
    
    <span class="c1"># Apply bilateral filtering to the noisy image and display it in the corresponding subplot</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">bilateralFilter</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">Img_noise</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="n">diameter</span><span class="p">,</span> <span class="n">sigmaColor</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">sigmaSpace</span><span class="o">=</span><span class="mi">75</span><span class="p">))</span>
    
    <span class="c1"># Set the title for the subplot with information about the diameter</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;bilateralFilter (Diameter = </span><span class="si">{</span><span class="n">diameter</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

<span class="c1"># Additional settings for each subplot</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="p">)):</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Set aspect ratio to 1 (square aspect)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>    <span class="c1"># Turn off axis</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Various Kernel Sizes for cv2.bilateralFilter&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="c1"># Ensure tight layout for better spacing</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/53da9e16e132b0259c841423af313d32f376e658a476f04af93fa76f24786204.png" src="_images/53da9e16e132b0259c841423af313d32f376e658a476f04af93fa76f24786204.png" />
</div>
</div>
</div>
</div>
<div class="section" id="feature-detection">
<h2><span class="section-number">5.3. </span>Feature Detection<a class="headerlink" href="#feature-detection" title="Permalink to this heading">#</a></h2>
<div class="section" id="sobel-derivatives">
<h3><span class="section-number">5.3.1. </span>Sobel Derivatives<a class="headerlink" href="#sobel-derivatives" title="Permalink to this heading">#</a></h3>
<p><strong>Sobel Operator</strong></p>
<ol class="arabic simple">
<li><p>The Sobel Operator is a mathematical tool commonly used in image processing. Its primary purpose is to help us understand how rapidly the intensity of an image changes at each point. In simpler terms, it helps identify edges and details within an image <span id="id10">[<a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>.</p></li>
<li><p>What makes the Sobel Operator particularly useful is that it combines two fundamental image processing techniques: smoothing and differentiation <span id="id11">[<a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>.</p></li>
</ol>
<p><strong>Formulation</strong></p>
<p>Assuming we have an image, denoted as <span class="math notranslate nohighlight">\(I\)</span>:</p>
<ol class="arabic">
<li><p><strong>Derivative Calculation:</strong></p>
<ul class="simple">
<li><p>To begin, we want to find out how the image changes in the horizontal (left to right) direction. This is done by applying a mathematical operation called convolution between the image <span class="math notranslate nohighlight">\(I\)</span> and a specific pattern called the “kernel.” The kernel used for horizontal changes is denoted as <span class="math notranslate nohighlight">\(G_x\)</span>. When we have a 3x3 kernel, it looks like this:</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-9e4baac0-c646-4ab2-abcb-cb4ff24ab043">
<span class="eqno">(5.11)<a class="headerlink" href="#equation-9e4baac0-c646-4ab2-abcb-cb4ff24ab043" title="Permalink to this equation">#</a></span>\[\begin{equation} G_x = \begin{bmatrix} -1 &amp; 0 &amp; +1 \\ -2 &amp; 0 &amp; +2 \\ -1 &amp; 0 &amp; +1 \end{bmatrix} \end{equation}\]</div>
<ul class="simple">
<li><p>In parallel, we also want to know how the image changes vertically (from top to bottom). To do this, we apply another convolution with a different kernel called <span class="math notranslate nohighlight">\(G_y\)</span>, which, with a 3x3 size, appears as:</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-7623b49d-584f-435e-bc8b-b2e0216db9de">
<span class="eqno">(5.12)<a class="headerlink" href="#equation-7623b49d-584f-435e-bc8b-b2e0216db9de" title="Permalink to this equation">#</a></span>\[\begin{equation} G_y = \begin{bmatrix} -1 &amp; -2 &amp; -1 \\ 0 &amp; 0 &amp; 0 \\ +1 &amp; +2 &amp; +1 \end{bmatrix} \end{equation}\]</div>
<p>These convolution operations reveal how the intensity of the image varies in both horizontal and vertical directions.</p>
</li>
<li><p><strong>Gradient Approximation:</strong></p>
<ul class="simple">
<li><p>Now that we have these two sets of information (horizontal and vertical changes), we want to combine them to find an overall measure of change at each point in the image. This is typically done using a method called the “gradient”.</p></li>
<li><p>The gradient at each point is calculated as <span id="id12">[<a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>:</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-d47ae711-bf28-4e5c-822c-4229c079c133">
<span class="eqno">(5.13)<a class="headerlink" href="#equation-d47ae711-bf28-4e5c-822c-4229c079c133" title="Permalink to this equation">#</a></span>\[\begin{equation} G = \sqrt{ G_{x}^{2} + G_{y}^{2} } \end{equation}\]</div>
<p>This equation computes the magnitude of change by taking the square root of the sum of squared changes in both directions. It provides a measure of how “edgy” or “smooth” the image is at each point <span id="id13">[<a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>.</p>
<ul class="simple">
<li><p>Alternatively, for simplicity and computational efficiency, we can use the “L1 Norm” to approximate the gradient:</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-c168433d-5df7-4767-8107-c6b33b035be7">
<span class="eqno">(5.14)<a class="headerlink" href="#equation-c168433d-5df7-4767-8107-c6b33b035be7" title="Permalink to this equation">#</a></span>\[\begin{equation} G = |G_{x}| + |G_{y}| \end{equation}\]</div>
<p>This version considers the absolute values of the changes in both directions and can still be useful in edge detection.</p>
</li>
</ol>
<p><strong>Kernel Size and Accuracy</strong></p>
<p>When using a small kernel size, such as 3x3, the Sobel operator may produce noticeable inaccuracies in edge detection. This is because the Sobel operator is, fundamentally, an approximation of the derivative of an image <span id="id14">[<a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>.</p>
<p><strong>Improved Accuracy with Scharr Operator</strong></p>
<p>To address this issue and achieve higher accuracy, OpenCV provides the Scharr() function. The Scharr operator is not only faster but also more accurate than the standard Sobel function, especially when dealing with small kernel sizes <span id="id15">[<a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>.</p>
<p><strong>Scharr Kernels</strong></p>
<p>The Scharr operator implements the following kernels for gradient calculation:</p>
<ul class="simple">
<li><p><strong>Horizontal Changes (<span class="math notranslate nohighlight">\(G_x\)</span>):</strong>
\begin{equation}
G_{x} = \begin{bmatrix} -3 &amp; 0 &amp; +3 \ -10 &amp; 0 &amp; +10 \ -3 &amp; 0 &amp; +3 \end{bmatrix}
\end{equation}</p></li>
<li><p><strong>Vertical Changes (<span class="math notranslate nohighlight">\(G_y\)</span>):</strong>
\begin{equation}
G_{y} = \begin{bmatrix} -3 &amp; -10 &amp; -3 \ 0 &amp; 0 &amp; 0 \ +3 &amp; +10 &amp; +3 \end{bmatrix}
\end{equation}</p></li>
</ul>
<p>These Scharr kernels are designed to provide a more accurate estimation of gradient changes, especially in scenarios where fine details and small features need to be detected. They are particularly useful when working with kernel sizes as small as 3x3, where the standard Sobel operator might fall short in terms of accuracy.</p>
<p>For more in-depth information and practical examples on Sobel and Scharr operators, you can explore the <a class="reference external" href="https://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/sobel_derivatives/sobel_derivatives.html?highlight=scharr">Sobel Derivatives</a> documentation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">io</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Load and convert the image to grayscale</span>
<span class="n">img_url</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;https://conted.ucalgary.ca/maincampus/maincampus.jpg&#39;</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">img_url</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>

<span class="c1"># Calculate the gradient using the Sobel operator</span>
<span class="n">gradient_x</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Sobel</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CV_64F</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">gradient_y</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Sobel</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CV_64F</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Calculate the magnitude and direction of the gradient</span>
<span class="n">gradient_magnitude</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">gradient_x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">gradient_y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">gradient_direction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctan2</span><span class="p">(</span><span class="n">gradient_y</span><span class="p">,</span> <span class="n">gradient_x</span><span class="p">)</span>

<span class="c1"># Create a 3x2 grid of subplots for displaying images</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">9.5</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">delaxes</span><span class="p">(</span><span class="n">ax</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># Remove the last subplot</span>

<span class="c1"># Plot the gradient components</span>
<span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">img</span><span class="p">,</span> <span class="n">gradient_x</span><span class="p">,</span> <span class="n">gradient_y</span><span class="p">,</span> <span class="n">gradient_direction</span><span class="p">,</span> <span class="n">gradient_magnitude</span><span class="p">]</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Original Image (Grayscale)&#39;</span><span class="p">,</span> <span class="s1">&#39;Gradient X&#39;</span><span class="p">,</span> <span class="s1">&#39;Gradient Y&#39;</span><span class="p">,</span> <span class="s1">&#39;Gradient Direction&#39;</span><span class="p">,</span> <span class="s1">&#39;Gradient Magnitude&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">title</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">titles</span><span class="p">)):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">NORM_MINMAX</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CV_8U</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

    <span class="c1"># Additional settings for each subplot</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Set aspect ratio to 1 (square aspect)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>    <span class="c1"># Turn off axis</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Sobel Derivatives&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="c1"># Ensure tight layout for better spacing</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/59f09964099a1b60b10edbaab4e1c4cdb922a37f8fc6628defda64c86084fb6e.png" src="_images/59f09964099a1b60b10edbaab4e1c4cdb922a37f8fc6628defda64c86084fb6e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">io</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Load and convert the image to grayscale</span>
<span class="n">img_url</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;https://conted.ucalgary.ca/maincampus/maincampus.jpg&#39;</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">img_url</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>

<span class="c1"># Calculate the gradient using the Sobel operator</span>
<span class="n">gradient_x</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Scharr</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CV_64F</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">gradient_y</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Scharr</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CV_64F</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Calculate the magnitude and direction of the gradient</span>
<span class="n">gradient_magnitude</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">gradient_x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">gradient_y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">gradient_direction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctan2</span><span class="p">(</span><span class="n">gradient_y</span><span class="p">,</span> <span class="n">gradient_x</span><span class="p">)</span>

<span class="c1"># Create a 3x2 grid of subplots for displaying images</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">9.5</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">delaxes</span><span class="p">(</span><span class="n">ax</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># Remove the last subplot</span>

<span class="c1"># Plot the gradient components</span>
<span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">img</span><span class="p">,</span> <span class="n">gradient_x</span><span class="p">,</span> <span class="n">gradient_y</span><span class="p">,</span> <span class="n">gradient_direction</span><span class="p">,</span> <span class="n">gradient_magnitude</span><span class="p">]</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Original Image (Grayscale)&#39;</span><span class="p">,</span> <span class="s1">&#39;Gradient X&#39;</span><span class="p">,</span> <span class="s1">&#39;Gradient Y&#39;</span><span class="p">,</span> <span class="s1">&#39;Gradient Direction&#39;</span><span class="p">,</span> <span class="s1">&#39;Gradient Magnitude&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">title</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">titles</span><span class="p">)):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">NORM_MINMAX</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CV_8U</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

    <span class="c1"># Additional settings for each subplot</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Set aspect ratio to 1 (square aspect)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>    <span class="c1"># Turn off axis</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Scharr Derivatives&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="c1"># Ensure tight layout for better spacing</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/fc604cbb0c8c193423df4012e2de5d331b669e28b007a83a552f75e9082dc353.png" src="_images/fc604cbb0c8c193423df4012e2de5d331b669e28b007a83a552f75e9082dc353.png" />
</div>
</div>
</div>
<div class="section" id="canny-edge-detection-algorithm">
<h3><span class="section-number">5.3.2. </span>Canny Edge Detection Algorithm<a class="headerlink" href="#canny-edge-detection-algorithm" title="Permalink to this heading">#</a></h3>
<p>Canny Edge Detection is a widely employed algorithm for detecting edges in images, introduced by John F. Canny <span id="id16">[<a class="reference internal" href="References.html#id140" title="John Canny. A computational approach to edge detection. IEEE Transactions on pattern analysis and machine intelligence, pages 679–698, 1986.">Canny, 1986</a>]</span>. This multi-stage algorithm involves the following key steps:</p>
<ol class="arabic">
<li><p><strong>Noise Reduction</strong>: To mitigate the impact of image noise, a 5x5 Gaussian filter is applied to the image. This step aims to enhance the overall quality of the image by reducing noise artifacts <span id="id17">[<a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>.</p></li>
<li><p><strong>Intensity Gradient Calculation</strong>: Following noise reduction, the smoothened image undergoes gradient calculations in both horizontal (<span class="math notranslate nohighlight">\(G_x\)</span>) and vertical (<span class="math notranslate nohighlight">\(G_y\)</span>) directions. These gradients are used to determine the edge gradient magnitude (<span class="math notranslate nohighlight">\(G\)</span>) and direction (<span class="math notranslate nohighlight">\(\theta\)</span>) for each pixel <span id="id18">[<a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-996befb7-0338-4b76-ac85-601742205af0">
<span class="eqno">(5.15)<a class="headerlink" href="#equation-996befb7-0338-4b76-ac85-601742205af0" title="Permalink to this equation">#</a></span>\[\begin{align}
G &amp;= \sqrt{G_x^2 + G_y^2}\\
\theta &amp;= \tan^{-1} \left(\frac{G_y}{G_x}\right)
\end{align}\]</div>
<p>It’s essential to note that the gradient direction is always perpendicular to the edges and is quantized to one of four angles, representing vertical, horizontal, and two diagonal directions <span id="id19">[<a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>.</p>
</li>
<li><p><strong>Non-maximum Suppression</strong>: In this stage, a comprehensive scan of the image is conducted to eliminate extraneous pixels that do not constitute edges. For each pixel, a check is performed to ascertain if it is a local maximum within its neighborhood along the gradient direction. If a pixel qualifies as a local maximum, it is retained for subsequent stages; otherwise, it is suppressed (set to zero) <span id="id20">[<a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>.</p></li>
</ol>
<div class="figure align-center" id="id24">
<a class="reference internal image-reference" href="_images/nms.jpg"><img alt="_images/nms.jpg" src="_images/nms.jpg" style="width: 600px;" /></a>
<p class="caption"><span class="caption-number">Fig. 5.2 </span><span class="caption-text">Point A resides on the edge in the vertical direction, and the gradient direction aligns perpendicularly to this edge. Points B and C lie along the gradient directions. Point A is subject to evaluation by comparing it to points B and C to determine if it qualifies as a local maximum. If it meets this criterion, it proceeds to the subsequent stage of processing; otherwise, it undergoes suppression and is assigned a value of zero. Image courtesy of {cite:p}`OpenCVDocumentation.</span><a class="headerlink" href="#id24" title="Permalink to this image">#</a></p>
</div>
<ol class="arabic simple" start="4">
<li><p><strong>Hysteresis Thresholding</strong>: This stage is crucial for distinguishing genuine edges from non-edges. It relies on two threshold values, namely, minVal and maxVal. Pixels with intensity gradients exceeding maxVal are unequivocally identified as edges, while those falling below minVal are unequivocally classified as non-edges and discarded. Pixels falling between these two thresholds are assessed based on their connectivity to “sure-edge” pixels. If they are connected to such pixels, they are deemed part of the edges; otherwise, they are also discarded <span id="id21">[<a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>.</p></li>
</ol>
<div class="figure align-center" id="id25">
<a class="reference internal image-reference" href="_images/hysteresis.jpg"><img alt="_images/hysteresis.jpg" src="_images/hysteresis.jpg" style="width: 600px;" /></a>
<p class="caption"><span class="caption-number">Fig. 5.3 </span><span class="caption-text">Edge A surpasses the threshold maxVal, categorizing it as a “sure-edge.” Conversely, while edge C falls below maxVal, its connectivity to edge A validates it as a legitimate edge, resulting in the formation of the complete curve. In contrast, edge B, despite exceeding minVal and residing within the same region as edge C, lacks connectivity to any “sure-edge” and is consequently discarded. Consequently, the precise selection of minVal and maxVal is of paramount importance in achieving accurate results. Image courtesy of {cite:p}`OpenCVDocumentation.</span><a class="headerlink" href="#id25" title="Permalink to this image">#</a></p>
</div>
<p>It’s imperative to carefully select minVal and maxVal to obtain the desired results and effectively eliminate small pixel noise, as the algorithm assumes that edges correspond to elongated lines <span id="id22">[<a class="reference internal" href="References.html#id26" title="OpenCV Developers. Opencv documentation. https://docs.opencv.org/4.x/index.html, 2023. [Online; accessed 01-August-2023].">OpenCV Developers, 2023</a>]</span>.</p>
</div>
<div class="section" id="canny-edge-detection-in-opencv">
<h3><span class="section-number">5.3.3. </span>Canny Edge Detection in OpenCV<a class="headerlink" href="#canny-edge-detection-in-opencv" title="Permalink to this heading">#</a></h3>
<p>OpenCV conveniently encapsulates the Canny Edge Detection algorithm within a single function: <code class="docutils literal notranslate"><span class="pre">cv.Canny()</span></code>. Let’s delve into its usage and parameters.</p>
<ul class="simple">
<li><p><strong>Input Image</strong>: The first argument is the input image on which edge detection is applied.</p></li>
<li><p><strong>Threshold Values</strong>: The second and third arguments, denoted as minVal and maxVal respectively, establish the lower and upper thresholds for the edge detection process.</p></li>
<li><p><strong>Aperture Size</strong>: The fourth argument, aperture_size, signifies the size of the Sobel kernel employed for computing image gradients. By default, it assumes a size of 3.</p></li>
<li><p><strong>L2 Gradient</strong>: The last argument, L2gradient, is a Boolean parameter that specifies the equation for calculating gradient magnitude. When set to True, it employs the more accurate equation discussed earlier: <span class="math notranslate nohighlight">\(Edge\_Gradient \; (G) = \sqrt{G_x^2 + G_y^2}\)</span>. Conversely, when set to False, it employs the alternative function: <span class="math notranslate nohighlight">\(Edge\_Gradient \; (G) = |G_x| + |G_y|\)</span>.</p></li>
</ul>
</div>
<div class="section" id="cv2-canny-function">
<h3><span class="section-number">5.3.4. </span><code class="docutils literal notranslate"><span class="pre">cv2.Canny</span></code> Function<a class="headerlink" href="#cv2-canny-function" title="Permalink to this heading">#</a></h3>
<p>In OpenCV, the <code class="docutils literal notranslate"><span class="pre">cv2.Canny</span></code> function [1] serves the purpose of edge detection in images. It detects edges in a single-channel (grayscale) 8-bit input image and generates an output edge map with the same dimensions and type as the input image. Here’s an explanation of the parameters and the function’s operation:</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">image</span></code></strong>: This corresponds to the input image subjected to edge detection. It should be a single-channel 8-bit image, typically in grayscale.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">edges</span></code></strong>: This is the output edge map where the detected edges are represented as white lines on a black background. It shares the same size and type as the input image.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">threshold1</span></code> and <code class="docutils literal notranslate"><span class="pre">threshold2</span></code></strong>: These parameters control the thresholds used in the hysteresis procedure, a crucial part of the Canny edge detection algorithm. The process involves marking potential edge points based on their gradient magnitudes relative to these thresholds.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">apertureSize</span></code></strong>: This parameter determines the aperture size for the Sobel operator, influencing the pixel neighborhood over which the gradient is computed. The default value is typically 3, indicating a 3x3 pixel neighborhood.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">L2gradient</span></code></strong>: A Boolean flag that dictates whether the more precise L2 norm or the default L1 norm should be utilized for calculating gradient magnitude.</p></li>
</ul>
<p>For further details, refer to the <a class="reference external" href="https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html">OpenCV documentation on Canny Edge Detection</a>.</p>
<p><font color='Blue'><b>Example:</b></font></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import necessary libraries</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_sample_images</span> 
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">io</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="c1"># Load sample images</span>
<span class="n">sample_images</span> <span class="o">=</span> <span class="n">load_sample_images</span><span class="p">()[</span><span class="s1">&#39;images&#39;</span><span class="p">]</span>
<span class="n">sample_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">load_sample_images</span><span class="p">()[</span><span class="s1">&#39;filenames&#39;</span><span class="p">]]</span>

<span class="c1"># Load the custom image (UofC)</span>
<span class="n">uofc_img_url</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;https://conted.ucalgary.ca/maincampus/maincampus.jpg&#39;</span>
<span class="n">uofc_img</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">uofc_img_url</span><span class="p">)</span>
<span class="n">sample_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">uofc_img</span><span class="p">)</span>
<span class="n">sample_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;UofC&#39;</span><span class="p">)</span>

<span class="c1"># Create a 2x2 grid of subplots for displaying images</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sample_images</span><span class="p">),</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">9.5</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>  <span class="c1"># Flatten the subplots for easier manipulation</span>

<span class="c1"># Loop to display original images and their edges</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">img</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sample_images</span><span class="p">):</span>    
    <span class="c1"># Display the original image in the left subplot</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Original Image - </span><span class="si">{</span><span class="n">sample_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    
    <span class="c1"># the original image in grayscale</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
    <span class="n">edge_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Canny</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
    
    <span class="c1"># Display the edge-detected image in the right subplot</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">edge_img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Image Edges - </span><span class="si">{</span><span class="n">sample_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

<span class="c1"># Additional settings for each subplot</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="p">)):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Set aspect ratio to 1 (square aspect)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>    <span class="c1"># Turn off axis</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/dd40366a45f9a78c98de8e97ddf2a2a83f406c4b4793c4158f3236b785dd4ff5.png" src="_images/dd40366a45f9a78c98de8e97ddf2a2a83f406c4b4793c4158f3236b785dd4ff5.png" />
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="CV_C4.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Image Thresholding</p>
      </div>
    </a>
    <a class="right-next"
       href="CV_C6.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6. </span>Morphological Transformations</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#smoothing-images">5.1. Smoothing Images</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-convolution-image-filtering">5.1.1. 2D Convolution (Image Filtering)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-blurring-image-smoothing">5.2. Image Blurring (Image Smoothing)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#box-blur-average-blur">5.2.1. Box Blur (Average Blur)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#box-filter">5.2.2. Box Filter</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-blur">5.2.3. Gaussian Blur</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#median-blur">5.2.4. Median Blur</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bilateral-filtering">5.2.5. Bilateral Filtering</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-detection">5.3. Feature Detection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sobel-derivatives">5.3.1. Sobel Derivatives</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#canny-edge-detection-algorithm">5.3.2. Canny Edge Detection Algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#canny-edge-detection-in-opencv">5.3.3. Canny Edge Detection in OpenCV</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cv2-canny-function">5.3.4. <code class="docutils literal notranslate"><span class="pre">cv2.Canny</span></code> Function</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hatef Dastour
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>